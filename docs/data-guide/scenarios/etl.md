---
title: Extrahieren, Transformieren und Laden (ETL)
description: 
author: zoinerTejada
ms:date: 02/12/2018
ms.openlocfilehash: a980c1f8aef99fc263083e5e496b1340204f7dac
ms.sourcegitcommit: 90cf2de795e50571d597cfcb9b302e48933e7f18
ms.translationtype: HT
ms.contentlocale: de-DE
ms.lasthandoff: 02/14/2018
---
# <a name="extract-transform-and-load-etl"></a><span data-ttu-id="d98d8-102">Extrahieren, Transformieren und Laden (ETL)</span><span class="sxs-lookup"><span data-stu-id="d98d8-102">Extract, transform, and load (ETL)</span></span>

<span data-ttu-id="d98d8-103">Viele Organisationen fragen sich, wie sie Daten aus mehreren Datenquellen und in verschiedenen Formaten erfassen und in einzelne oder mehrere Datenspeicher verschieben können.</span><span class="sxs-lookup"><span data-stu-id="d98d8-103">A common problem that organizations face is how to gathering data from multiple sources, in multiple formats, and move it to one or more data stores.</span></span> <span data-ttu-id="d98d8-104">Das Ziel ist möglicherweise nicht die gleiche Art von Datenspeicher wie die Quelle, und häufig unterscheidet sich auch das Format, oder die Daten müssen vor dem Laden in das endgültige Ziel strukturiert oder bereinigt werden.</span><span class="sxs-lookup"><span data-stu-id="d98d8-104">The destination may not be the same type of data store as the source, and often the format is different, or the data needs to be shaped or cleaned before loading it into its final destination.</span></span>

<span data-ttu-id="d98d8-105">Zur Bewältigung dieser Herausforderungen wurden im Laufe der Jahre verschiedene Tools, Dienste und Prozesse entwickelt.</span><span class="sxs-lookup"><span data-stu-id="d98d8-105">Various tools, services, and processes have been developed over the years to help address these challenges.</span></span> <span data-ttu-id="d98d8-106">Unabhängig vom verwendeten Prozess muss im Allgemeinen die Arbeit koordiniert und ein gewisses Maß an Datentransformation innerhalb der Datenpipeline angewendet werden.</span><span class="sxs-lookup"><span data-stu-id="d98d8-106">No matter the process used, there is a common need to coordinate the work and apply some level of data transformation within the data pipeline.</span></span> <span data-ttu-id="d98d8-107">In den folgenden Abschnitten werden gängige Methoden für die Durchführung dieser Aufgaben erläutert.</span><span class="sxs-lookup"><span data-stu-id="d98d8-107">The following sections highlight the common methods used to perform these tasks.</span></span>

## <a name="extract-transform-and-load-etl"></a><span data-ttu-id="d98d8-108">Extrahieren, Transformieren und Laden (ETL)</span><span class="sxs-lookup"><span data-stu-id="d98d8-108">Extract, transform, and load (ETL)</span></span>

<span data-ttu-id="d98d8-109">Extrahieren, Transformieren und Laden (ETL) ist eine Datenpipeline und wird verwendet, um Daten aus verschiedenen Quellen zu sammeln, gemäß den Geschäftsregeln zu transformieren und in einen Zieldatenspeicher zu laden.</span><span class="sxs-lookup"><span data-stu-id="d98d8-109">Extract, transform, and load (ETL) is a data pipeline used to collect data from various sources, transform the data according to business rules, and load it into a destination data store.</span></span> <span data-ttu-id="d98d8-110">Die Transformation in ETL findet in einem speziellen Modul statt und beinhaltet häufig die Verwendung von Stagingtabellen zur vorübergehenden Speicherung von Daten, während diese transformiert und schließlich in das Ziel geladen werden.</span><span class="sxs-lookup"><span data-stu-id="d98d8-110">The transformation work in ETL takes place in a specialized engine, and often involves using staging tables to temporarily hold data as it is being transformed and ultimately loaded to its destination.</span></span>

<span data-ttu-id="d98d8-111">Die durchgeführte Datentransformation umfasst in der Regel verschiedene Vorgänge wie Filtern, Sortieren, Aggregieren, Verknüpfen, Bereinigen, Deduplizieren und Validieren von Daten.</span><span class="sxs-lookup"><span data-stu-id="d98d8-111">The data transformation that takes place usually involves various operations, such as filtering, sorting, aggregating, joining data, cleaning data, deduplicating, and validating data.</span></span>

![ETL-Prozess (Extrahieren, Transformieren, Laden)](./images/etl.png)

<span data-ttu-id="d98d8-113">Die drei ETL-Phasen werden häufig parallel ausgeführt, um Zeit zu sparen.</span><span class="sxs-lookup"><span data-stu-id="d98d8-113">Often, the three ETL phases are run in parallel to save time.</span></span> <span data-ttu-id="d98d8-114">Während der Datenextraktion kann also beispielsweise ein Transformationsprozess für bereits empfangene Daten ausgeführt werden, um die Daten für das Laden vorzubereiten, und ein Ladevorgang kann mit der Arbeit an den vorbereiteten Daten beginnen, anstatt auf den Abschluss des gesamten Extraktionsprozesses zu warten.</span><span class="sxs-lookup"><span data-stu-id="d98d8-114">For example, while data is being extracted, a transformation process could be working on data already received and prepare it for loading, and a loading process can begin working on the prepared data, rather than waiting for the entire extraction process to complete.</span></span>

<span data-ttu-id="d98d8-115">In Frage kommender Azure-Dienst:</span><span class="sxs-lookup"><span data-stu-id="d98d8-115">Relevant Azure service:</span></span>
- [<span data-ttu-id="d98d8-116">Azure Data Factory v2</span><span class="sxs-lookup"><span data-stu-id="d98d8-116">Azure Data Factory v2</span></span>](https://azure.microsoft.com/services/data-factory/)

<span data-ttu-id="d98d8-117">Weitere Tools:</span><span class="sxs-lookup"><span data-stu-id="d98d8-117">Other tools:</span></span>
- [<span data-ttu-id="d98d8-118">SQL Server Integration Services (SSIS)</span><span class="sxs-lookup"><span data-stu-id="d98d8-118">SQL Server Integration Services (SSIS)</span></span>](/sql/integration-services/sql-server-integration-services)

## <a name="extract-load-and-transform-elt"></a><span data-ttu-id="d98d8-119">Extrahieren, Laden und Transformieren (ELT)</span><span class="sxs-lookup"><span data-stu-id="d98d8-119">Extract, load, and transform (ELT)</span></span>

<span data-ttu-id="d98d8-120">Extrahieren, Laden und Transformieren (ELT) unterscheidet sich von ETL lediglich darin, an welcher Stelle die Transformation erfolgt.</span><span class="sxs-lookup"><span data-stu-id="d98d8-120">Extract, load, and transform (ELT) differs from ETL solely in where the transformation takes place.</span></span> <span data-ttu-id="d98d8-121">In der ELT-Pipeline findet die Transformation im Zieldatenspeicher statt.</span><span class="sxs-lookup"><span data-stu-id="d98d8-121">In the ELT pipeline, the transformation occurs in the target data store.</span></span> <span data-ttu-id="d98d8-122">Die Daten werden mithilfe der Verarbeitungsfunktionen des Zieldatenspeichers transformiert, anstatt ein separates Transformationsmodul zu verwenden.</span><span class="sxs-lookup"><span data-stu-id="d98d8-122">Instead of using a separate transformation engine, the processing capabilities of the target data store are used to transform data.</span></span> <span data-ttu-id="d98d8-123">Dadurch wird das Transformationsmodul aus der Pipeline entfernt, was die Architektur vereinfacht.</span><span class="sxs-lookup"><span data-stu-id="d98d8-123">This simplifies the architecture by removing the transformation engine from the pipeline.</span></span> <span data-ttu-id="d98d8-124">Ein weiterer Vorteil dieses Ansatzes ist, dass durch Skalieren des Zieldatenspeichers auch die Leistung der ELT-Pipeline skaliert wird.</span><span class="sxs-lookup"><span data-stu-id="d98d8-124">Another benefit to this approach is that scaling the target data store also scales the ELT pipeline performance.</span></span> <span data-ttu-id="d98d8-125">ELT setzt jedoch voraus, dass das Zielsystem über genügend Leistung verfügt, um die Daten effizient transformieren zu können.</span><span class="sxs-lookup"><span data-stu-id="d98d8-125">However, ELT only works well when the target system is powerful enough to transform the data efficiently.</span></span>

![ELT-Prozess (Extrahieren, Laden, Transformieren)](./images/elt.png)

<span data-ttu-id="d98d8-127">ELT kommt üblicherweise in Big Data-Szenarien zum Einsatz.</span><span class="sxs-lookup"><span data-stu-id="d98d8-127">Typical use cases for ELT fall within the big data realm.</span></span> <span data-ttu-id="d98d8-128">So können Sie beispielsweise zunächst alle Quelldaten in Flatfiles in einem skalierbaren Speicher wie HDFS (Hadoop Distributed File System) oder Azure Data Lake Store extrahieren.</span><span class="sxs-lookup"><span data-stu-id="d98d8-128">For example, you might start by extracting all of the source data to flat files in scalable storage such as Hadoop distributed file system (HDFS) or Azure Data Lake Store.</span></span> <span data-ttu-id="d98d8-129">Anschließend können Sie die Quelldaten mit Technologien wie Spark, Hive oder PolyBase abfragen.</span><span class="sxs-lookup"><span data-stu-id="d98d8-129">Technologies such as Spark, Hive, or PolyBase can then be used to query the source data.</span></span> <span data-ttu-id="d98d8-130">Entscheidend bei ELT ist, dass der für die Transformation verwendete Datenspeicher der gleiche Datenspeicher ist, in dem die Daten später auch genutzt werden.</span><span class="sxs-lookup"><span data-stu-id="d98d8-130">The key point with ELT is that the data store used to perform the transformation is the same data store where the data is ultimately consumed.</span></span> <span data-ttu-id="d98d8-131">Dieser Datenspeicher liest direkt aus dem skalierbaren Speicher, anstatt die Daten in seinen eigenen proprietären Speicher zu laden.</span><span class="sxs-lookup"><span data-stu-id="d98d8-131">This data store reads directly from the scalable storage, instead of loading the data into its own proprietary storage.</span></span> <span data-ttu-id="d98d8-132">Bei diesem Ansatz wird also der Datenkopierschritt aus ELT übersprungen, der bei umfangreichen Datasets sehr zeitaufwendig sein kann.</span><span class="sxs-lookup"><span data-stu-id="d98d8-132">This approach skips the data copy step present in ETL, which can be a time consuming operation for large data sets.</span></span>

<span data-ttu-id="d98d8-133">In der Praxis ist der Zieldatenspeicher ein [Data Warehouse](./data-warehousing.md) mit einem Hadoop-Cluster (Hive oder Spark) oder ein SQL Data Warehouse.</span><span class="sxs-lookup"><span data-stu-id="d98d8-133">In practice, the target data store is a [data warehouse](./data-warehousing.md) using either a Hadoop cluster (using Hive or Spark) or a SQL Data Warehouse.</span></span> <span data-ttu-id="d98d8-134">Im Allgemeinen wird bei der Abfrage ein Schema auf die Flatfiledaten angewendet und als Tabelle gespeichert, wodurch die Daten wie jede andere Tabelle im Datenspeicher abgefragt werden können.</span><span class="sxs-lookup"><span data-stu-id="d98d8-134">In general, a schema is overlaid on the flat file data at query time and stored as a table, enabling the data to be queried like any other table in the data store.</span></span> <span data-ttu-id="d98d8-135">Diese Tabellen werden als externe Tabellen bezeichnet, da sich die Daten nicht in dem Speicher befinden, der vom Datenspeicher selbst verwaltet wird, sondern in einem externen skalierbaren Speicher.</span><span class="sxs-lookup"><span data-stu-id="d98d8-135">These are referred to as external tables because the data does not reside in storage managed by the data store itself, but on some external scalable storage.</span></span> 

<span data-ttu-id="d98d8-136">Der Datenspeicher verwaltet nur das Schema der Daten und wendet es beim Lesen an.</span><span class="sxs-lookup"><span data-stu-id="d98d8-136">The data store only manages the schema of the data and applies the schema on read.</span></span> <span data-ttu-id="d98d8-137">Ein Hadoop-Cluster mit Hive beschreibt beispielsweise eine Hive-Tabelle, in der die Datenquelle im Grunde ein Pfad zu einer Gruppe von Dateien in HDFS ist.</span><span class="sxs-lookup"><span data-stu-id="d98d8-137">For example, a Hadoop cluster using Hive would describe a Hive table where the data source is effectively a path to a set of files in HDFS.</span></span> <span data-ttu-id="d98d8-138">In SQL Data Warehouse lässt sich mit PolyBase das gleiche Ergebnis erzielen: Es wird eine Tabelle für Daten erstellt, die außerhalb der eigentlichen Datenbank gespeichert sind.</span><span class="sxs-lookup"><span data-stu-id="d98d8-138">In SQL Data Warehouse, PolyBase can achieve the same result &mdash; creating a table against data stored externally to the database itself.</span></span> <span data-ttu-id="d98d8-139">Nach dem Laden der Quelldaten können die in externen Tabellen enthaltenen Daten mithilfe der Funktionen des Datenspeichers verarbeitet werden.</span><span class="sxs-lookup"><span data-stu-id="d98d8-139">Once the source data is loaded, the data present in the external tables can be processed using the capabilities of the data store.</span></span> <span data-ttu-id="d98d8-140">In Big Data-Szenarien muss der Datenspeicher für MPP (Massively Parallel Processing) geeignet sein. Dabei werden die Daten in kleinere Blöcke aufgeteilt, die dann parallel von mehreren Computern verarbeitet werden.</span><span class="sxs-lookup"><span data-stu-id="d98d8-140">In big data scenarios, this means the data store must be capable of massively parallel processing (MPP), which breaks the data into smaller chunks and distributes processing of the chunks across multiple machines in parallel.</span></span>

<span data-ttu-id="d98d8-141">In der letzten Phase der ELT-Pipeline werden die Quelldaten üblicherweise in ein endgültiges Format transformiert, das besser für die Arten von Abfragen geeignet ist, die unterstützt werden müssen.</span><span class="sxs-lookup"><span data-stu-id="d98d8-141">The final phase of the ELT pipeline is typically to transform the source data into a final format that is more efficient for the types of queries that need to be supported.</span></span> <span data-ttu-id="d98d8-142">So können die Daten beispielsweise partitioniert werden.</span><span class="sxs-lookup"><span data-stu-id="d98d8-142">For example, the data may be partitioned.</span></span> <span data-ttu-id="d98d8-143">ELT kann außerdem optimierte Speicherformate wie Parquet verwendet, das zeilenorientierte Daten spaltenförmig speichert und eine optimierte Indizierung bietet.</span><span class="sxs-lookup"><span data-stu-id="d98d8-143">Also, ELT might use optimized storage formats like Parquet, which stores row-oriented data in a columnar fashion and providess optimized indexing.</span></span> 

<span data-ttu-id="d98d8-144">In Frage kommender Azure-Dienst:</span><span class="sxs-lookup"><span data-stu-id="d98d8-144">Relevant Azure service:</span></span>

- [<span data-ttu-id="d98d8-145">Azure SQL Data Warehouse</span><span class="sxs-lookup"><span data-stu-id="d98d8-145">Azure SQL Data Warehouse</span></span>](/azure/sql-data-warehouse/sql-data-warehouse-overview-what-is)
- [<span data-ttu-id="d98d8-146">HDInsight mit Hive</span><span class="sxs-lookup"><span data-stu-id="d98d8-146">HDInsight with Hive</span></span>](/azure/hdinsight/hadoop/hdinsight-use-hive)
- [<span data-ttu-id="d98d8-147">Azure Data Factory v2</span><span class="sxs-lookup"><span data-stu-id="d98d8-147">Azure Data Factory v2</span></span>](https://azure.microsoft.com/services/data-factory/)
- [<span data-ttu-id="d98d8-148">Oozie in HDInsight</span><span class="sxs-lookup"><span data-stu-id="d98d8-148">Oozie on HDInsight</span></span>](/azure/hdinsight/hdinsight-use-oozie-linux-mac)

<span data-ttu-id="d98d8-149">Weitere Tools:</span><span class="sxs-lookup"><span data-stu-id="d98d8-149">Other tools:</span></span>

- [<span data-ttu-id="d98d8-150">SQL Server Integration Services (SSIS)</span><span class="sxs-lookup"><span data-stu-id="d98d8-150">SQL Server Integration Services (SSIS)</span></span>](/sql/integration-services/sql-server-integration-services)

## <a name="data-flow-and-control-flow"></a><span data-ttu-id="d98d8-151">Datenfluss und Ablaufsteuerung</span><span class="sxs-lookup"><span data-stu-id="d98d8-151">Data flow and control flow</span></span>

<span data-ttu-id="d98d8-152">Im Datenpipelinekontext sorgt die Ablaufsteuerung für eine geordnete Verarbeitung einer Reihe von Tasks.</span><span class="sxs-lookup"><span data-stu-id="d98d8-152">In the context of data pipelines, the control flow ensures orderly processing of a set of tasks.</span></span> <span data-ttu-id="d98d8-153">Zur Erzwingung der korrekten Verarbeitungsreihenfolge dieser Tasks werden Rangfolgeneinschränkungen verwendet.</span><span class="sxs-lookup"><span data-stu-id="d98d8-153">To enforce the correct processing order of these tasks, precedence constraints are used.</span></span> <span data-ttu-id="d98d8-154">Diese Einschränkungen können Sie sich als Connectors in einem Workflowdiagramm vorstellen, wie in der folgenden Abbildung zu sehen.</span><span class="sxs-lookup"><span data-stu-id="d98d8-154">You can think of these constraints as connectors in a workflow diagram, as shown in the image below.</span></span> <span data-ttu-id="d98d8-155">Jeder Task hat ein Ergebnis wie „Erfolgreich“, „Fehler“ oder „Abschluss“.</span><span class="sxs-lookup"><span data-stu-id="d98d8-155">Each task has an outcome, such as success, failure, or completion.</span></span> <span data-ttu-id="d98d8-156">Die Verarbeitung nachfolgender Tasks wird erst initiiert, wenn der vorherige Task mit einem dieser Ergebnisse abgeschlossen wurde.</span><span class="sxs-lookup"><span data-stu-id="d98d8-156">Any subsequent task does not initiate processing until its predecessor has completed with one of these outcomes.</span></span>

<span data-ttu-id="d98d8-157">Ablaufsteuerungen führen Datenflüsse als Task aus.</span><span class="sxs-lookup"><span data-stu-id="d98d8-157">Control flows execute data flows as a task.</span></span> <span data-ttu-id="d98d8-158">In einem Datenflusstask werden Daten aus einer Quelle extrahiert, transformiert oder in einen Datenspeicher geladen.</span><span class="sxs-lookup"><span data-stu-id="d98d8-158">In a data flow task, data is extracted from a source, transformed, or loaded into a data store.</span></span> <span data-ttu-id="d98d8-159">Die Ausgabe eines einzelnen Datenflusstasks kann als Eingabe für den nächsten Datenflusstask verwendet werden, und Datenflüsse können parallel ausgeführt werden.</span><span class="sxs-lookup"><span data-stu-id="d98d8-159">The output of one data flow task can be the input to the next data flow task, and data flowss can run in parallel.</span></span> <span data-ttu-id="d98d8-160">Im Gegensatz zu Ablaufsteuerungen können zwischen Tasks in einem Datenfluss keine Einschränkungen hinzugefügt werden.</span><span class="sxs-lookup"><span data-stu-id="d98d8-160">Unlike control flows, you cannot add constraints between tasks in a data flow.</span></span> <span data-ttu-id="d98d8-161">Sie können jedoch einen Daten-Viewer hinzufügen, um die Daten zu beobachten, die durch die einzelnen Tasks verarbeitet werden.</span><span class="sxs-lookup"><span data-stu-id="d98d8-161">You can, however, add a data viewer to observe the data as it is processed by each task.</span></span>

![Datenfluss, der als Task in einer Ablaufsteuerung ausgeführt wird](./images/control-flow-data-flow.png)

<span data-ttu-id="d98d8-163">Das obige Diagramm enthält mehrere Tasks innerhalb der Ablaufsteuerung. Einer davon ist ein Datenflusstask.</span><span class="sxs-lookup"><span data-stu-id="d98d8-163">In the diagram above, there are several tasks within the control flow, one of which is a data flow task.</span></span> <span data-ttu-id="d98d8-164">Einer der Tasks ist in einen Container geschachtelt.</span><span class="sxs-lookup"><span data-stu-id="d98d8-164">One of the tasks is nested within a container.</span></span> <span data-ttu-id="d98d8-165">Container ermöglichen die Strukturierung von Tasks, um eine Arbeitseinheit bereitzustellen.</span><span class="sxs-lookup"><span data-stu-id="d98d8-165">Containers can be used to provide structure to tasks, providing a unit of work.</span></span> <span data-ttu-id="d98d8-166">Ein Beispiel wäre etwa die Wiederholung von Elementen in einer Sammlung (beispielsweise Dateien in einem Ordner oder Datenbankanweisungen).</span><span class="sxs-lookup"><span data-stu-id="d98d8-166">One such example is for repeating elements within a collection, such as files in a folder or database statements.</span></span>

<span data-ttu-id="d98d8-167">In Frage kommender Azure-Dienst:</span><span class="sxs-lookup"><span data-stu-id="d98d8-167">Relevant Azure service:</span></span>
- [<span data-ttu-id="d98d8-168">Azure Data Factory v2</span><span class="sxs-lookup"><span data-stu-id="d98d8-168">Azure Data Factory v2</span></span>](https://azure.microsoft.com/services/data-factory/)

<span data-ttu-id="d98d8-169">Weitere Tools:</span><span class="sxs-lookup"><span data-stu-id="d98d8-169">Other tools:</span></span>
- [<span data-ttu-id="d98d8-170">SQL Server Integration Services (SSIS)</span><span class="sxs-lookup"><span data-stu-id="d98d8-170">SQL Server Integration Services (SSIS)</span></span>](/sql/integration-services/sql-server-integration-services)

## <a name="technology-choices"></a><span data-ttu-id="d98d8-171">Auswahl der Technologie</span><span class="sxs-lookup"><span data-stu-id="d98d8-171">Technology choices</span></span>

- [<span data-ttu-id="d98d8-172">OLTP-Datenspeicher (Online Transaction Processing)</span><span class="sxs-lookup"><span data-stu-id="d98d8-172">Online Transaction Processing (OLTP) data stores</span></span>](../technology-choices/oltp-data-stores.md)
- [<span data-ttu-id="d98d8-173">OLAP-Datenspeicher (Online Analytical Processing)</span><span class="sxs-lookup"><span data-stu-id="d98d8-173">Online Analytical Processing (OLAP) data stores</span></span>](../technology-choices/olap-data-stores.md)
- [<span data-ttu-id="d98d8-174">Data Warehouses</span><span class="sxs-lookup"><span data-stu-id="d98d8-174">Data warehouses</span></span>](../technology-choices/data-warehouses.md)
- [<span data-ttu-id="d98d8-175">Pipelineorchestrierung</span><span class="sxs-lookup"><span data-stu-id="d98d8-175">Pipeline orchestration</span></span>](../technology-choices/pipeline-orchestration-data-movement.md)
