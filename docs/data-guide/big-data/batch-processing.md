---
title: Batchverarbeitung
description: ''
author: zoinerTejada
ms.date: 02/12/2018
ms.openlocfilehash: fe07d4d6501d4778025b75807f4d6be5854c3e09
ms.sourcegitcommit: e7e0e0282fa93f0063da3b57128ade395a9c1ef9
ms.translationtype: HT
ms.contentlocale: de-DE
ms.lasthandoff: 12/05/2018
ms.locfileid: "52901982"
---
# <a name="batch-processing"></a><span data-ttu-id="05036-102">Batchverarbeitung</span><span class="sxs-lookup"><span data-stu-id="05036-102">Batch processing</span></span>

<span data-ttu-id="05036-103">Ein verbreitetes Big Data-Szenario ist die Batchverarbeitung ruhender Daten.</span><span class="sxs-lookup"><span data-stu-id="05036-103">A common big data scenario is batch processing of data at rest.</span></span> <span data-ttu-id="05036-104">In diesem Szenario werden die Quelldaten in einen Datenspeicher geladen – entweder durch die Quellanwendung selbst oder durch einen Orchestrierungsworkflow.</span><span class="sxs-lookup"><span data-stu-id="05036-104">In this scenario, the source data is loaded into data storage, either by the source application itself or by an orchestration workflow.</span></span> <span data-ttu-id="05036-105">Anschließend werden die Daten direkt durch einen parallelisierten Auftrag verarbeitet. Dieser Auftrag kann ebenfalls durch den Orchestrierungsworkflow initiiert werden.</span><span class="sxs-lookup"><span data-stu-id="05036-105">The data is then processed in-place by a parallelized job, which can also be initiated by the orchestration workflow.</span></span> <span data-ttu-id="05036-106">Die Verarbeitung kann mehrere iterative Schritte umfassen. Die transformierten Ergebnisse werden schließlich in einen Analysedatenspeicher geladen, der von Analyse- und Berichterstellungskomponenten abgefragt werden kann.</span><span class="sxs-lookup"><span data-stu-id="05036-106">The processing may include multiple iterative steps before the transformed results are loaded into an analytical data store, which can be queried by analytics and reporting components.</span></span>

<span data-ttu-id="05036-107">So können beispielsweise die Protokolle eines Webservers in einen Ordner kopiert und über Nacht verarbeitet werden, um tägliche Berichte zur Webaktivität zu generieren.</span><span class="sxs-lookup"><span data-stu-id="05036-107">For example, the logs from a web server might be copied to a folder and then processed overnight to generate daily reports of web activity.</span></span>

![](./images/batch-pipeline.png)

## <a name="when-to-use-this-solution"></a><span data-ttu-id="05036-108">Verwendung dieser Lösung</span><span class="sxs-lookup"><span data-stu-id="05036-108">When to use this solution</span></span>

<span data-ttu-id="05036-109">Die Batchverarbeitung kommt in verschiedensten Szenarien zum Einsatz – von der einfachen Datentransformation bis hin zur umfassenderen ETL-Pipeline (Extrahieren, Transformieren, Laden).</span><span class="sxs-lookup"><span data-stu-id="05036-109">Batch processing is used in a variety of scenarios, from simple data transformations to a more complete ETL (extract-transform-load) pipeline.</span></span> <span data-ttu-id="05036-110">In einem Big Data-Kontext kann die Batchverarbeitung auf sehr große Datasets angewendet werden, bei denen die Berechnung viel Zeit in Anspruch nimmt.</span><span class="sxs-lookup"><span data-stu-id="05036-110">In a big data context, batch processing may operate over very large data sets, where the computation takes significant time.</span></span> <span data-ttu-id="05036-111">(Weitere Informationen finden Sie beispielsweise unter [Lambda-Architektur](../big-data/index.md#lambda-architecture).) Die Batchverarbeitung führt in der Regel zu weiteren interaktiven Untersuchungen, stellt die modellierungsbereiten Daten für Machine Learning bereit oder schreibt die Daten in einen für die Analyse und Visualisierung optimierten Datenspeicher.</span><span class="sxs-lookup"><span data-stu-id="05036-111">(For example, see [Lambda architecture](../big-data/index.md#lambda-architecture).) Batch processing typically leads to further interactive exploration, provides the modeling-ready data for machine learning, or writes the data to a data store that is optimized for analytics and visualization.</span></span>

<span data-ttu-id="05036-112">Ein Beispiel für die Batchverarbeitung ist die Transformation zahlreicher teilweise strukturierter CSV- oder JSON-Flatfiles in ein schematisiertes und strukturiertes Format, das für weitere Abfragen genutzt werden kann.</span><span class="sxs-lookup"><span data-stu-id="05036-112">One example of batch processing is transforming a large set of flat, semi-structured CSV or JSON files into a schematized and structured format that is ready for further querying.</span></span> <span data-ttu-id="05036-113">Die Daten werden in der Regel aus den bei der Erfassung verwendeten Rohformaten (beispielsweise CSV) in Binärformate konvertiert, mit denen sich bei Abfragen eine bessere Leistung erzielen lässt, da sie Daten in einem spaltenförmigen Format speichern und häufig Indizes und Inlinestatistiken für die Daten bereitstellen.</span><span class="sxs-lookup"><span data-stu-id="05036-113">Typically the data is converted from the raw formats used for ingestion (such as CSV) into binary formats that are more performant for querying because they store data in a columnar format, and often provide indexes and inline statistics about the data.</span></span>

## <a name="challenges"></a><span data-ttu-id="05036-114">Herausforderungen</span><span class="sxs-lookup"><span data-stu-id="05036-114">Challenges</span></span>

- <span data-ttu-id="05036-115">**Datenformat und -codierung**:</span><span class="sxs-lookup"><span data-stu-id="05036-115">**Data format and encoding**.</span></span> <span data-ttu-id="05036-116">Einige der kompliziertesten Probleme treten bei Dateien mit unerwartetem Format oder unerwarteter Codierung auf.</span><span class="sxs-lookup"><span data-stu-id="05036-116">Some of the most difficult issues to debug happen when files use an unexpected format or encoding.</span></span> <span data-ttu-id="05036-117">So können Quelldateien beispielsweise eine Mischung aus UTF-16- und UTF-8-Codierung, unerwartete Trennzeichen (Leerzeichen anstelle von Tabstopps) oder unerwartete Zeichen enthalten.</span><span class="sxs-lookup"><span data-stu-id="05036-117">For example, source files might use a mix of UTF-16 and UTF-8 encoding, or contain unexpected delimiters (space versus tab), or include unexpected characters.</span></span> <span data-ttu-id="05036-118">Ein weiteres Beispiel sind Textfelder mit Tabstopps, Leerzeichen oder Kommas, die als Trennzeichen interpretiert werden.</span><span class="sxs-lookup"><span data-stu-id="05036-118">Another common example is text fields that contain tabs, spaces, or commas that are interpreted as delimiters.</span></span> <span data-ttu-id="05036-119">Die Logik für das Laden und Analysieren der Daten muss über die nötige Flexibilität verfügen, um diese Probleme erkennen und bewältigen zu können.</span><span class="sxs-lookup"><span data-stu-id="05036-119">Data loading and parsing logic must be flexible enough to detect and handle these issues.</span></span>

- <span data-ttu-id="05036-120">**Orchestrieren von Zeitsegmenten**:</span><span class="sxs-lookup"><span data-stu-id="05036-120">**Orchestrating time slices.**</span></span> <span data-ttu-id="05036-121">Quelldaten werden häufig in einer Ordnerhierarchie platziert, die Verarbeitungsfenster darstellt, welche nach Jahr, Monat, Tag, Stunde usw. strukturiert sind.</span><span class="sxs-lookup"><span data-stu-id="05036-121">Often source data is placed in a folder hierarchy that reflects processing windows, organized by year, month, day, hour, and so on.</span></span> <span data-ttu-id="05036-122">Manchmal treffen Daten unter Umständen verspätet ein.</span><span class="sxs-lookup"><span data-stu-id="05036-122">In some cases, data may arrive late.</span></span> <span data-ttu-id="05036-123">Ein Beispiel: Angenommen, ein Webserver fällt aus, und die Protokolle für den 7. März landen erst am 9. März in dem Ordner für die Verarbeitung.</span><span class="sxs-lookup"><span data-stu-id="05036-123">For example, suppose that a web server fails, and the logs for March 7th don't end up in the folder for processing until March 9th.</span></span> <span data-ttu-id="05036-124">Werden sie einfach ignoriert, da sie zu spät eingetroffen sind?</span><span class="sxs-lookup"><span data-stu-id="05036-124">Are they just ignored because they're too late?</span></span> <span data-ttu-id="05036-125">Kommt die Downstreamverarbeitungslogik mit außerordentlichen Datensätzen zurecht?</span><span class="sxs-lookup"><span data-stu-id="05036-125">Can the downstream processing logic handle out-of-order records?</span></span>

## <a name="architecture"></a><span data-ttu-id="05036-126">Architecture</span><span class="sxs-lookup"><span data-stu-id="05036-126">Architecture</span></span>

<span data-ttu-id="05036-127">Eine Batchverarbeitungsarchitektur verfügt über folgende logische Komponenten, die auch im obigen Diagramm dargestellt sind:</span><span class="sxs-lookup"><span data-stu-id="05036-127">A batch processing architecture has the following logical components, shown in the diagram above.</span></span>

- <span data-ttu-id="05036-128">**Datenspeicher**:</span><span class="sxs-lookup"><span data-stu-id="05036-128">**Data storage.**</span></span> <span data-ttu-id="05036-129">In der Regel ein verteilter Datenspeicher, der als Repository für zahlreiche große Dateien in verschiedenen Formaten fungieren kann.</span><span class="sxs-lookup"><span data-stu-id="05036-129">Typically a distributed file store that can serve as a repository for high volumes of large files in various formats.</span></span> <span data-ttu-id="05036-130">Diese Art von Speicher wird allgemein häufig als Data Lake bezeichnet.</span><span class="sxs-lookup"><span data-stu-id="05036-130">Generically, this kind of store is often referred to as a data lake.</span></span> 

- <span data-ttu-id="05036-131">**Batchverarbeitung**:</span><span class="sxs-lookup"><span data-stu-id="05036-131">**Batch processing.**</span></span> <span data-ttu-id="05036-132">Aufgrund des großen Umfangs von Big Data müssen Lösungen oftmals Datendateien mithilfe von Batchaufträgen mit langer Ausführungszeit verarbeiten, um die Daten zu filtern, zu aggregieren und anderweitig auf die Analyse vorzubereiten.</span><span class="sxs-lookup"><span data-stu-id="05036-132">The high-volume nature of big data often means that solutions must process data files using long-running batch jobs to filter, aggregate, and otherwise prepare the data for analysis.</span></span> <span data-ttu-id="05036-133">Diese Aufträge beinhalten in der Regel das Lesen von Quelldateien, ihre Verarbeitung und das Schreiben der Ausgabe in neue Dateien.</span><span class="sxs-lookup"><span data-stu-id="05036-133">Usually these jobs involve reading source files, processing them, and writing the output to new files.</span></span> 

- <span data-ttu-id="05036-134">**Analysedatenspeicher**:</span><span class="sxs-lookup"><span data-stu-id="05036-134">**Analytical data store.**</span></span> <span data-ttu-id="05036-135">Viele Big Data-Lösungen bereiten Daten für die Analyse vor und stellen die verarbeiteten Daten dann in einem strukturierten Format bereit, das mithilfe von Analysetools abgefragt werden kann.</span><span class="sxs-lookup"><span data-stu-id="05036-135">Many big data solutions are designed to prepare data for analysis and then serve the processed data in a structured format that can be queried using analytical tools.</span></span> 

- <span data-ttu-id="05036-136">**Analysen und Berichte**:</span><span class="sxs-lookup"><span data-stu-id="05036-136">**Analysis and reporting.**</span></span> <span data-ttu-id="05036-137">Ziel der meisten Big Data-Lösungen ist es, über Analysen und Berichte Einblicke in die Daten zu bieten.</span><span class="sxs-lookup"><span data-stu-id="05036-137">The goal of most big data solutions is to provide insights into the data through analysis and reporting.</span></span> 

- <span data-ttu-id="05036-138">**Orchestrierung**:</span><span class="sxs-lookup"><span data-stu-id="05036-138">**Orchestration.**</span></span> <span data-ttu-id="05036-139">In Verbindung mit der Batchverarbeitung ist in der Regel auch ein gewisses Maß an Orchestrierung erforderlich, um die Daten in Ihren Datenspeicher, in die Batchverarbeitung, in den Analysedatenspeicher und in die Berichterstellungsebenen zu kopieren bzw. zu migrieren.</span><span class="sxs-lookup"><span data-stu-id="05036-139">With batch processing, typically some orchestration is required to migrate or copy the data into your data storage, batch processing, analytical data store, and reporting layers.</span></span>

## <a name="technology-choices"></a><span data-ttu-id="05036-140">Auswahl der Technologie</span><span class="sxs-lookup"><span data-stu-id="05036-140">Technology choices</span></span>

<span data-ttu-id="05036-141">Für Batchverarbeitungslösungen in Azure werden folgende Technologien empfohlen:</span><span class="sxs-lookup"><span data-stu-id="05036-141">The following technologies are recommended choices for batch processing solutions in Azure.</span></span>

### <a name="data-storage"></a><span data-ttu-id="05036-142">Datenspeicher</span><span class="sxs-lookup"><span data-stu-id="05036-142">Data storage</span></span>

- <span data-ttu-id="05036-143">**Azure Storage Blob-Container**:</span><span class="sxs-lookup"><span data-stu-id="05036-143">**Azure Storage Blob Containers**.</span></span> <span data-ttu-id="05036-144">Da Azure Blob Storage bereits von vielen Azure-Geschäftsprozessen genutzt wird, ist diese Option eine gute Wahl für einen Big Data-Speicher.</span><span class="sxs-lookup"><span data-stu-id="05036-144">Many existing Azure business processes already make use of Azure blob storage, making this a good choice for a big data store.</span></span>
- <span data-ttu-id="05036-145">**Azure Data Lake Store**.</span><span class="sxs-lookup"><span data-stu-id="05036-145">**Azure Data Lake Store**.</span></span> <span data-ttu-id="05036-146">Der nahezu unbegrenzte Speicher für jegliche Dateigröße sowie umfassende Sicherheitsoptionen machen Azure Data Lake Store zu einer guten Wahl für besonders umfangreiche Big Data-Lösungen, die einen zentralen Speicher für Daten in heterogenen Formaten benötigen.</span><span class="sxs-lookup"><span data-stu-id="05036-146">Azure Data Lake Store offers virtually unlimited storage for any size of file, and extensive security options, making it a good choice for extremely large-scale big data solutions that require a centralized store for data in heterogeneous formats.</span></span>

<span data-ttu-id="05036-147">Weitere Informationen finden Sie im Artikel zur [Datenspeicherung](../technology-choices/data-storage.md).</span><span class="sxs-lookup"><span data-stu-id="05036-147">For more information, see [Data storage](../technology-choices/data-storage.md).</span></span>

### <a name="batch-processing"></a><span data-ttu-id="05036-148">Batchverarbeitung</span><span class="sxs-lookup"><span data-stu-id="05036-148">Batch processing</span></span>

- <span data-ttu-id="05036-149">**U-SQL**:</span><span class="sxs-lookup"><span data-stu-id="05036-149">**U-SQL**.</span></span> <span data-ttu-id="05036-150">U-SQL ist die von Azure Data Lake Analytics verwendete Abfrageverarbeitungssprache.</span><span class="sxs-lookup"><span data-stu-id="05036-150">U-SQL is the query processing language used by Azure Data Lake Analytics.</span></span> <span data-ttu-id="05036-151">Sie kombiniert den deklarativen Charakter von SQL mit der prozeduralen Erweiterbarkeit von C# und den Vorteilen der Parallelität, um eine effiziente Verarbeitung umfangreicher Daten zu ermöglichen.</span><span class="sxs-lookup"><span data-stu-id="05036-151">It combines the declarative nature of SQL with the procedural extensibility of C#, and takes advantage of parallelism to enable efficient processing of data at massive scale.</span></span>
- <span data-ttu-id="05036-152">**Hive**:</span><span class="sxs-lookup"><span data-stu-id="05036-152">**Hive**.</span></span> <span data-ttu-id="05036-153">Hive ist eine SQL-ähnliche Sprache, die von den meisten Hadoop-Distributionen (einschließlich HDInsight) unterstützt wird.</span><span class="sxs-lookup"><span data-stu-id="05036-153">Hive is a SQL-like language that is supported in most Hadoop distributions, including HDInsight.</span></span> <span data-ttu-id="05036-154">Sie kann zum Verarbeiten von Daten aus einem beliebigen HDFS-kompatiblen Speicher (einschließlich Azure Blob Storage und Azure Data Lake Store) verwendet werden.</span><span class="sxs-lookup"><span data-stu-id="05036-154">It can be used to process data from any HDFS-compatible store, including Azure blob storage and Azure Data Lake Store.</span></span>
- <span data-ttu-id="05036-155">**Pig**:</span><span class="sxs-lookup"><span data-stu-id="05036-155">**Pig**.</span></span> <span data-ttu-id="05036-156">Pig ist eine deklarative Big Data-Verarbeitungssprache, die in vielen Hadoop-Distributionen (einschließlich HDInsight) zum Einsatz kommt.</span><span class="sxs-lookup"><span data-stu-id="05036-156">Pig is a declarative big data processing language used in many Hadoop distributions, including HDInsight.</span></span> <span data-ttu-id="05036-157">Sie eignet sich besonders gut für die Verarbeitung unstrukturierter oder teilweise strukturierter Daten.</span><span class="sxs-lookup"><span data-stu-id="05036-157">It is particularly useful for processing data that is unstructured or semi-structured.</span></span>
- <span data-ttu-id="05036-158">**Spark**:</span><span class="sxs-lookup"><span data-stu-id="05036-158">**Spark**.</span></span> <span data-ttu-id="05036-159">Das Spark-Modul unterstützt Batchverarbeitungsprogramme in verschiedenen Programmiersprachen (beispielsweise Python, Java und Scala).</span><span class="sxs-lookup"><span data-stu-id="05036-159">The Spark engine supports batch processing programs written in a range of languages, including Java, Scala, and Python.</span></span> <span data-ttu-id="05036-160">Spark verwendet eine verteilte Architektur, um Daten parallel auf mehreren Workerknoten zu verarbeiten.</span><span class="sxs-lookup"><span data-stu-id="05036-160">Spark uses a distributed architecture to process data in parallel across multiple worker nodes.</span></span>

<span data-ttu-id="05036-161">Weitere Informationen finden Sie im Artikel zur [Batchverarbeitung](../technology-choices/batch-processing.md).</span><span class="sxs-lookup"><span data-stu-id="05036-161">For more information, see [Batch processing](../technology-choices/batch-processing.md).</span></span>

### <a name="analytical-data-store"></a><span data-ttu-id="05036-162">Analysedatenspeicher</span><span class="sxs-lookup"><span data-stu-id="05036-162">Analytical data store</span></span>

- <span data-ttu-id="05036-163">**SQL Data Warehouse**:</span><span class="sxs-lookup"><span data-stu-id="05036-163">**SQL Data Warehouse**.</span></span> <span data-ttu-id="05036-164">Azure SQL Data Warehouse ist ein verwalteter, auf SQL Server-Datenbanktechnologien basierender Dienst und für die Unterstützung umfangreicher Data Warehousing-Workloads optimiert.</span><span class="sxs-lookup"><span data-stu-id="05036-164">Azure SQL Data Warehouse is a managed service based on SQL Server database technologies and optimized to support large-scale data warehousing workloads.</span></span>
- <span data-ttu-id="05036-165">**Spark SQL**:</span><span class="sxs-lookup"><span data-stu-id="05036-165">**Spark SQL**.</span></span> <span data-ttu-id="05036-166">Spark SQL ist eine API, die auf Spark basiert und die Erstellung von Datenrahmen und Tabellen unterstützt, für die das Abfragen per SQL-Syntax möglich ist.</span><span class="sxs-lookup"><span data-stu-id="05036-166">Spark SQL is an API built on Spark that supports the creation of dataframes and tables that can be queried using SQL syntax.</span></span>
- <span data-ttu-id="05036-167">**HBase**:</span><span class="sxs-lookup"><span data-stu-id="05036-167">**HBase**.</span></span> <span data-ttu-id="05036-168">HBase ist ein NoSQL-Datenspeicher mit geringer Wartezeit und einer flexiblen Hochleistungsoption für die Abfrage strukturierter und teilweise strukturierter Daten.</span><span class="sxs-lookup"><span data-stu-id="05036-168">HBase is a low-latency NoSQL store that offers a high-performance, flexible option for querying structured and semi-structured data.</span></span>
- <span data-ttu-id="05036-169">**Hive**:</span><span class="sxs-lookup"><span data-stu-id="05036-169">**Hive**.</span></span> <span data-ttu-id="05036-170">Hive ist nicht nur bei der Batchverarbeitung hilfreich, sondern bietet auch eine Datenbankarchitektur, die ähnlich konzeptioniert ist wie ein typisches Managementsystem für relationale Datenbanken.</span><span class="sxs-lookup"><span data-stu-id="05036-170">In addition to being useful for batch processing, Hive offers a database architecture that is conceptually similar to that of a typical relational database management system.</span></span> <span data-ttu-id="05036-171">Dank Verbesserungen der Hive-Abfrageleistung durch Innovationen wie dem Tez-Modul und der Stinger-Initiative können Hive-Tabellen in einigen Szenarien effektiv als Quellen für analytische Abfragen verwendet werden.</span><span class="sxs-lookup"><span data-stu-id="05036-171">Improvements in Hive query performance through innovations like the Tez engine and Stinger initiative mean that Hive tables can be used effectively as sources for analytical queries in some scenarios.</span></span>

<span data-ttu-id="05036-172">Weitere Informationen finden Sie im Artikel zu [Analysedatenspeichern](../technology-choices/analytical-data-stores.md).</span><span class="sxs-lookup"><span data-stu-id="05036-172">For more information, see [Analytical data stores](../technology-choices/analytical-data-stores.md).</span></span>

### <a name="analytics-and-reporting"></a><span data-ttu-id="05036-173">Analysen und Berichte</span><span class="sxs-lookup"><span data-stu-id="05036-173">Analytics and reporting</span></span>

- <span data-ttu-id="05036-174">**Azure Analysis Services**:</span><span class="sxs-lookup"><span data-stu-id="05036-174">**Azure Analysis Services**.</span></span> <span data-ttu-id="05036-175">Viele Big Data-Lösungen emulieren herkömmliche Business Intelligence-Architekturen für Unternehmen durch die Einbeziehung eines zentralisierten OLAP-Datenmodells (Online Analytical Processing, analytische Onlineverarbeitung; häufig als Cube bezeichnet), das als Grundlage für Berichte, Dashboards und interaktive Analysen („Slice and Dice“) verwendet werden kann.</span><span class="sxs-lookup"><span data-stu-id="05036-175">Many big data solutions emulate traditional enterprise business intelligence architectures by including a centralized online analytical processing (OLAP) data model (often referred to as a cube) on which reports, dashboards, and interactive “slice and dice” analysis can be based.</span></span> <span data-ttu-id="05036-176">Azure Analysis Services unterstützt die Erstellung tabellarischer Modelle, um diese Anforderung zu erfüllen.</span><span class="sxs-lookup"><span data-stu-id="05036-176">Azure Analysis Services supports the creation of tabular models to meet this need.</span></span>
- <span data-ttu-id="05036-177">**Power BI**:</span><span class="sxs-lookup"><span data-stu-id="05036-177">**Power BI**.</span></span> <span data-ttu-id="05036-178">Mit Power BI können Datenanalysten interaktive Datenvisualisierungen auf der Grundlage von Datenmodellen in einem OLAP-Modell oder direkt auf der Grundlage eines Analysedatenspeichers erstellen.</span><span class="sxs-lookup"><span data-stu-id="05036-178">Power BI enables data analysts to create interactive data visualizations based on data models in an OLAP model or directly from an analytical data store.</span></span>
- <span data-ttu-id="05036-179">**Microsoft Excel**:</span><span class="sxs-lookup"><span data-stu-id="05036-179">**Microsoft Excel**.</span></span> <span data-ttu-id="05036-180">Microsoft Excel ist eine der meistverwendeten Softwareanwendungen der Welt und bietet ein breites Spektrum an Funktionen für die Analyse und Visualisierung von Daten.</span><span class="sxs-lookup"><span data-stu-id="05036-180">Microsoft Excel is one of the most widely used software applications in the world, and offers a wealth of data analysis and visualization capabilities.</span></span> <span data-ttu-id="05036-181">Mit Excel können Datenanalysten Dokumentdatenmodelle auf der Grundlage von Analysedatenspeichern erstellen oder Daten aus OLAP-Datenmodellen in interaktive PivotTables und Diagramme abrufen.</span><span class="sxs-lookup"><span data-stu-id="05036-181">Data analysts can use Excel to build document data models from analytical data stores, or to retrieve data from OLAP data models into interactive PivotTables and charts.</span></span>

<span data-ttu-id="05036-182">Weitere Informationen finden Sie im Artikel zu [Analysen und Berichten](../technology-choices/analysis-visualizations-reporting.md).</span><span class="sxs-lookup"><span data-stu-id="05036-182">For more information, see [Analytics and reporting](../technology-choices/analysis-visualizations-reporting.md).</span></span>

### <a name="orchestration"></a><span data-ttu-id="05036-183">Orchestrierung</span><span class="sxs-lookup"><span data-stu-id="05036-183">Orchestration</span></span>

- <span data-ttu-id="05036-184">**Azure Data Factory**</span><span class="sxs-lookup"><span data-stu-id="05036-184">**Azure Data Factory**.</span></span> <span data-ttu-id="05036-185">Mit Azure Data Factory-Pipelines kann eine Abfolge von Aktivitäten definiert und für wiederkehrende temporale Fenster geplant werden.</span><span class="sxs-lookup"><span data-stu-id="05036-185">Azure Data Factory pipelines can be used to define a sequence of activities, scheduled for recurring temporal windows.</span></span> <span data-ttu-id="05036-186">Diese Aktivitäten können Datenkopiervorgänge sowie Hive-, Pig-, MapReduce- oder Spark-Aufträge in bedarfsgesteuerten HDInsight-Clustern, U-SQL-Aufträge in Azure Data Lake Analytics und gespeicherte Prozeduren in Azure SQL Data Warehouse oder Azure SQL-Datenbank initiieren.</span><span class="sxs-lookup"><span data-stu-id="05036-186">These activities can initiate data copy operations as well as Hive, Pig, MapReduce, or Spark jobs in on-demand HDInsight clusters; U-SQL jobs in Azure Date Lake Analytics; and stored procedures in Azure SQL Data Warehouse or Azure SQL Database.</span></span>
- <span data-ttu-id="05036-187">**Oozie** und **Sqoop**:</span><span class="sxs-lookup"><span data-stu-id="05036-187">**Oozie** and **Sqoop**.</span></span> <span data-ttu-id="05036-188">Oozie ist ein Auftragsautomatisierungsmodul für das Apache Hadoop-Ökosystem und kann verwendet werden, um Datenkopiervorgänge und Hive-, Pig- und MapReduce-Aufträge zum Verarbeiten von Daten sowie Sqoop-Aufträge zum Kopieren von Daten zwischen HDFS und SQL-Datenbanken zu initiieren.</span><span class="sxs-lookup"><span data-stu-id="05036-188">Oozie is a job automation engine for the Apache Hadoop ecosystem and can be used to initiate data copy operations as well as Hive, Pig, and MapReduce jobs to process data and Sqoop jobs to copy data between HDFS and SQL databases.</span></span>

<span data-ttu-id="05036-189">Weitere Informationen finden Sie im Artikel zur [Pipelineorchestrierung](../technology-choices/pipeline-orchestration-data-movement.md).</span><span class="sxs-lookup"><span data-stu-id="05036-189">For more information, see [Pipeline orchestration](../technology-choices/pipeline-orchestration-data-movement.md)</span></span>
