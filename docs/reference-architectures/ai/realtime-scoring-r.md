---
title: Echtzeitbewertung von R-Machine Learning-Modellen
description: Implementieren Sie mithilfe von Machine Learning Server unter Azure Kubernetes Service (AKS) einen Echtzeit-Prognosedienst in R.
author: njray
ms.date: 12/12/2018
ms.topic: reference-architecture
ms.service: architecture-center
ms.subservice: reference-architecture
ms.custom: azcat-ai
ms.openlocfilehash: 00bea3cae0c3d2f0fea2babd7b0157382cf9890a
ms.sourcegitcommit: c053e6edb429299a0ad9b327888d596c48859d4a
ms.translationtype: HT
ms.contentlocale: de-DE
ms.lasthandoff: 03/20/2019
ms.locfileid: "58248685"
---
# <a name="real-time-scoring-of-r-machine-learning-models"></a><span data-ttu-id="0b905-103">Echtzeitbewertung von R-Machine Learning-Modellen</span><span class="sxs-lookup"><span data-stu-id="0b905-103">Real-time scoring of R machine learning models</span></span>

<span data-ttu-id="0b905-104">Diese Referenzarchitektur zeigt, wie Sie mithilfe von Microsoft Machine Learning Server unter Azure Kubernetes Service (AKS) einen (synchronen) Echtzeit-Prognosedienst in R implementieren.</span><span class="sxs-lookup"><span data-stu-id="0b905-104">This reference architecture shows how to implement a real-time (synchronous) prediction service in R using Microsoft Machine Learning Server running in Azure Kubernetes Service (AKS).</span></span> <span data-ttu-id="0b905-105">Diese generische Architektur eignet sich für jedes beliebige R-basierte Prognosemodell, das Sie als Echtzeitdienst bereitstellen möchten.</span><span class="sxs-lookup"><span data-stu-id="0b905-105">This architecture is intended to be generic and suited for any predictive model built in R that you want to deploy as a real-time service.</span></span> <span data-ttu-id="0b905-106">**[Stellen Sie diese Lösung bereit.][github]**</span><span class="sxs-lookup"><span data-stu-id="0b905-106">**[Deploy this solution][github]**.</span></span>

## <a name="architecture"></a><span data-ttu-id="0b905-107">Architecture</span><span class="sxs-lookup"><span data-stu-id="0b905-107">Architecture</span></span>

![Echtzeitbewertung von R-Machine Learning-Modellen in Azure][0]

<span data-ttu-id="0b905-109">In dieser Referenzarchitektur wird ein containerbasierter Ansatz verwendet.</span><span class="sxs-lookup"><span data-stu-id="0b905-109">This reference architecture takes a container-based approach.</span></span> <span data-ttu-id="0b905-110">Es werden ein Docker-Image, das R enthält, sowie die verschiedenen Artefakte erstellt, die zur Bewertung neuer Daten erforderlich sind.</span><span class="sxs-lookup"><span data-stu-id="0b905-110">A Docker image is built containing R, as well as the various artifacts needed to score new data.</span></span> <span data-ttu-id="0b905-111">Dazu gehören das Modellobjekt selbst und ein Bewertungsskript.</span><span class="sxs-lookup"><span data-stu-id="0b905-111">These include the model object itself and a scoring script.</span></span> <span data-ttu-id="0b905-112">Dieses Image wird an eine in Azure gehostete Docker-Registrierung gepusht und anschließend in einem Kubernetes-Cluster (ebenfalls in Azure) bereitgestellt.</span><span class="sxs-lookup"><span data-stu-id="0b905-112">This image is pushed to a Docker registry hosted in Azure, and then deployed to a Kubernetes cluster, also in Azure.</span></span>

<span data-ttu-id="0b905-113">Die Architektur dieses Workflows umfasst folgende Komponenten:</span><span class="sxs-lookup"><span data-stu-id="0b905-113">The architecture of this workflow includes the following components.</span></span>

- <span data-ttu-id="0b905-114">**[Azure Container Registry:][acr]** Dient zum Speichern der Images für diesen Workflow.</span><span class="sxs-lookup"><span data-stu-id="0b905-114">**[Azure Container Registry][acr]** is used to store the images for this workflow.</span></span> <span data-ttu-id="0b905-115">Mit Container Registry erstellte Registrierungen können über die standardmäßige [Docker-Registrierungs-API (Version 2)][docker] und den entsprechenden Client verwaltet werden.</span><span class="sxs-lookup"><span data-stu-id="0b905-115">Registries created with Container Registry can be managed via the standard [Docker Registry V2 API][docker] and client.</span></span>

- <span data-ttu-id="0b905-116">**[Azure Kubernetes Service:][aks]** Dient zum Hosten der Bereitstellung und des Diensts.</span><span class="sxs-lookup"><span data-stu-id="0b905-116">**[Azure Kubernetes Service][aks]** is used to host the deployment and service.</span></span> <span data-ttu-id="0b905-117">Mit AKS erstellte Cluster können über die standardmäßige [Kubernetes-API][k-api] und den entsprechenden Client (kubectl) verwaltet werden.</span><span class="sxs-lookup"><span data-stu-id="0b905-117">Clusters created with AKS can be managed using the standard [Kubernetes API][k-api] and client (kubectl).</span></span>

- <span data-ttu-id="0b905-118">**[Microsoft Machine Learning Server:][mmls]** Dient zum Definieren der REST-API für den Dienst und enthält die [Modelloperationalisierung][operationalization].</span><span class="sxs-lookup"><span data-stu-id="0b905-118">**[Microsoft Machine Learning Server][mmls]** is used to define the REST API for the service and includes [Model Operationalization][operationalization].</span></span> <span data-ttu-id="0b905-119">Dieser dienstorientierte Webserverprozess lauscht auf Anforderungen, die dann an andere Hintergrundprozesse übergeben werden, die wiederum den eigentlichen R-Code ausführen, um die Ergebnisse zu generieren.</span><span class="sxs-lookup"><span data-stu-id="0b905-119">This service-oriented web server process listens for requests, which are then handed off to other background processes that run the actual R code to generate the results.</span></span> <span data-ttu-id="0b905-120">Bei dieser Konfiguration werden alle hier genannten Prozesse auf einem einzelnen Knoten in einem Container ausgeführt.</span><span class="sxs-lookup"><span data-stu-id="0b905-120">All these processes run on a single node in this configuration, which is wrapped in a container.</span></span> <span data-ttu-id="0b905-121">Ausführliche Informationen zur Verwendung dieses Diensts außerhalb einer Entwicklungs- oder Testumgebung erhalten Sie von Ihrem Ansprechpartner bei Microsoft.</span><span class="sxs-lookup"><span data-stu-id="0b905-121">For details about using this service outside a dev or test environment, contact your Microsoft representative.</span></span>

## <a name="performance-considerations"></a><span data-ttu-id="0b905-122">Überlegungen zur Leistung</span><span class="sxs-lookup"><span data-stu-id="0b905-122">Performance considerations</span></span>

<span data-ttu-id="0b905-123">Machine Learning-Workloads sind häufig mit einem hohen Rechenaufwand verbunden. Das gilt sowohl beim Trainieren als auch beim Bewerten neuer Daten.</span><span class="sxs-lookup"><span data-stu-id="0b905-123">Machine learning workloads tend to be compute-intensive, both when training and when scoring new data.</span></span> <span data-ttu-id="0b905-124">Es wird daher davon abgeraten, mehrere Bewertungsprozesse pro Kern auszuführen.</span><span class="sxs-lookup"><span data-stu-id="0b905-124">As a rule of thumb, try not to run more than one scoring process per core.</span></span> <span data-ttu-id="0b905-125">Mit Machine Learning Server können Sie die Anzahl von R-Prozessen definieren, die in den einzelnen Containern ausgeführt werden können.</span><span class="sxs-lookup"><span data-stu-id="0b905-125">Machine Learning Server lets you define the number of R processes running in each container.</span></span> <span data-ttu-id="0b905-126">Der Wert ist standardmäßig auf fünf Prozesse festgelegt.</span><span class="sxs-lookup"><span data-stu-id="0b905-126">The default is five processes.</span></span> <span data-ttu-id="0b905-127">Wenn Sie ein relativ einfaches Modell (etwa eine lineare Regression mit nur einigen wenigen Variablen) oder eine einfache Entscheidungsstruktur erstellen, können Sie die Prozessanzahl erhöhen.</span><span class="sxs-lookup"><span data-stu-id="0b905-127">When creating a relatively simple model, such as a linear regression with a small number of variables, or a small decision tree, you can increase the number of processes.</span></span> <span data-ttu-id="0b905-128">Überwachen Sie die CPU-Auslastung der Clusterknoten, um einen geeigneten Grenzwert für die Anzahl von Containern zu ermitteln.</span><span class="sxs-lookup"><span data-stu-id="0b905-128">Monitor the CPU load on your cluster nodes to determine the appropriate limit on the number of containers.</span></span>

<span data-ttu-id="0b905-129">Ein GPU-fähiger Cluster kann einige Arten von Workloads beschleunigen. Das gilt insbesondere für Deep Learning-Modelle.</span><span class="sxs-lookup"><span data-stu-id="0b905-129">A GPU-enabled cluster can speed up some types of workloads, and deep learning models in particular.</span></span> <span data-ttu-id="0b905-130">Von GPUs profitieren nur Workloads, die intensiven Gebrauch von Matrixalgebra machen.</span><span class="sxs-lookup"><span data-stu-id="0b905-130">Not all workloads can take advantage of GPUs &mdash; only those that make heavy use of matrix algebra.</span></span> <span data-ttu-id="0b905-131">So entstehen etwa bei strukturbasierten Modellen (einschließlich Random Forests und Boosting-Modelle) in der Regel keine Vorteile durch GPUs.</span><span class="sxs-lookup"><span data-stu-id="0b905-131">For example, tree-based models, including random forests and boosting models, generally derive no advantage from GPUs.</span></span>

<span data-ttu-id="0b905-132">Bestimmte Modelltypen (unter anderem Random Forests) sind auf CPUs hochgradig parallelisierbar.</span><span class="sxs-lookup"><span data-stu-id="0b905-132">Some model types such as random forests are massively parallelizable on CPUs.</span></span> <span data-ttu-id="0b905-133">In diesen Fällen können Sie die Bewertung einer einzelnen Anforderung beschleunigen, indem Sie die Workload auf mehrere Kerne verteilen.</span><span class="sxs-lookup"><span data-stu-id="0b905-133">In these cases, speed up the scoring of a single request by distributing the workload across multiple cores.</span></span> <span data-ttu-id="0b905-134">Dies geht jedoch zulasten Ihrer Verarbeitungskapazität für mehrere Bewertungsanforderungen bei einer festen Clustergröße.</span><span class="sxs-lookup"><span data-stu-id="0b905-134">However, doing so reduces your capacity to handle multiple scoring requests given a fixed cluster size.</span></span>

<span data-ttu-id="0b905-135">Open-Source-basierte R-Modelle speichern in der Regel alle ihre Daten im Arbeitsspeicher. Stellen Sie daher sicher, dass Sie über genügend Arbeitsspeicher für die Prozesse verfügen, die Sie parallel ausführen möchten.</span><span class="sxs-lookup"><span data-stu-id="0b905-135">In general, open-source R models store all their data in memory, so ensure that your nodes have enough memory to accommodate the processes you plan to run concurrently.</span></span> <span data-ttu-id="0b905-136">Wenn Sie Ihre Modelle mithilfe von Machine Learning Server anpassen, verwenden Sie die Bibliotheken, die Daten auf dem Datenträger verarbeiten können, anstatt alle Daten in den Arbeitsspeicher zu lesen.</span><span class="sxs-lookup"><span data-stu-id="0b905-136">If you are using Machine Learning Server to fit your models, use the libraries that can process data on disk, rather than reading it all into memory.</span></span> <span data-ttu-id="0b905-137">Dadurch lässt sich der Arbeitsspeicherbedarf ggf. erheblich senken.</span><span class="sxs-lookup"><span data-stu-id="0b905-137">This can help reduce memory requirements significantly.</span></span> <span data-ttu-id="0b905-138">Überwachen Sie unabhängig von der Verwendung von Machine Learning Server oder Open-Source-R Ihre Knoten, um sicherzustellen, dass Ihren Bewertungsprozessen nicht der Arbeitsspeicher ausgeht.</span><span class="sxs-lookup"><span data-stu-id="0b905-138">Regardless of whether you use Machine Learning Server or open-source R, monitor your nodes to ensure that your scoring processes are not memory-starved.</span></span>

## <a name="security-considerations"></a><span data-ttu-id="0b905-139">Sicherheitshinweise</span><span class="sxs-lookup"><span data-stu-id="0b905-139">Security considerations</span></span>

### <a name="network-encryption"></a><span data-ttu-id="0b905-140">Netzwerkverschlüsselung</span><span class="sxs-lookup"><span data-stu-id="0b905-140">Network encryption</span></span>

<span data-ttu-id="0b905-141">In dieser Referenzarchitektur werden HTTPS für die Kommunikation mit dem Cluster und ein Bereitstellungszertifikat von [Let's Encrypt][encrypt] verwendet.</span><span class="sxs-lookup"><span data-stu-id="0b905-141">In this reference architecture, HTTPS is enabled for communication with the cluster, and a staging certificate from [Let’s Encrypt][encrypt] is used.</span></span> <span data-ttu-id="0b905-142">Verwenden Sie in einer Produktionsumgebung ein eigenes Zertifikat von einer geeigneten Signaturstelle.</span><span class="sxs-lookup"><span data-stu-id="0b905-142">For production purposes, substitute your own certificate from an appropriate signing authority.</span></span>

### <a name="authentication-and-authorization"></a><span data-ttu-id="0b905-143">Authentifizierung und Autorisierung</span><span class="sxs-lookup"><span data-stu-id="0b905-143">Authentication and authorization</span></span>

<span data-ttu-id="0b905-144">Die [Modelloperationalisierung][operationalization] von Machine Learning Server erfordert eine Authentifizierung von Bewertungsanforderungen.</span><span class="sxs-lookup"><span data-stu-id="0b905-144">Machine Learning Server [Model Operationalization][operationalization] requires scoring requests to be authenticated.</span></span> <span data-ttu-id="0b905-145">In dieser Bereitstellung werden ein Benutzername und ein Kennwort verwendet.</span><span class="sxs-lookup"><span data-stu-id="0b905-145">In this deployment, a username and password are used.</span></span> <span data-ttu-id="0b905-146">In einer Unternehmensumgebung können Sie die Authentifizierung über [Azure Active Directory][AAD] ermöglichen oder unter Verwendung von [Azure API Management][API] ein separates Front-End erstellen.</span><span class="sxs-lookup"><span data-stu-id="0b905-146">In an enterprise setting, you can enable authentication using [Azure Active Directory][AAD] or create a separate front end using [Azure API Management][API].</span></span>

<span data-ttu-id="0b905-147">Damit die Modelloperationalisierung mit Machine Learning Server in Containern ordnungsgemäß funktioniert, muss ein JWT-Zertifikat (JSON Web Token) installiert werden.</span><span class="sxs-lookup"><span data-stu-id="0b905-147">For Model Operationalization to work correctly with Machine Learning Server on containers, you must install a JSON Web Token (JWT) certificate.</span></span> <span data-ttu-id="0b905-148">In dieser Bereitstellung wird ein von Microsoft bereitgestelltes Zertifikat verwendet.</span><span class="sxs-lookup"><span data-stu-id="0b905-148">This deployment uses a certificate supplied by Microsoft.</span></span> <span data-ttu-id="0b905-149">In einer Produktionsumgebung muss ein eigenes Zertifikat verwendet werden.</span><span class="sxs-lookup"><span data-stu-id="0b905-149">In a production setting, supply your own.</span></span>

<span data-ttu-id="0b905-150">Für den Datenverkehr zwischen Container Registry und AKS empfiehlt sich ggf. die Aktivierung der [rollenbasierten Zugriffssteuerung][rbac] (role-based access control, RBAC), um Zugriffsrechte auf ein Mindestmaß zu beschränken.</span><span class="sxs-lookup"><span data-stu-id="0b905-150">For traffic between Container Registry and AKS, consider enabling [role-based access control][rbac] (RBAC) to limit access privileges to only those needed.</span></span>

### <a name="separate-storage"></a><span data-ttu-id="0b905-151">Trennen des Speichers</span><span class="sxs-lookup"><span data-stu-id="0b905-151">Separate storage</span></span>

<span data-ttu-id="0b905-152">Bei dieser Referenzarchitektur werden die Anwendung (R) und die Daten (Modellobjekt und Bewertungsskript) in einem einzelnen Image gebündelt.</span><span class="sxs-lookup"><span data-stu-id="0b905-152">This reference architecture bundles the application (R) and the data (model object and scoring script) into a single image.</span></span> <span data-ttu-id="0b905-153">Manchmal kann es jedoch von Vorteil sein, diese Komponenten zu trennen.</span><span class="sxs-lookup"><span data-stu-id="0b905-153">In some cases, it may be beneficial to separate these.</span></span> <span data-ttu-id="0b905-154">Sie können die Modelldaten und den Code in [Azure Storage][storage] (Blob- oder Dateispeicher) platzieren und bei der Containerinitialisierung abrufen.</span><span class="sxs-lookup"><span data-stu-id="0b905-154">You can place the model data and code into Azure blob or file [storage][storage], and retrieve them at container initialization.</span></span> <span data-ttu-id="0b905-155">In diesem Fall muss das Speicherkonto so konfiguriert sein, dass nur authentifizierte Zugriffe zulässig sind und HTTPS verwendet werden muss.</span><span class="sxs-lookup"><span data-stu-id="0b905-155">In this case, ensure that the storage account is set to allow authenticated access only and require HTTPS.</span></span>

## <a name="monitoring-and-logging-considerations"></a><span data-ttu-id="0b905-156">Überlegungen zur Überwachung und Protokollierung</span><span class="sxs-lookup"><span data-stu-id="0b905-156">Monitoring and logging considerations</span></span>

<span data-ttu-id="0b905-157">Verwenden Sie zur Überwachung des Gesamtstatus Ihres AKS-Clusters das [Kubernetes-Dashboard][dashboard].</span><span class="sxs-lookup"><span data-stu-id="0b905-157">Use the [Kubernetes dashboard][dashboard] to monitor the overall status of your AKS cluster.</span></span> <span data-ttu-id="0b905-158">Ausführlichere Informationen finden Sie im Azure-Portal auf dem Übersichtsblatt des Clusters.</span><span class="sxs-lookup"><span data-stu-id="0b905-158">See the cluster’s overview blade in Azure portal for more details.</span></span> <span data-ttu-id="0b905-159">In den [GitHub][github]-Ressourcen erfahren Sie auch, wie Sie das Dashboard über R aufrufen.</span><span class="sxs-lookup"><span data-stu-id="0b905-159">The [GitHub][github] resources also show how to bring up the dashboard from R.</span></span>

<span data-ttu-id="0b905-160">Das Dashboard gibt zwar Aufschluss über die allgemeine Integrität Ihres Clusters, es ist aber auch wichtig, den Status einzelner Container nachzuverfolgen.</span><span class="sxs-lookup"><span data-stu-id="0b905-160">Although the dashboard gives you a view of the overall health of your cluster, it’s also important to track the status of individual containers.</span></span> <span data-ttu-id="0b905-161">Aktivieren Sie hierzu im Azure-Portal auf dem Übersichtsblatt des Clusters das Feature [Azure Monitor Insights][monitor], oder lesen Sie [Azure Monitor für Container (Vorschau) – Übersicht][monitor-containers].</span><span class="sxs-lookup"><span data-stu-id="0b905-161">To do this, enable [Azure Monitor Insights][monitor] from the cluster overview blade in Azure portal, or see [Azure Monitor for containers][monitor-containers] (in preview).</span></span>

## <a name="cost-considerations"></a><span data-ttu-id="0b905-162">Kostenbetrachtung</span><span class="sxs-lookup"><span data-stu-id="0b905-162">Cost considerations</span></span>

<span data-ttu-id="0b905-163">Die Lizenzierung von Machine Learning Server ist kernbasiert. Dabei werden alle Kerne im Cluster berücksichtigt, auf denen Machine Learning Server ausgeführt wird.</span><span class="sxs-lookup"><span data-stu-id="0b905-163">Machine Learning Server is licensed on a per-core basis, and all the cores in the cluster that will run Machine Learning  Server count towards this.</span></span> <span data-ttu-id="0b905-164">Wenden Sie sich als Unternehmenskunde mit Machine Learning Server oder Microsoft SQL Server an Ihren Ansprechpartner bei Microsoft, um Preisinformationen zu erhalten.</span><span class="sxs-lookup"><span data-stu-id="0b905-164">If you are an enterprise Machine Learning Server or Microsoft SQL Server customer, contact your Microsoft representative for pricing details.</span></span>

<span data-ttu-id="0b905-165">Eine Open-Source-Alternative zu Machine Learning Server ist [Plumber][plumber]. Dabei handelt es sich um ein R-Paket, das Ihren Code in eine REST-API verwandelt.</span><span class="sxs-lookup"><span data-stu-id="0b905-165">An open-source alternative to Machine Learning Server is [Plumber][plumber], an R package that turns your code into a REST API.</span></span> <span data-ttu-id="0b905-166">Plumber bietet weniger Features als Machine Learning Server.</span><span class="sxs-lookup"><span data-stu-id="0b905-166">Plumber is less fully featured than Machine Learning Server.</span></span> <span data-ttu-id="0b905-167">So stehen standardmäßig beispielweise keine Features für die Anforderungsauthentifizierung zur Verfügung.</span><span class="sxs-lookup"><span data-stu-id="0b905-167">For example, by default it doesn't include any features that provide request authentication.</span></span> <span data-ttu-id="0b905-168">Bei Verwendung von Plumber empfiehlt es sich, [Azure API Management][API] für die Authentifizierung zu aktivieren.</span><span class="sxs-lookup"><span data-stu-id="0b905-168">If you use Plumber, it’s recommended that you enable [Azure API Management][API] to handle authentication details.</span></span>

<span data-ttu-id="0b905-169">Für die Kosten sind neben der Lizenzierung insbesondere die Computeressourcen des Kubernetes-Clusters relevant.</span><span class="sxs-lookup"><span data-stu-id="0b905-169">Besides licensing, the main cost consideration is the Kubernetes cluster's compute resources.</span></span> <span data-ttu-id="0b905-170">Der Cluster muss groß genug sein, um das zu Spitzenzeiten erwartete Anforderungsvolumen bewältigen zu können. Das führt jedoch dazu, dass sich Ressourcen außerhalb von Spitzenzeiten im Leerlauf befinden.</span><span class="sxs-lookup"><span data-stu-id="0b905-170">The cluster must be large enough to handle the expected request volume at peak times, but this approach leaves resources idle at other times.</span></span> <span data-ttu-id="0b905-171">Aktivieren Sie mithilfe des kubectl-Tools die [automatische horizontale Skalierung][autoscaler] für den Cluster, um die Auswirkungen von Ressourcen im Leerlauf zu verringern.</span><span class="sxs-lookup"><span data-stu-id="0b905-171">To limit the impact of idle resources, enable the [horizontal autoscaler][autoscaler] for the cluster using the kubectl tool.</span></span> <span data-ttu-id="0b905-172">Alternativ können Sie auch die [automatische Clusterskalierung][cluster-autoscaler] von AKS verwenden.</span><span class="sxs-lookup"><span data-stu-id="0b905-172">Or use the AKS [cluster autoscaler][cluster-autoscaler].</span></span>

## <a name="deploy-the-solution"></a><span data-ttu-id="0b905-173">Bereitstellen der Lösung</span><span class="sxs-lookup"><span data-stu-id="0b905-173">Deploy the solution</span></span>

<span data-ttu-id="0b905-174">Die Referenzimplementierung dieser Architektur ist auf [GitHub][github] verfügbar.</span><span class="sxs-lookup"><span data-stu-id="0b905-174">The reference implementation of this architecture is available on [GitHub][github].</span></span> <span data-ttu-id="0b905-175">Gehen Sie wie dort beschrieben vor, um ein einfaches Prognosemodell als Dienst bereitzustellen.</span><span class="sxs-lookup"><span data-stu-id="0b905-175">Follow the steps described there to deploy a simple predictive model as a service.</span></span>

<!-- links -->
[AAD]: /azure/active-directory/fundamentals/active-directory-whatis
[API]: /azure/api-management/api-management-key-concepts
[ACR]: /azure/container-registry/container-registry-intro
[AKS]: /azure/aks/intro-kubernetes
[autoscaler]: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/
[cluster-autoscaler]: /azure/aks/autoscaler
[monitor]: /azure/monitoring/monitoring-container-insights-overview
[dashboard]: /azure/aks/kubernetes-dashboard
[docker]: https://docs.docker.com/registry/spec/api/
[encrypt]: https://letsencrypt.org/
[gitHub]: https://github.com/Azure/RealtimeRDeployment
[K-API]: https://kubernetes.io/docs/reference/
[MMLS]: /machine-learning-server/what-is-machine-learning-server
[monitor-containers]: /azure/azure-monitor/insights/container-insights-overview
[operationalization]: /machine-learning-server/what-is-operationalization
[plumber]: https://www.rplumber.io
[RBAC]: /azure/role-based-access-control/overview
[storage]: /azure/storage/common/storage-introduction
[0]: ./_images/realtime-scoring-r.png
