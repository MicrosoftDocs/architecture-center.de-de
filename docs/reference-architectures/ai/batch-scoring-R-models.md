---
title: Batchbewertung mit R-Modellen in Azure
description: Führen Sie die Batchbewertung mit R-Modellen mit Azure Batch und einem Dataset durch, das auf Einzelhandelsverkaufs-Prognosen basiert.
author: njray
ms.date: 03/29/2019
ms.topic: reference-architecture
ms.service: architecture-center
ms.subservice: reference-architecture
ms.custom: azcat-ai
ms.openlocfilehash: 4fa57168c337b01c8e7d0fc86ba54fee59a7ae47
ms.sourcegitcommit: 1a3cc91530d56731029ea091db1f15d41ac056af
ms.translationtype: HT
ms.contentlocale: de-DE
ms.lasthandoff: 04/03/2019
ms.locfileid: "58887872"
---
# <a name="batch-scoring-of-r-machine-learning-models-on-azure"></a><span data-ttu-id="65424-103">Batchbewertung von R-Machine Learning-Modellen in Azure</span><span class="sxs-lookup"><span data-stu-id="65424-103">Batch scoring of R machine learning models on Azure</span></span>

<span data-ttu-id="65424-104">Diese Referenzarchitektur zeigt, wie Sie die Batchbewertung mit R-Modellen mit Azure Batch ausführen.</span><span class="sxs-lookup"><span data-stu-id="65424-104">This reference architecture shows how to perform batch scoring with R models using Azure Batch.</span></span> <span data-ttu-id="65424-105">Das Szenario basiert auf Einzelhandelsverkaufs-Prognosen, aber diese Architektur kann für jedes Szenario verallgemeinert werden, das die Generierung von Vorhersagen auf einem großen Scaler mithilfe von R-Modellen erfordert.</span><span class="sxs-lookup"><span data-stu-id="65424-105">The scenario is based on retail store sales forecasting, but this architecture can be generalized for any scenario requiring the generation of predictions on a large scaler using R models.</span></span> <span data-ttu-id="65424-106">Eine Referenzimplementierung für diese Architektur ist auf [GitHub][github] verfügbar.</span><span class="sxs-lookup"><span data-stu-id="65424-106">A reference implementation for this architecture is available on [GitHub][github].</span></span>

![Architekturdiagramm][0]

<span data-ttu-id="65424-108">**Szenario:** Eine Supermarktkette muss Produktverkäufe für das bevorstehende Quartal prognostizieren.</span><span class="sxs-lookup"><span data-stu-id="65424-108">**Scenario**: A supermarket chain needs to forecast sales of products over the upcoming quarter.</span></span> <span data-ttu-id="65424-109">Die Vorhersage ermöglicht dem Unternehmen, seine Lieferkette besser zu verwalten und sicherzustellen, die Nachfrage nach Produkten in allen Filialen zu erfüllen.</span><span class="sxs-lookup"><span data-stu-id="65424-109">The forecast allows the company to manage its supply chain better and ensure it can meet demand for products at each of its stores.</span></span> <span data-ttu-id="65424-110">Das Unternehmen aktualisiert seine Prognosen jede Woche, wenn neue Verkaufsdaten aus der vorherigen Woche verfügbar sind und die Produktmarketingstrategie für das nächste Quartal festgelegt ist.</span><span class="sxs-lookup"><span data-stu-id="65424-110">The company updates its forecasts every week as new sales data from the previous week becomes available and the product marketing strategy for next quarter is set.</span></span> <span data-ttu-id="65424-111">Quantilvorhersagen werden generiert, um die Ungewissheit bei einzelnen Umsatzprognosen einzuschätzen.</span><span class="sxs-lookup"><span data-stu-id="65424-111">Quantile forecasts are generated to estimate the uncertainty of the individual sales forecasts.</span></span>

<span data-ttu-id="65424-112">Die Verarbeitung umfasst die folgenden Schritte:</span><span class="sxs-lookup"><span data-stu-id="65424-112">Processing involves the following steps:</span></span>

1. <span data-ttu-id="65424-113">Eine Azure-Logik-App löst einmal pro Woche die Vorhersagengenerierung aus.</span><span class="sxs-lookup"><span data-stu-id="65424-113">An Azure Logic App triggers the forecast generation process once per week.</span></span>

1. <span data-ttu-id="65424-114">Die Logik-App startet eine Azure-Containerinstanz, auf der der Planer-Docker-Container ausgeführt wird, der die Bewertungsaufträge im Batch-Cluster startet.</span><span class="sxs-lookup"><span data-stu-id="65424-114">The logic app starts an Azure Container Instance running the scheduler Docker container, which triggers the scoring jobs on the Batch cluster.</span></span>

1. <span data-ttu-id="65424-115">Bewertungsaufträge werden parallel die Knoten des Clusters übergreifend ausgeführt.</span><span class="sxs-lookup"><span data-stu-id="65424-115">Scoring jobs run in parallel across the nodes of the Batch cluster.</span></span> <span data-ttu-id="65424-116">Jeder Knoten:</span><span class="sxs-lookup"><span data-stu-id="65424-116">Each node:</span></span>

    1. <span data-ttu-id="65424-117">Ruft das Worker-Docker-Image aus Docker Hub ab und startet einen Container.</span><span class="sxs-lookup"><span data-stu-id="65424-117">Pulls the worker Docker image from Docker Hub and starts a container.</span></span>

    1. <span data-ttu-id="65424-118">Liest die Eingabedaten und vortrainierten R-Modelle aus Azure Blob Storage.</span><span class="sxs-lookup"><span data-stu-id="65424-118">Reads input data and pre-trained R models from Azure Blob storage.</span></span>

    1. <span data-ttu-id="65424-119">Bewertet die Daten, um die Prognosen zu erstellen.</span><span class="sxs-lookup"><span data-stu-id="65424-119">Scores the data to produce the forecasts.</span></span>

    1. <span data-ttu-id="65424-120">Schreibt die Prognoseergebnisse in Blob Storage.</span><span class="sxs-lookup"><span data-stu-id="65424-120">Writes the forecast results to blob storage.</span></span>

<span data-ttu-id="65424-121">Die folgende Abbildung zeigt die vorhergesagten Verkäufe für vier Produkte (SKUs) in einer Filiale.</span><span class="sxs-lookup"><span data-stu-id="65424-121">The figure below shows the forecasted sales for four products (SKUs) in one store.</span></span> <span data-ttu-id="65424-122">Die schwarze Linie ist der Umsatzverlauf, die gestrichelte Linie ist die Medianvorhersage (q50), das rosa Band stellt das 25. und 75. Quantil dar und das blaue Band das fünfte und 95. Quantil.</span><span class="sxs-lookup"><span data-stu-id="65424-122">The black line is the sales history, the dashed line is the median (q50) forecast, the pink band represents the twenty-fifth and seventy-fifth percentiles, and the blue band represents the fifth and ninety-fifth percentiles.</span></span>

![Verkaufsprognosen][1]

## <a name="architecture"></a><span data-ttu-id="65424-124">Architecture</span><span class="sxs-lookup"><span data-stu-id="65424-124">Architecture</span></span>

<span data-ttu-id="65424-125">Diese Architektur umfasst die folgenden Komponenten.</span><span class="sxs-lookup"><span data-stu-id="65424-125">This architecture consists of the following components.</span></span>

<span data-ttu-id="65424-126">[Azure Batch][batch] wird verwendet, um Aufträge zur Vorhersagengenerierung parallel auf einem Cluster von virtuellen Computern auszuführen.</span><span class="sxs-lookup"><span data-stu-id="65424-126">[Azure Batch][batch] is used to run forecast generation jobs in parallel on a cluster of virtual machines.</span></span> <span data-ttu-id="65424-127">Vorhersagen werden mithilfe vorab trainierter Machine Learning-Modelle getroffen, die in R implementiert sind. Azure Batch kann die Anzahl der VMs basierend auf der Anzahl der Aufträge, die an den Cluster übermittelt werden, automatisch skalieren.</span><span class="sxs-lookup"><span data-stu-id="65424-127">Predictions are made using pre-trained machine learning models implemented in R. Azure Batch can automatically scale the number of VMs based on the number of jobs submitted to the cluster.</span></span> <span data-ttu-id="65424-128">Auf jedem Knoten wird ein R-Skript zum Bewerten von Daten und Generieren von Vorhersagen in einem Docker-Container ausgeführt.</span><span class="sxs-lookup"><span data-stu-id="65424-128">On each node, an R script runs within a Docker container to score data and generate forecasts.</span></span>

<span data-ttu-id="65424-129">[Azure Blob Storage][blob] wird zum Speichern der Eingabedaten, der vorab trainierten Machine Learning-Modelle und der Prognoseergebnisse verwendet.</span><span class="sxs-lookup"><span data-stu-id="65424-129">[Azure Blob Storage][blob] is used to store the input data, the pre-trained machine learning models, and the forecast results.</span></span> <span data-ttu-id="65424-130">Blob Storage bietet sehr kostengünstigen Speicher für die Leistung, die diese Workload erfordert.</span><span class="sxs-lookup"><span data-stu-id="65424-130">It delivers very cost-effective storage for the performance that this workload requires.</span></span>

<span data-ttu-id="65424-131">[Azure Container Instances][aci] ermöglicht serverloses Compute nach Bedarf.</span><span class="sxs-lookup"><span data-stu-id="65424-131">[Azure Container Instances][aci] provide serverless compute on demand.</span></span> <span data-ttu-id="65424-132">In diesem Fall wird eine Containerinstanz nach einem Zeitplan bereitgestellt, um Batchaufträge auszulösen, die die Prognosen generieren.</span><span class="sxs-lookup"><span data-stu-id="65424-132">In this case, a container instance is deployed on a schedule to trigger the Batch jobs that generate the forecasts.</span></span> <span data-ttu-id="65424-133">Die Batchaufträge werden von einem R-Skript unter Verwendung des [DoAzureParallel][doAzureParallel]-Pakets ausgelöst.</span><span class="sxs-lookup"><span data-stu-id="65424-133">The Batch jobs are triggered from an R script using the [doAzureParallel][doAzureParallel] package.</span></span> <span data-ttu-id="65424-134">Die Containerinstanz wird automatisch beendet, sobald die Aufträge abgeschlossen sind.</span><span class="sxs-lookup"><span data-stu-id="65424-134">The container instance automatically shuts down once the jobs have finished.</span></span>

<span data-ttu-id="65424-135">[Azure Logic Apps][logic-apps] löst den gesamten Workflow durch Bereitstellung der Containerinstanzen nach einem Zeitplan aus.</span><span class="sxs-lookup"><span data-stu-id="65424-135">[Azure Logic Apps][logic-apps] trigger the entire workflow by deploying the container instances on a schedule.</span></span> <span data-ttu-id="65424-136">Ein Azure Container Instances-Connector in Logic Apps ermöglicht, dass eine Instanz bei einer Reihe von Auslöseereignissen bereitgestellt werden kann.</span><span class="sxs-lookup"><span data-stu-id="65424-136">An Azure Container Instances connector in Logic Apps allows an instance to be deployed upon a range of trigger events.</span></span>

## <a name="performance-considerations"></a><span data-ttu-id="65424-137">Überlegungen zur Leistung</span><span class="sxs-lookup"><span data-stu-id="65424-137">Performance considerations</span></span>

### <a name="containerized-deployment"></a><span data-ttu-id="65424-138">Containerbereitstellung</span><span class="sxs-lookup"><span data-stu-id="65424-138">Containerized deployment</span></span>

<span data-ttu-id="65424-139">Bei dieser Architektur werden alle R-Skripts in [Docker](https://www.docker.com/)-Containern ausgeführt.</span><span class="sxs-lookup"><span data-stu-id="65424-139">With this architecture, all R scripts run within [Docker](https://www.docker.com/) containers.</span></span> <span data-ttu-id="65424-140">Dadurch wird sichergestellt, dass die Skripts jedes Mal in einer konsistenten Umgebung, mit der gleichen R-Version und den gleichen Paketversionen ausgeführt werden.</span><span class="sxs-lookup"><span data-stu-id="65424-140">This ensures that the scripts run in a consistent environment, with the same R version and packages versions, every time.</span></span> <span data-ttu-id="65424-141">Für den Planer- und Worker-Container werden separate Docker-Images verwendet, da jeder einen anderen Satz von R-Paketabhängigkeiten hat.</span><span class="sxs-lookup"><span data-stu-id="65424-141">Separate Docker images are used for the scheduler and worker containers, because each has a different set of R package dependencies.</span></span>

<span data-ttu-id="65424-142">Azure Container Instances bietet eine serverlose Umgebung zum Ausführen des Planer-Containers.</span><span class="sxs-lookup"><span data-stu-id="65424-142">Azure Container Instances provides a serverless environment to run the scheduler container.</span></span> <span data-ttu-id="65424-143">Der Planer-Container führt ein R-Skript aus, das die einzelnen in einem Azure Batch-Cluster ausgeführten Bewertungsaufträge auslöst.</span><span class="sxs-lookup"><span data-stu-id="65424-143">The scheduler container runs an R script that triggers the individual scoring jobs running on an Azure Batch cluster.</span></span>

<span data-ttu-id="65424-144">Jeder Knoten des Batch-Clusters führt den Worker-Container aus, der das Bewertungsskript ausführt.</span><span class="sxs-lookup"><span data-stu-id="65424-144">Each node of the Batch cluster runs the worker container, which executes the scoring script.</span></span>

### <a name="parallelizing-the-workload"></a><span data-ttu-id="65424-145">Parallelisierung der Workload</span><span class="sxs-lookup"><span data-stu-id="65424-145">Parallelizing the workload</span></span>

<span data-ttu-id="65424-146">Erwägen Sie bei der Batchbewertung von Daten mit R-Modellen, wie Sie die Workload parallelisieren.</span><span class="sxs-lookup"><span data-stu-id="65424-146">When batch scoring data with R models, consider how to parallelize the workload.</span></span> <span data-ttu-id="65424-147">Die Eingabedaten müssen irgendwie partitioniert werden, damit der Bewertungsvorgang auf die Clusterknoten verteilt werden kann.</span><span class="sxs-lookup"><span data-stu-id="65424-147">The input data must be partitioned somehow so that the scoring operation can be distributed  across the cluster nodes.</span></span> <span data-ttu-id="65424-148">Probieren Sie unterschiedliche Ansätze aus, um die beste Wahl für die Verteilung Ihrer Workload zu ermitteln.</span><span class="sxs-lookup"><span data-stu-id="65424-148">Try different approaches to discover the best choice for distributing your workload.</span></span> <span data-ttu-id="65424-149">Berücksichtigen Sie auf Fall-zu-Fall-Basis Folgendes:</span><span class="sxs-lookup"><span data-stu-id="65424-149">On a case-by-case basis, consider the following:</span></span>

- <span data-ttu-id="65424-150">Wie viele Daten in den Arbeitsspeicher eines einzelnen Knotens geladen und dort verarbeitet werden können.</span><span class="sxs-lookup"><span data-stu-id="65424-150">How much data can be loaded and processed in the memory of a single node.</span></span>
- <span data-ttu-id="65424-151">Den Mehraufwand, jeden einzelnen Batchauftrag zu starten.</span><span class="sxs-lookup"><span data-stu-id="65424-151">The overhead of starting each batch job.</span></span>
- <span data-ttu-id="65424-152">Den Mehraufwand, die R-Modelle zu laden.</span><span class="sxs-lookup"><span data-stu-id="65424-152">The overhead of loading the R models.</span></span>

<span data-ttu-id="65424-153">In dem für dieses Beispiel verwendeten Szenario sind die Modellobjekte umfangreich, und es dauert nur wenige Sekunden, um eine Vorhersage für die einzelnen Produkte zu generieren.</span><span class="sxs-lookup"><span data-stu-id="65424-153">In the scenario used for this example, the model objects are large, and it takes only a few seconds to generate a forecast for individual products.</span></span> <span data-ttu-id="65424-154">Aus diesem Grund können Sie die Produkte gruppieren und einen einzelnen Batchauftrag pro Knoten ausführen.</span><span class="sxs-lookup"><span data-stu-id="65424-154">For this reason, you can group the products and execute a single Batch job per node.</span></span> <span data-ttu-id="65424-155">Eine Schleife innerhalb jedes Auftrags generiert sequenziell Vorhersagen für die Produkte.</span><span class="sxs-lookup"><span data-stu-id="65424-155">A loop within each job generates forecasts for the products sequentially.</span></span> <span data-ttu-id="65424-156">Es zeigt sich, dass diese bestimmte Workload mit dieser Methode am effizientesten parallelisiert werden kann.</span><span class="sxs-lookup"><span data-stu-id="65424-156">This method turns out to be the most efficient way to parallelize this particular workload.</span></span> <span data-ttu-id="65424-157">Sie vermeidet den zusätzlichen Aufwand, viele kleinere Batchaufträge zu starten und die R-Modelle wiederholt zu laden.</span><span class="sxs-lookup"><span data-stu-id="65424-157">It avoids the overhead of starting many smaller Batch jobs and repeatedly loading the R models.</span></span>

<span data-ttu-id="65424-158">Ein alternativer Ansatz ist, einen Batchauftrag pro Produkt auszulösen.</span><span class="sxs-lookup"><span data-stu-id="65424-158">An alternative approach is to trigger one Batch job per product.</span></span> <span data-ttu-id="65424-159">Azure Batch bildet automatisch eine Warteschlange mit Aufträgen und übermittelt sie zur Ausführung an den Cluster, sobald Knoten verfügbar sind.</span><span class="sxs-lookup"><span data-stu-id="65424-159">Azure Batch automatically forms a queue of jobs and submits them to be executed on the cluster as nodes become available.</span></span> <span data-ttu-id="65424-160">Passen Sie mit der [automatischen Skalierung][autoscale] die Anzahl der Knoten im Cluster der Anzahl der Aufträge an.</span><span class="sxs-lookup"><span data-stu-id="65424-160">Use [automatic scaling][autoscale] to adjust the number of nodes in the cluster depending on the number of jobs.</span></span> <span data-ttu-id="65424-161">Dieser Ansatz ergibt mehr Sinn, wenn es relativ lange dauert, jeden Bewertungsvorgang auszuführen, sodass der Aufwand, die Aufträge zu starten und die Modellobjekte erneut zu laden, gerechtfertigt ist.</span><span class="sxs-lookup"><span data-stu-id="65424-161">This approach makes more sense if it takes a relatively long time to complete each scoring operation, justifying the overhead of starting the jobs and reloading the model objects.</span></span> <span data-ttu-id="65424-162">Dieser Ansatz ist auch einfacher zu implementieren und bietet Ihnen die Flexibilität, die automatische Skalierung zu verwenden – ein wichtiger Aspekt, wenn die Größe der gesamten Workload im Voraus nicht bekannt ist.</span><span class="sxs-lookup"><span data-stu-id="65424-162">This approach is also simpler to implement and gives you the flexibility to use automatic scaling—an important consideration if the size of the total workload is not known in advance.</span></span>

## <a name="monitoring-and-logging-considerations"></a><span data-ttu-id="65424-163">Überlegungen zur Überwachung und Protokollierung</span><span class="sxs-lookup"><span data-stu-id="65424-163">Monitoring and logging considerations</span></span>

### <a name="monitoring-azure-batch-jobs"></a><span data-ttu-id="65424-164">Überwachen von Azure Batch-Aufträgen</span><span class="sxs-lookup"><span data-stu-id="65424-164">Monitoring Azure Batch jobs</span></span>

<span data-ttu-id="65424-165">Überwachen und beenden Sie Batchaufträge vom Bereich **Aufträge** des Batchkontos im Azure-Portal aus.</span><span class="sxs-lookup"><span data-stu-id="65424-165">Monitor and terminate Batch jobs from the **Jobs** pane of the Batch account in the Azure portal.</span></span> <span data-ttu-id="65424-166">Überwachen Sie den Batchcluster einschließlich des Status der einzelnen Knoten vom Bereich **Pools** aus.</span><span class="sxs-lookup"><span data-stu-id="65424-166">Monitor the batch cluster, including the state of individual nodes, from the **Pools** pane.</span></span>

### <a name="logging-with-doazureparallel"></a><span data-ttu-id="65424-167">Protokollierung mit doAzureParallel</span><span class="sxs-lookup"><span data-stu-id="65424-167">Logging with doAzureParallel</span></span>

<span data-ttu-id="65424-168">Das doAzureParallel-Paket erfasst automatisch Protokolle aller stdout-/stderr-Vorgänge für jeden an Azure Batch übermittelten Auftrag.</span><span class="sxs-lookup"><span data-stu-id="65424-168">The doAzureParallel package automatically collects logs of all stdout/stderr for every job submitted on Azure Batch.</span></span> <span data-ttu-id="65424-169">Diese Protokolle finden Sie im beim Setup erstellten Speicherkonto.</span><span class="sxs-lookup"><span data-stu-id="65424-169">These can be found in the storage account created at setup.</span></span> <span data-ttu-id="65424-170">Verwenden Sie zu ihrer Anzeige ein Speichernavigationstool wie z.B. den [Azure Storage-Explorer][storage-explorer] oder das Azure-Portal.</span><span class="sxs-lookup"><span data-stu-id="65424-170">To view them, use a storage navigation tool such as [Azure Storage Explorer][storage-explorer] or Azure portal.</span></span>

<span data-ttu-id="65424-171">Um Batchaufträge während der Entwicklung schnell zu debuggen, drucken Sie Protokolle in Ihrer lokalen R-Sitzung mit der [getJobFiles][getJobFiles]-Funktion von doAzureParallel aus.</span><span class="sxs-lookup"><span data-stu-id="65424-171">To quickly debug Batch jobs during development, print logs in your local R session using the [getJobFiles][getJobFiles] function of doAzureParallel.</span></span>

## <a name="cost-considerations"></a><span data-ttu-id="65424-172">Kostenbetrachtung</span><span class="sxs-lookup"><span data-stu-id="65424-172">Cost considerations</span></span>

<span data-ttu-id="65424-173">Die in dieser Referenzarchitektur genutzten Computeressourcen sind die teuersten Komponenten.</span><span class="sxs-lookup"><span data-stu-id="65424-173">The compute resources used in this reference architecture are the most costly components.</span></span> <span data-ttu-id="65424-174">Für dieses Szenario wird ein Cluster mit fester Größe erstellt, wenn der Auftrag ausgelöst wird, und dann nach Abschluss des Auftrags heruntergefahren.</span><span class="sxs-lookup"><span data-stu-id="65424-174">For this scenario, a cluster of fixed size is created whenever the job is triggered and then shut down after the job has completed.</span></span> <span data-ttu-id="65424-175">Kosten fallen nur an, während die Clusterknoten gestartet, ausgeführt oder heruntergefahren werden.</span><span class="sxs-lookup"><span data-stu-id="65424-175">Cost is incurred only while the cluster nodes are starting, running, or shutting down.</span></span> <span data-ttu-id="65424-176">Dieser Ansatz eignet sich für ein Szenario, in dem die zum Generieren der Vorhersagen benötigten Computeressourcen von Job zu Job relativ konstant bleiben.</span><span class="sxs-lookup"><span data-stu-id="65424-176">This approach is suitable for a scenario where the compute resources required to generate the forecasts remain relatively constant from job to job.</span></span>

<span data-ttu-id="65424-177">In Szenarien, in denen die zum Ausführen des Auftrags erforderliche Computekapazität nicht im Voraus bekannt ist, kann es sinnvoller sein, die automatische Skalierung zu verwenden.</span><span class="sxs-lookup"><span data-stu-id="65424-177">In scenarios where the amount of compute required to complete the job is not known in advance, it may be more suitable to use automatic scaling.</span></span> <span data-ttu-id="65424-178">Bei diesem Ansatz wird die Größe des Clusters abhängig von der Größe des Auftrags nach oben oder unten skaliert.</span><span class="sxs-lookup"><span data-stu-id="65424-178">With this approach, the size of the cluster is scaled up or down depending on the size of the job.</span></span> <span data-ttu-id="65424-179">Azure Batch unterstützt eine Reihe von Formeln für die automatische Skalierung, die Sie festlegen können, wenn Sie den Cluster mit der [doAzureParallel][doAzureParallel]-API definieren.</span><span class="sxs-lookup"><span data-stu-id="65424-179">Azure Batch supports a range of auto-scale formulae which you can set when defining the cluster using the [doAzureParallel][doAzureParallel] API.</span></span>

<span data-ttu-id="65424-180">Für einige Szenarien ist die Zeit zwischen Aufträgen möglicherweise zu kurz, um den Cluster herunterzufahren und wieder zu starten.</span><span class="sxs-lookup"><span data-stu-id="65424-180">For some scenarios, the time between jobs may be too short to shut down and start up the cluster.</span></span> <span data-ttu-id="65424-181">Behalten Sie in diesen Fällen die Ausführung des Clusters zwischen Aufträgen nach Möglichkeit bei.</span><span class="sxs-lookup"><span data-stu-id="65424-181">In these cases, keep the cluster running between jobs if appropriate.</span></span>

<span data-ttu-id="65424-182">Azure Batch und doAzureParallel unterstützen die Verwendung von VMs mit niedriger Priorität.</span><span class="sxs-lookup"><span data-stu-id="65424-182">Azure Batch and doAzureParallel support the use of low-priority VMs.</span></span> <span data-ttu-id="65424-183">Diese virtuellen Computer bieten einen erheblichen Rabatt, doch besteht das Risiko, das andere Workloads mit höherer Priorität sich diese VMs aneignen.</span><span class="sxs-lookup"><span data-stu-id="65424-183">These VMs come with a significant discount but risk being appropriated by other higher priority workloads.</span></span> <span data-ttu-id="65424-184">Die Verwendung dieser virtuellen Computer ist daher für entscheidende Produktionsworkloads nicht zu empfehlen.</span><span class="sxs-lookup"><span data-stu-id="65424-184">The use of these VMs are therefore not recommended for critical production workloads.</span></span> <span data-ttu-id="65424-185">Sie sind jedoch sehr nützlich für experimentelle oder Entwicklungsworkloads.</span><span class="sxs-lookup"><span data-stu-id="65424-185">However, they are very useful for experimental or development workloads.</span></span>

## <a name="deployment"></a><span data-ttu-id="65424-186">Bereitstellung</span><span class="sxs-lookup"><span data-stu-id="65424-186">Deployment</span></span>

<span data-ttu-id="65424-187">Befolgen Sie die Schritte im [GitHub-Repository][github], um diese Referenzarchitektur bereitzustellen.</span><span class="sxs-lookup"><span data-stu-id="65424-187">To deploy this reference architecture, follow the steps described in the [GitHub][github] repo.</span></span>


[0]: ./_images/batch-scoring-r-models.png
[1]: ./_images/sales-forecasts.png
[aci]: /azure/container-instances/container-instances-overview
[autoscale]: /azure/batch/batch-automatic-scaling
[batch]: /azure/batch/batch-technical-overview
[blob]: /azure/storage/blobs/storage-blobs-introduction
[doAzureParallel]: https://github.com/Azure/doAzureParallel/blob/master/docs/32-autoscale.md
[getJobFiles]: /azure/machine-learning/service/how-to-train-ml-models
[github]: https://github.com/Azure/RBatchScoring
[logic-apps]: /azure/logic-apps/logic-apps-overview
[storage-explorer]: /azure/vs-azure-tools-storage-manage-with-storage-explorer?tabs=windows