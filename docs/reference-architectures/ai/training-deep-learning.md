---
title: Verteiltes Trainieren von Deep Learning-Modellen in Azure
description: Diese Referenzarchitektur zeigt, wie Sie unter Verwendung von Azure Batch AI ein verteiltes Training von Deep Learning-Modellen in mehreren Clustern mit GPU-fähigen virtuellen Computern durchführen.
author: njray
ms.date: 01/14/19
ms.custom: azcat-ai
ms.openlocfilehash: 0e63ed24c1e19333e7c9d48d531a7ddc778f3d86
ms.sourcegitcommit: c053e6edb429299a0ad9b327888d596c48859d4a
ms.translationtype: HT
ms.contentlocale: de-DE
ms.lasthandoff: 03/20/2019
ms.locfileid: "58242391"
---
# <a name="distributed-training-of-deep-learning-models-on-azure"></a><span data-ttu-id="6dd55-103">Verteiltes Trainieren von Deep Learning-Modellen in Azure</span><span class="sxs-lookup"><span data-stu-id="6dd55-103">Distributed training of deep learning models on Azure</span></span>

<span data-ttu-id="6dd55-104">Diese Referenzarchitektur zeigt, wie Sie ein verteiltes Training von Deep Learning-Modellen in mehreren Clustern mit GPU-fähigen virtuellen Computern durchführen.</span><span class="sxs-lookup"><span data-stu-id="6dd55-104">This reference architecture shows how to conduct distributed training of deep learning models across clusters of GPU-enabled VMs.</span></span> <span data-ttu-id="6dd55-105">Bei dem Szenario handelt es sich zwar um eine Bildklassifizierung, die Lösung kann jedoch auch für andere Deep Learning-Szenarien (etwa für die Segmentierung oder Objekterkennung) generalisiert werden.</span><span class="sxs-lookup"><span data-stu-id="6dd55-105">The scenario is image classification, but the solution can be generalized for other deep learning scenarios such as segmentation and object detection.</span></span>

<span data-ttu-id="6dd55-106">Eine Referenzimplementierung für diese Architektur ist auf [GitHub][github] verfügbar.</span><span class="sxs-lookup"><span data-stu-id="6dd55-106">A reference implementation for this architecture is available on [GitHub][github].</span></span>

![Architektur für verteiltes Deep Learning][0]

<span data-ttu-id="6dd55-108">**Szenario:** Bildklassifizierung ist eine weit verbreitete Technik in Verbindung mit maschinellem Sehen und wird häufig durch Trainieren eines auf dem Faltungsprinzip basierenden neuronalen Netzes (Convolutional Neural Network, CNN) umgesetzt.</span><span class="sxs-lookup"><span data-stu-id="6dd55-108">**Scenario**: Image classification is a widely applied technique in computer vision, often tackled by training a convolutional neural network (CNN).</span></span> <span data-ttu-id="6dd55-109">Bei besonders umfangreichen Modellen mit großen Datasets kann das Training mit einer einzelnen GPU Wochen oder Monate dauern.</span><span class="sxs-lookup"><span data-stu-id="6dd55-109">For particularly large models with large datasets, the training process can take weeks or months on a single GPU.</span></span> <span data-ttu-id="6dd55-110">Manchmal sind die Modelle sogar so groß, dass gar keine sinnvollen Batchgrößen für die GPU möglich sind.</span><span class="sxs-lookup"><span data-stu-id="6dd55-110">In some situations, the models are so large that it's not possible to fit reasonable batch sizes onto the GPU.</span></span> <span data-ttu-id="6dd55-111">In solchen Fällen lässt sich die Trainingsdauer mithilfe eines verteilten Trainings verkürzen.</span><span class="sxs-lookup"><span data-stu-id="6dd55-111">Using distributed training in these situations can shorten the training time.</span></span>

<span data-ttu-id="6dd55-112">In diesem spezifischen Szenario wird ein [ResNet50-CNN-Modell][resnet] unter Verwendung von [Horovod][horovod] mit dem [Imagenet-Dataset][imagenet] sowie mit synthetischen Daten trainiert.</span><span class="sxs-lookup"><span data-stu-id="6dd55-112">In this specific scenario, a [ResNet50 CNN model][resnet] is trained using [Horovod][horovod] on the [Imagenet dataset][imagenet] and on synthetic data.</span></span> <span data-ttu-id="6dd55-113">Die Referenzimplementierung veranschaulicht die Bewältigung dieser Aufgabe anhand von drei der beliebtesten Deep Learning-Frameworks: TensorFlow, Keras und PyTorch.</span><span class="sxs-lookup"><span data-stu-id="6dd55-113">The reference implementation shows how to accomplish this task using three of the most popular deep learning frameworks: TensorFlow, Keras, and PyTorch.</span></span>

<span data-ttu-id="6dd55-114">Für das verteilte Trainieren von Deep Learning-Modellen gibt es verschiedene Möglichkeiten. Hierzu zählen unter anderem Ansätze mit parallelen Daten und parallelem Modell auf der Grundlage von synchronen oder asynchronen Aktualisierungen.</span><span class="sxs-lookup"><span data-stu-id="6dd55-114">There are several ways to train a deep learning model in a distributed fashion, including data-parallel and model-parallel approaches based on synchronous or asynchronous updates.</span></span> <span data-ttu-id="6dd55-115">Das gängigste Szenario ist derzeit der Ansatz mit parallelen Daten und synchronen Aktualisierungen.</span><span class="sxs-lookup"><span data-stu-id="6dd55-115">Currently the most common scenario is data parallel with synchronous updates.</span></span> <span data-ttu-id="6dd55-116">Dieser Ansatz lässt sich am einfachsten implementieren und ist in den meisten Fällen ausreichend.</span><span class="sxs-lookup"><span data-stu-id="6dd55-116">This approach is the easiest to implement and is sufficient for most use cases.</span></span>

<span data-ttu-id="6dd55-117">Beim verteilten Trainieren mit parallelen Daten und synchronen Aktualisierungen wird das Modell auf *n* Hardwaregeräten repliziert.</span><span class="sxs-lookup"><span data-stu-id="6dd55-117">In data-parallel distributed training with synchronous updates, the model is replicated across *n* hardware devices.</span></span> <span data-ttu-id="6dd55-118">Ein Minibatch mit Trainingsbeispielen wird auf *n* Mikrobatches aufgeteilt.</span><span class="sxs-lookup"><span data-stu-id="6dd55-118">A mini-batch of training samples is divided into *n* micro-batches.</span></span> <span data-ttu-id="6dd55-119">Jedes Gerät führt die Vorwärts- und Rückwärtsvorgänge für einen Mikrobatch aus.</span><span class="sxs-lookup"><span data-stu-id="6dd55-119">Each device performs the forward and backward passes for a micro-batch.</span></span> <span data-ttu-id="6dd55-120">Nach Abschluss des Prozesses gibt das jeweilige Gerät die Aktualisierungen an die anderen Geräte weiter.</span><span class="sxs-lookup"><span data-stu-id="6dd55-120">When a device finishes the process, it shares the updates with the other devices.</span></span> <span data-ttu-id="6dd55-121">Die Werte werden verwendet, um die aktualisierten Gewichtungen des gesamten Minibatchs zu berechnen, und die Gewichtungen werden modellübergreifend synchronisiert.</span><span class="sxs-lookup"><span data-stu-id="6dd55-121">These values are used to calculate the updated weights of the entire mini-batch, and the weights are synchronized across the models.</span></span> <span data-ttu-id="6dd55-122">Dieses Szenario wird in [diesem GitHub-Repository][github] behandelt.</span><span class="sxs-lookup"><span data-stu-id="6dd55-122">This scenario is covered in the [GitHub][github] repository.</span></span>

![Verteiltes Trainieren mit parallelen Daten][1]

<span data-ttu-id="6dd55-124">Diese Architektur kann auch für den Ansatz mit parallelem Modell und asynchronen Aktualisierungen verwendet werden.</span><span class="sxs-lookup"><span data-stu-id="6dd55-124">This architecture can also be used for model-parallel and asynchronous updates.</span></span> <span data-ttu-id="6dd55-125">Beim verteilten Trainieren mit parallelem Modell wird das Modell auf *n* Hardwaregeräte aufgeteilt, wobei jedes Gerät über einen Teil des Modells verfügt.</span><span class="sxs-lookup"><span data-stu-id="6dd55-125">In model-parallel distributed training, the model is divided across *n* hardware devices, with each device holding a part of the model.</span></span> <span data-ttu-id="6dd55-126">In der einfachsten Implementierung kann jedes Gerät über eine Schicht des Netzwerks verfügen, und Informationen werden während der Vorwärts- und Rückwärtsphase zwischen Geräten ausgetauscht.</span><span class="sxs-lookup"><span data-stu-id="6dd55-126">In the simplest implementation, each device may hold a layer of the network, and information is passed between devices during the forward and backwards pass.</span></span> <span data-ttu-id="6dd55-127">Größere neuronale Netze können zwar auf diese Weise trainiert werden, dies geht jedoch zulasten der Leistung, da Geräte ständig darauf warten, dass andere Geräte entweder die Vorwärts- oder die Rückwärtsphase abschließen.</span><span class="sxs-lookup"><span data-stu-id="6dd55-127">Larger neural networks can be trained this way, but at the cost of performance, since devices are constantly waiting for each other to complete either the forward or backwards pass.</span></span> <span data-ttu-id="6dd55-128">Bei einigen erweiterten Techniken wird mithilfe synthetischer Gradienten versucht, dieses Problem zumindest teilweise zu entschärfen.</span><span class="sxs-lookup"><span data-stu-id="6dd55-128">Some advanced techniques try to partially alleviate this issue by using synthetic gradients.</span></span>

<span data-ttu-id="6dd55-129">Das Training umfasst folgende Schritte:</span><span class="sxs-lookup"><span data-stu-id="6dd55-129">The steps for training are:</span></span>

1. <span data-ttu-id="6dd55-130">Erstellen von Skripts, die im Cluster ausgeführt werden und Ihr Modell trainieren, und anschließendes Übertragen in den Dateispeicher</span><span class="sxs-lookup"><span data-stu-id="6dd55-130">Create scripts that will run on the cluster and train your model, then transfer them to file storage.</span></span>

1. <span data-ttu-id="6dd55-131">Schreiben der Daten in Blob Storage</span><span class="sxs-lookup"><span data-stu-id="6dd55-131">Write the data to Blob Storage.</span></span>

1. <span data-ttu-id="6dd55-132">Erstellen eines Batch AI-Dateiservers und Herunterladen der Daten aus Blob Storage</span><span class="sxs-lookup"><span data-stu-id="6dd55-132">Create a Batch AI file server and download the data from Blob Storage onto it.</span></span>

1. <span data-ttu-id="6dd55-133">Erstellen der Docker-Container für das jeweilige Deep Learning-Framework und Übertragen der Container in eine Containerregistrierung (Docker Hub)</span><span class="sxs-lookup"><span data-stu-id="6dd55-133">Create the Docker containers for each deep learning framework and transfer them to a container registry (Docker Hub).</span></span>

1. <span data-ttu-id="6dd55-134">Erstellen eines Batch AI-Pools, der auch den Batch AI-Dateiserver einbindet</span><span class="sxs-lookup"><span data-stu-id="6dd55-134">Create a Batch AI pool that also mounts the Batch AI file server.</span></span>

1. <span data-ttu-id="6dd55-135">Übermitteln von Aufträgen.</span><span class="sxs-lookup"><span data-stu-id="6dd55-135">Submit jobs.</span></span> <span data-ttu-id="6dd55-136">Jeder Auftrag ruft mittels Pullvorgang das entsprechende Docker-Image sowie die Skripts ab.</span><span class="sxs-lookup"><span data-stu-id="6dd55-136">Each pulls in the appropriate Docker image and scripts.</span></span>

1. <span data-ttu-id="6dd55-137">Nach Abschluss des Auftrags: Schreiben aller Ergebnisse in den Dateispeicher</span><span class="sxs-lookup"><span data-stu-id="6dd55-137">Once the job is completed, write all the results to Files storage.</span></span>

## <a name="architecture"></a><span data-ttu-id="6dd55-138">Architecture</span><span class="sxs-lookup"><span data-stu-id="6dd55-138">Architecture</span></span>

<span data-ttu-id="6dd55-139">Diese Architektur umfasst die folgenden Komponenten.</span><span class="sxs-lookup"><span data-stu-id="6dd55-139">This architecture consists of the following components.</span></span>

<span data-ttu-id="6dd55-140">**[Azure Batch AI][batch-ai]** bildet das Herzstück dieser Architektur und sorgt für eine bedarfsgerechte Skalierung der Ressourcen.</span><span class="sxs-lookup"><span data-stu-id="6dd55-140">**[Azure Batch AI][batch-ai]** plays the central role in this architecture by scaling resources up and down according to need.</span></span> <span data-ttu-id="6dd55-141">Der Batch AI-Dienst unterstützt Sie beim Bereitstellen und Verwalten von VM-Clustern, beim Planen von Aufträgen, beim Erfassen der Ergebnisse, beim Skalieren der Ressourcen, beim Behandeln von Fehlern sowie beim Erstellen des erforderlichen Speichers.</span><span class="sxs-lookup"><span data-stu-id="6dd55-141">Batch AI is a service that helps provision and manage clusters of VMs, schedule jobs, gather results, scale resources, handle failures, and create appropriate storage.</span></span> <span data-ttu-id="6dd55-142">Er unterstützt GPU-fähige virtuelle Computer für Deep Learning-Workloads.</span><span class="sxs-lookup"><span data-stu-id="6dd55-142">It supports GPU-enabled VMs for deep learning workloads.</span></span> <span data-ttu-id="6dd55-143">Für Batch AI sind ein Python SDK und eine Befehlszeilenschnittstelle (Command-Line Interface, CLI) verfügbar.</span><span class="sxs-lookup"><span data-stu-id="6dd55-143">A Python SDK and a command-line interface (CLI) are available for Batch AI.</span></span>

> [!NOTE]
> <span data-ttu-id="6dd55-144">Der Azure Batch AI-Dienst wird im März 2019 eingestellt. Die skalierbaren Trainings- und Bewertungsfunktionen dieses Diensts sind nun in [Azure Machine Learning Service][amls] verfügbar.</span><span class="sxs-lookup"><span data-stu-id="6dd55-144">The Azure Batch AI service is retiring March 2019, and its at-scale training and scoring capabilities are now available in [Azure Machine Learning Service][amls].</span></span> <span data-ttu-id="6dd55-145">Diese Referenzarchitektur wird demnächst für die Verwendung von Machine Learning aktualisiert, wodurch ein verwaltetes Computeziel namens [Azure Machine Learning Compute][aml-compute] zum Trainieren, Bereitstellen und Bewerten von Machine Learning-Modellen zur Verfügung steht.</span><span class="sxs-lookup"><span data-stu-id="6dd55-145">This reference architecture will be updated soon to use Machine Learning, which offers a managed compute target called [Azure Machine Learning Compute][aml-compute] for training, deploying, and scoring machine learning models.</span></span>

<span data-ttu-id="6dd55-146">**[Blob Storage][azure-blob]** wird zum Bereitstellen der Daten verwendet.</span><span class="sxs-lookup"><span data-stu-id="6dd55-146">**[Blob storage][azure-blob]** is used to stage the data.</span></span> <span data-ttu-id="6dd55-147">Die Daten werden im Rahmen des Trainings auf einen Batch AI-Dateiserver heruntergeladen.</span><span class="sxs-lookup"><span data-stu-id="6dd55-147">This data is downloaded to a Batch AI file server during training.</span></span>

<span data-ttu-id="6dd55-148">**[Azure Files][files]** wird zum Speichern der Skripts, Protokolle und Endergebnisse des Trainings verwendet.</span><span class="sxs-lookup"><span data-stu-id="6dd55-148">**[Azure Files][files]** is used to store the scripts, logs, and the final results from the training.</span></span> <span data-ttu-id="6dd55-149">File Storage eignet sich sehr gut zum Speichern von Protokollen und Skripts, ist aber nicht so leistungsfähig wie Blob Storage und sollte daher nicht für datenintensive Aufgaben verwendet werden.</span><span class="sxs-lookup"><span data-stu-id="6dd55-149">File storage works well for storing logs and scripts, but is not as performant as Blob Storage, so it shouldn't be used for data-intensive tasks.</span></span>

<span data-ttu-id="6dd55-150">**[Batch AI-Dateiserver][batch-ai-files]** ist eine NFS-Freigabe mit einem einzelnen Knoten und wird in dieser Architektur zum Speichern der Trainingsdaten verwendet.</span><span class="sxs-lookup"><span data-stu-id="6dd55-150">**[Batch AI file server][batch-ai-files]** is a single-node NFS share used in this architecture to store the training data.</span></span> <span data-ttu-id="6dd55-151">Batch AI erstellt eine NFS-Freigabe und bindet sie auf dem Cluster ein.</span><span class="sxs-lookup"><span data-stu-id="6dd55-151">Batch AI creates an NFS share and mounts it on the cluster.</span></span> <span data-ttu-id="6dd55-152">Batch AI-Dateiserver sind die empfohlene Methode, um Daten mit dem nötigen Durchsatz für den Cluster bereitzustellen.</span><span class="sxs-lookup"><span data-stu-id="6dd55-152">Batch AI file servers are the recommended way to serve data to the cluster with the necessary throughput.</span></span>

<span data-ttu-id="6dd55-153">**[Docker-Hub][docker]** wird zum Speichern des Docker-Images benutzt, das Batch AI zum Ausführen des Trainings verwendet.</span><span class="sxs-lookup"><span data-stu-id="6dd55-153">**[Docker Hub][docker]** is used to store the Docker image that Batch AI uses to run the training.</span></span> <span data-ttu-id="6dd55-154">Der Docker-Hub wurde für diese Architektur ausgewählt, weil er benutzerfreundlich und das Standardimagerepository für Docker-Benutzer ist.</span><span class="sxs-lookup"><span data-stu-id="6dd55-154">Docker Hub was chosen for this architecture because it's easy to use and is the default image repository for Docker users.</span></span> <span data-ttu-id="6dd55-155">[Azure Container Registry][acr] kann ebenfalls verwendet werden.</span><span class="sxs-lookup"><span data-stu-id="6dd55-155">[Azure Container Registry][acr] can also be used.</span></span>

## <a name="performance-considerations"></a><span data-ttu-id="6dd55-156">Überlegungen zur Leistung</span><span class="sxs-lookup"><span data-stu-id="6dd55-156">Performance considerations</span></span>

<span data-ttu-id="6dd55-157">Azure bietet vier [GPU-fähige VM-Typen][gpu], die zum Trainieren von Deep Learning-Modellen geeignet sind.</span><span class="sxs-lookup"><span data-stu-id="6dd55-157">Azure provides four [GPU-enabled VM types][gpu] suitable for training deep learning models.</span></span> <span data-ttu-id="6dd55-158">Im Anschluss finden Sie Informationen zu den verschiedenen Preisen und zur jeweiligen Geschwindigkeit (in aufsteigender Reihenfolge):</span><span class="sxs-lookup"><span data-stu-id="6dd55-158">They range in price and speed from low to high as follows:</span></span>

| <span data-ttu-id="6dd55-159">**Azure-VM-Serie**</span><span class="sxs-lookup"><span data-stu-id="6dd55-159">**Azure VM series**</span></span> | <span data-ttu-id="6dd55-160">**NVIDIA-GPU**</span><span class="sxs-lookup"><span data-stu-id="6dd55-160">**NVIDIA GPU**</span></span> |
|---------------------|----------------|
| <span data-ttu-id="6dd55-161">NC</span><span class="sxs-lookup"><span data-stu-id="6dd55-161">NC</span></span>                  | <span data-ttu-id="6dd55-162">K80</span><span class="sxs-lookup"><span data-stu-id="6dd55-162">K80</span></span>            |
| <span data-ttu-id="6dd55-163">ND</span><span class="sxs-lookup"><span data-stu-id="6dd55-163">ND</span></span>                  | <span data-ttu-id="6dd55-164">P40</span><span class="sxs-lookup"><span data-stu-id="6dd55-164">P40</span></span>            |
| <span data-ttu-id="6dd55-165">NCv2</span><span class="sxs-lookup"><span data-stu-id="6dd55-165">NCv2</span></span>                | <span data-ttu-id="6dd55-166">P100</span><span class="sxs-lookup"><span data-stu-id="6dd55-166">P100</span></span>           |
| <span data-ttu-id="6dd55-167">NCv3</span><span class="sxs-lookup"><span data-stu-id="6dd55-167">NCv3</span></span>                | <span data-ttu-id="6dd55-168">V100</span><span class="sxs-lookup"><span data-stu-id="6dd55-168">V100</span></span>           |

<span data-ttu-id="6dd55-169">Es empfiehlt sich, das Training zunächst zentral zu skalieren, bevor Sie eine horizontale Skalierung durchführen. Versuchen Sie es also beispielsweise erst mit einer einzelnen V100-Instanz, bevor Sie einen Cluster mit K80-Instanzen verwenden.</span><span class="sxs-lookup"><span data-stu-id="6dd55-169">We recommended scaling up your training before scaling out. For example, try a single V100 before trying a cluster of K80s.</span></span>

<span data-ttu-id="6dd55-170">Das folgende Diagramm zeigt die Leistungsunterschiede für verschiedene GPU-Typen auf der Grundlage von [Benchmarktests][benchmark], die mit TensorFlow und Horovod in Batch AI durchgeführt wurden.</span><span class="sxs-lookup"><span data-stu-id="6dd55-170">The following graph shows the performance differences for different GPU types based on [benchmarking tests][benchmark] carried out using TensorFlow and Horovod on Batch AI.</span></span> <span data-ttu-id="6dd55-171">Das Diagramm zeigt den Durchsatz von 32 GPU-Clustern für verschiedene Modelle mit unterschiedlichen GPU-Typen und MPI-Versionen.</span><span class="sxs-lookup"><span data-stu-id="6dd55-171">The graph shows throughput of 32 GPU clusters across various models, on different GPU types and MPI versions.</span></span> <span data-ttu-id="6dd55-172">Die Modelle wurden in TensorFlow 1.9 implementiert.</span><span class="sxs-lookup"><span data-stu-id="6dd55-172">Models were implemented in TensorFlow 1.9</span></span>

![Durchsatzergebnisse für TensorFlow-Modelle in GPU-Clustern][2]

<span data-ttu-id="6dd55-174">Jede VM-Serie aus der obigen Tabelle verfügt über eine Konfiguration mit InfiniBand.</span><span class="sxs-lookup"><span data-stu-id="6dd55-174">Each VM series shown in the previous table includes a configuration with InfiniBand.</span></span> <span data-ttu-id="6dd55-175">Verwenden Sie die InfiniBand-Konfigurationen beim Ausführen von verteilten Trainings, um die Kommunikation zwischen Knoten zu beschleunigen.</span><span class="sxs-lookup"><span data-stu-id="6dd55-175">Use the InfiniBand configurations when you run distributed training, for faster communication between nodes.</span></span> <span data-ttu-id="6dd55-176">InfiniBand erhöht außerdem die Skalierungseffizienz des Trainings für die Frameworks, die dafür geeignet sind.</span><span class="sxs-lookup"><span data-stu-id="6dd55-176">InfiniBand also increases the scaling efficiency of the training for the frameworks that can take advantage of it.</span></span> <span data-ttu-id="6dd55-177">Ausführliche Informationen finden Sie im [Benchmarkvergleich][benchmark] für InfiniBand.</span><span class="sxs-lookup"><span data-stu-id="6dd55-177">For details, see the Infiniband [benchmark comparison][benchmark].</span></span>

<span data-ttu-id="6dd55-178">Batch AI kann Blob Storage zwar mithilfe des Adapters [blobfuse][blobfuse] einbinden, wir raten jedoch davon ab, Blob Storage auf diese Weise für verteilte Trainings zu verwenden, da die Leistung für den erforderlichen Durchsatz nicht ausreicht.</span><span class="sxs-lookup"><span data-stu-id="6dd55-178">Although Batch AI can mount Blob storage using the [blobfuse][blobfuse] adapter, we don't recommend using Blob Storage this way for distributed training, because the performance isn't good enough to handle the necessary throughput.</span></span> <span data-ttu-id="6dd55-179">Verschieben Sie die Daten stattdessen auf einen Batch AI-Dateiserver, wie im Architekturdiagramm dargestellt.</span><span class="sxs-lookup"><span data-stu-id="6dd55-179">Move the data to a Batch AI file server instead, as shown in the architecture diagram.</span></span>

## <a name="scalability-considerations"></a><span data-ttu-id="6dd55-180">Überlegungen zur Skalierbarkeit</span><span class="sxs-lookup"><span data-stu-id="6dd55-180">Scalability considerations</span></span>

<span data-ttu-id="6dd55-181">Bei der Skalierungseffizienz des verteilten Trainings werden aufgrund des Zusatzaufwands für das Netzwerk niemals 100 Prozent erreicht: Die Synchronisierung des gesamten Modells zwischen Geräten wird zu einem Engpass.</span><span class="sxs-lookup"><span data-stu-id="6dd55-181">The scaling efficiency of distributed training is always less than 100 percent due to network overhead &mdash; syncing the entire model between devices becomes a bottleneck.</span></span> <span data-ttu-id="6dd55-182">Somit eignen sich verteilte Trainings am besten für umfangreiche Modelle, die nicht mit einer sinnvollen Batchgröße auf einer einzelnen GPU trainiert werden können, oder für Probleme, die sich nicht durch eine einfache, parallele Verteilung des Modells lösen lassen.</span><span class="sxs-lookup"><span data-stu-id="6dd55-182">Therefore, distributed training is most suited for large models that cannot be trained using a reasonable batch size on a single GPU, or for problems that cannot be addressed by distributing the model in a simple, parallel way.</span></span>

<span data-ttu-id="6dd55-183">Verteilte Trainings sollten nicht für Hyperparameter-Suchvorgänge verwendet werden.</span><span class="sxs-lookup"><span data-stu-id="6dd55-183">Distributed training is not recommended for running hyperparameter searches.</span></span> <span data-ttu-id="6dd55-184">Die Skalierungseffizienz wirkt sich auf die Leistung aus und macht einen verteilten Ansatz weniger effizient als das separate Trainieren mehrerer Modellkonfigurationen.</span><span class="sxs-lookup"><span data-stu-id="6dd55-184">The scaling efficiency affects performance and makes a distributed approach less efficient than training multiple model configurations separately.</span></span>

<span data-ttu-id="6dd55-185">Eine Möglichkeit zur Steigerung der Skalierungseffizienz ist die Erhöhung der Batchgröße.</span><span class="sxs-lookup"><span data-stu-id="6dd55-185">One way to increase scaling efficiency is to increase the batch size.</span></span> <span data-ttu-id="6dd55-186">Dabei ist jedoch Vorsicht geboten, da die Erhöhung der Batchgröße ohne Anpassung der anderen Parameter letztendlich die Leistung des Modells beeinträchtigen kann.</span><span class="sxs-lookup"><span data-stu-id="6dd55-186">That must be done carefully, however, because increasing the batch size without adjusting the other parameters can hurt the model's final performance.</span></span>

## <a name="storage-considerations"></a><span data-ttu-id="6dd55-187">Speicheraspekt</span><span class="sxs-lookup"><span data-stu-id="6dd55-187">Storage considerations</span></span>

<span data-ttu-id="6dd55-188">Beim Trainieren von Deep Learning-Modellen wird oftmals der Speicherort der Daten außer Acht gelassen.</span><span class="sxs-lookup"><span data-stu-id="6dd55-188">When training deep learning models, an often-overlooked aspect is where the data is stored.</span></span> <span data-ttu-id="6dd55-189">Ist der Speicher den Anforderungen der GPUs nicht gewachsen, geht dies unter Umständen zulasten der Trainingsleistung.</span><span class="sxs-lookup"><span data-stu-id="6dd55-189">If the storage is too slow to keep up with the demands of the GPUs, training performance can degrade.</span></span>

<span data-ttu-id="6dd55-190">Batch AI unterstützt verschiedenste Speicherlösungen.</span><span class="sxs-lookup"><span data-stu-id="6dd55-190">Batch AI supports many storage solutions.</span></span> <span data-ttu-id="6dd55-191">In dieser Architektur wird ein Batch AI-Dateiserver verwendet, da er das beste Verhältnis zwischen Benutzerfreundlichkeit und Leistung bietet.</span><span class="sxs-lookup"><span data-stu-id="6dd55-191">This architecture uses a Batch AI file server, because it provides the best tradeoff between ease of use and performance.</span></span> <span data-ttu-id="6dd55-192">Die beste Leistung erzielen Sie, wenn Sie die Daten lokal laden.</span><span class="sxs-lookup"><span data-stu-id="6dd55-192">For best performance, load the data locally.</span></span> <span data-ttu-id="6dd55-193">Dies kann sich jedoch als umständlich erweisen, da alle Knoten die Daten aus Blob Storage herunterladen müssen, was bei dem ImageNet-Dataset mehrere Stunden dauern kann.</span><span class="sxs-lookup"><span data-stu-id="6dd55-193">However, this can be cumbersome, because all the nodes must download the data from Blob Storage, and with the ImageNet dataset, this can take hours.</span></span> <span data-ttu-id="6dd55-194">Eine andere empfehlenswerte Option ist [Azure Premium Blob Storage][blob] (eingeschränkte Public Preview).</span><span class="sxs-lookup"><span data-stu-id="6dd55-194">[Azure Premium Blob Storage][blob] (limited public preview) is another good option to consider.</span></span>

<span data-ttu-id="6dd55-195">Binden Sie für verteilte Trainings weder Blob noch File Storage als Datenspeicher ein.</span><span class="sxs-lookup"><span data-stu-id="6dd55-195">Do not mount Blob and File storage as data stores for distributed training.</span></span> <span data-ttu-id="6dd55-196">Diese Optionen sind zu langsam und beeinträchtigen die Trainingsleistung.</span><span class="sxs-lookup"><span data-stu-id="6dd55-196">They are too slow and will hinder training performance.</span></span>

## <a name="security-considerations"></a><span data-ttu-id="6dd55-197">Sicherheitshinweise</span><span class="sxs-lookup"><span data-stu-id="6dd55-197">Security considerations</span></span>

### <a name="restrict-access-to-azure-blob-storage"></a><span data-ttu-id="6dd55-198">Beschränken des Zugriffs auf Azure Blob Storage</span><span class="sxs-lookup"><span data-stu-id="6dd55-198">Restrict access to Azure Blob Storage</span></span>

<span data-ttu-id="6dd55-199">In dieser Architektur werden [Speicherkontoschlüssel][security-guide] für den Zugriff auf Blob Storage verwendet.</span><span class="sxs-lookup"><span data-stu-id="6dd55-199">This architecture uses [storage account keys][security-guide] to access the Blob storage.</span></span> <span data-ttu-id="6dd55-200">Für noch mehr Kontrolle und Schutz sollten Sie stattdessen Shared Access Signatur (SAS) verwenden.</span><span class="sxs-lookup"><span data-stu-id="6dd55-200">For further control and protection, consider using a shared access signature (SAS) instead.</span></span> <span data-ttu-id="6dd55-201">Dadurch wird der Zugriff auf die gespeicherten Objekte eingeschränkt, ohne dass die Kontoschlüssel hartcodiert oder als Klartext gespeichert werden müssen.</span><span class="sxs-lookup"><span data-stu-id="6dd55-201">This grants limited access to objects in storage, without needing to hard-code the account keys or save them in plaintext.</span></span> <span data-ttu-id="6dd55-202">Mit SAS können Sie außerdem sicherstellen, dass das Speicherkonto über eine ordnungsgemäße Governance verfügt und der Zugriff nur ausgewählten Personen gewährt wird.</span><span class="sxs-lookup"><span data-stu-id="6dd55-202">Using a SAS also helps to ensure that the storage account has proper governance, and that access is granted only to the people intended to have it.</span></span>

<span data-ttu-id="6dd55-203">Stellen Sie in Szenarien mit sensibleren Daten sicher, dass alle Ihre Speicherschlüssel geschützt sind, weil diese Schlüssel den Vollzugriff auf alle Ein- und Ausgabedaten der Workload ermöglichen.</span><span class="sxs-lookup"><span data-stu-id="6dd55-203">For scenarios with more sensitive data, make sure that all of your storage keys are protected, because these keys grant full access to all input and output data from the workload.</span></span>

### <a name="encrypt-data-at-rest-and-in-motion"></a><span data-ttu-id="6dd55-204">Verschlüsseln von ruhenden und übertragenen Daten</span><span class="sxs-lookup"><span data-stu-id="6dd55-204">Encrypt data at rest and in motion</span></span>

<span data-ttu-id="6dd55-205">In Szenarien mit sensiblen Daten müssen ruhende Daten (Daten im Speicher) verschlüsselt werden.</span><span class="sxs-lookup"><span data-stu-id="6dd55-205">In scenarios that use sensitive data, encrypt the data at rest &mdash; that is, the data in storage.</span></span> <span data-ttu-id="6dd55-206">Bei Datenübertragungen müssen die Daten mithilfe von SSL geschützt werden.</span><span class="sxs-lookup"><span data-stu-id="6dd55-206">Each time data moves from one location to the next, use SSL to secure the data transfer.</span></span> <span data-ttu-id="6dd55-207">Weitere Informationen finden Sie im [Azure Storage-Sicherheitsleitfaden][security-guide].</span><span class="sxs-lookup"><span data-stu-id="6dd55-207">For more information, see the [Azure Storage security guide][security-guide].</span></span>

### <a name="secure-data-in-a-virtual-network"></a><span data-ttu-id="6dd55-208">Schützen von Daten in einem virtuellen Netzwerk</span><span class="sxs-lookup"><span data-stu-id="6dd55-208">Secure data in a virtual network</span></span>

<span data-ttu-id="6dd55-209">Bei Produktionsbereitstellungen empfiehlt es sich ggf., den Batch AI-Cluster in einem Subnetz eines von Ihnen angegebenen virtuellen Netzwerks bereitzustellen.</span><span class="sxs-lookup"><span data-stu-id="6dd55-209">For production deployments, consider deploying the Batch AI cluster into a subnet of a virtual network that you specify.</span></span> <span data-ttu-id="6dd55-210">Dadurch können die Computeknoten im Cluster sicher mit anderen virtuellen Computern oder mit einem lokalen Netzwerk kommunizieren.</span><span class="sxs-lookup"><span data-stu-id="6dd55-210">This allows the compute nodes in the cluster to communicate securely with other virtual machines or with an on-premises network.</span></span> <span data-ttu-id="6dd55-211">Sie können auch [Dienstendpunkte][endpoints] mit Blob Storage verwenden, um den Zugriff über ein virtuelles Netzwerk zu ermöglichen, oder ein NFS mit einem einzelnen Knoten innerhalb des virtuellen Netzwerks mit Batch AI.</span><span class="sxs-lookup"><span data-stu-id="6dd55-211">You can also use [service endpoints][endpoints] with blob storage to grant access from a virtual network or use a single-node NFS inside the virtual network with Batch AI.</span></span>

## <a name="monitoring-considerations"></a><span data-ttu-id="6dd55-212">Aspekte der Überwachung</span><span class="sxs-lookup"><span data-stu-id="6dd55-212">Monitoring considerations</span></span>

<span data-ttu-id="6dd55-213">Beim Ausführen Ihres Auftrags ist es wichtig, den Fortschritt zu überwachen und zu überprüfen, ob alles wie erwartet funktioniert.</span><span class="sxs-lookup"><span data-stu-id="6dd55-213">While running your job, it's important to monitor the progress and make sure that things are working as expected.</span></span> <span data-ttu-id="6dd55-214">Es kann jedoch eine Herausforderung sein, über einen Cluster von aktiven Knoten hinweg zu überwachen.</span><span class="sxs-lookup"><span data-stu-id="6dd55-214">However, it can be a challenge to monitor across a cluster of active nodes.</span></span>

<span data-ttu-id="6dd55-215">Die Batch AI-Dateiserver können über das Azure-Portal oder über die [Azure-Befehlszeilenschnittstelle][cli] und das Python SDK verwaltet werden.</span><span class="sxs-lookup"><span data-stu-id="6dd55-215">The Batch AI file servers can be managed through the Azure portal or though the [Azure CLI][cli] and Python SDK.</span></span> <span data-ttu-id="6dd55-216">Um einen Eindruck vom Gesamtzustand des Clusters zu bekommen, navigieren Sie im Azure-Portal zu **Batch AI**, und untersuchen Sie den Zustand der Clusterknoten.</span><span class="sxs-lookup"><span data-stu-id="6dd55-216">To get a sense of the overall state of the cluster, navigate to **Batch AI** in the Azure portal to inspect the state of the cluster nodes.</span></span> <span data-ttu-id="6dd55-217">Wenn ein Knoten inaktiv ist oder bei einem Auftrag ein Fehler auftritt, werden die Fehlerprotokolle in Blob Storage gespeichert und stehen auch im Azure-Portal unter **Aufträge** zur Verfügung.</span><span class="sxs-lookup"><span data-stu-id="6dd55-217">If a node is inactive or a job fails, the error logs are saved to blob storage, and are also accessible in the Azure Portal under **Jobs**.</span></span>

<span data-ttu-id="6dd55-218">Erweitern Sie die Überwachung, indem Sie Protokolle mit [Azure Application Insights][ai] verknüpfen oder separate Prozesse ausführen, die den Zustand des Batch AI-Clusters und der dazugehörigen Aufträge abrufen.</span><span class="sxs-lookup"><span data-stu-id="6dd55-218">Enrich monitoring by connecting logs to [Azure Application Insights][ai] or by running separate processes that poll for the state of the Batch AI cluster and its jobs.</span></span>

<span data-ttu-id="6dd55-219">Batch AI protokolliert automatisch alle stdout/stderr-Ereignisse im entsprechenden Blob Storage-Konto.</span><span class="sxs-lookup"><span data-stu-id="6dd55-219">Batch AI automatically logs all stdout/stderr to the associate Blob storage account.</span></span> <span data-ttu-id="6dd55-220">Speichernavigationstools wie der [Azure Storage-Explorer][storage-explorer] vereinfachen die Navigation durch die Protokolldateien.</span><span class="sxs-lookup"><span data-stu-id="6dd55-220">Use a storage navigation tool such as [Azure Storage Explorer][storage-explorer] for an easier experience when navigating log files.</span></span>

<span data-ttu-id="6dd55-221">Die Protokolle für die einzelnen Aufträge können auch gestreamt werden.</span><span class="sxs-lookup"><span data-stu-id="6dd55-221">It is also possible to stream the logs for each job.</span></span> <span data-ttu-id="6dd55-222">Ausführliche Informationen zu dieser Option finden Sie in den Entwicklungsschritten auf [GitHub][github].</span><span class="sxs-lookup"><span data-stu-id="6dd55-222">For details about this option, see the development steps on [GitHub][github].</span></span>

## <a name="deployment"></a><span data-ttu-id="6dd55-223">Bereitstellung</span><span class="sxs-lookup"><span data-stu-id="6dd55-223">Deployment</span></span>

<span data-ttu-id="6dd55-224">Die Referenzimplementierung dieser Architektur ist auf [GitHub][github] verfügbar.</span><span class="sxs-lookup"><span data-stu-id="6dd55-224">The reference implementation of this architecture is available on [GitHub][github].</span></span> <span data-ttu-id="6dd55-225">Führen Sie die dort beschriebenen Schritte aus, um ein verteiltes Training von Deep Learning-Modellen in mehreren Clustern mit GPU-fähigen virtuellen Computern durchzuführen.</span><span class="sxs-lookup"><span data-stu-id="6dd55-225">Follow the steps described there to conduct distributed training of deep learning models across clusters of GPU-enabled VMs.</span></span>

## <a name="next-steps"></a><span data-ttu-id="6dd55-226">Nächste Schritte</span><span class="sxs-lookup"><span data-stu-id="6dd55-226">Next steps</span></span>

<span data-ttu-id="6dd55-227">Diese Architektur gibt ein trainiertes, in Blob Storage gespeichertes Modell aus.</span><span class="sxs-lookup"><span data-stu-id="6dd55-227">The output from this architecture is a trained model that is saved to blob storage.</span></span> <span data-ttu-id="6dd55-228">Dieses Modell kann für Echtzeitbewertungen oder für Batchbewertungen operationalisiert werden.</span><span class="sxs-lookup"><span data-stu-id="6dd55-228">You can operationalize this model for either real-time scoring or batch scoring.</span></span> <span data-ttu-id="6dd55-229">Weitere Informationen finden Sie in den folgenden Referenzarchitekturen:</span><span class="sxs-lookup"><span data-stu-id="6dd55-229">For more information, see the following reference architectures:</span></span>

- <span data-ttu-id="6dd55-230">[Echtzeitbewertung von Python-Modellen (scikit-learn) und Deep Learning-Modellen in Azure][real-time-scoring]</span><span class="sxs-lookup"><span data-stu-id="6dd55-230">[Real-time scoring of Python scikit-learn and deep learning models on Azure][real-time-scoring]</span></span>
- <span data-ttu-id="6dd55-231">[Batchbewertung in Azure für Deep Learning-Modelle][batch-scoring]</span><span class="sxs-lookup"><span data-stu-id="6dd55-231">[Batch scoring on Azure for deep learning models][batch-scoring]</span></span>

[0]: ./_images/distributed_dl_architecture.png
[1]: ./_images/distributed_dl_flow.png
[2]: ./_images/distributed_dl_tests.png
[acr]: /azure/container-registry/container-registry-intro
[ai]: /azure/application-insights/app-insights-overview
[aml-compute]: /azure/machine-learning/service/how-to-set-up-training-targets#amlcompute
[amls]: /azure/machine-learning/service/overview-what-is-azure-ml
[azure-blob]: /azure/storage/blobs/storage-blobs-introduction
[batch-ai]: /azure/batch-ai/overview
[batch-ai-files]: /azure/batch-ai/resource-concepts#file-server
[batch-scoring]: /azure/architecture/reference-architectures/ai/batch-scoring-deep-learning
[benchmark]: https://github.com/msalvaris/BatchAIHorovodBenchmark
[blob]: https://azure.microsoft.com/en-gb/blog/introducing-azure-premium-blob-storage-limited-public-preview/
[blobfuse]: https://github.com/Azure/azure-storage-fuse
[cli]: https://github.com/Azure/BatchAI/blob/master/documentation/using-azure-cli-20.md
[docker]: https://hub.docker.com/
[endpoints]: /azure/storage/common/storage-network-security?toc=%2fazure%2fvirtual-network%2ftoc.json#grant-access-from-a-virtual-network
[files]: /azure/storage/files/storage-files-introduction
[github]: https://github.com/Azure/DistributedDeepLearning/
[gpu]: /azure/virtual-machines/windows/sizes-gpu
[horovod]: https://github.com/uber/horovod
[imagenet]: http://www.image-net.org/
[real-time-scoring]: /azure/architecture/reference-architectures/ai/realtime-scoring-python
[resnet]: https://arxiv.org/abs/1512.03385
[security-guide]: /azure/storage/common/storage-security-guide
[storage-explorer]: /azure/vs-azure-tools-storage-manage-with-storage-explorer?tabs=windows
[tutorial]: https://github.com/Azure/DistributedDeepLearning