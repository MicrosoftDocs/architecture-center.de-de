---
title: Trainieren von Python-Modellen vom Typ „scikit-learn“ in Azure
description: Diese Referenzarchitektur veranschaulicht bewährte Methoden für die Optimierung der Hyperparameter (Trainingsparameter) eines Python-Modells vom Typ „scikit-learn“.
author: njray
ms.date: 03/07/19
ms.custom: azcat-ai
ms.openlocfilehash: 23689ff7423b681c6cf5aeb713920a98f658044f
ms.sourcegitcommit: c053e6edb429299a0ad9b327888d596c48859d4a
ms.translationtype: HT
ms.contentlocale: de-DE
ms.lasthandoff: 03/20/2019
ms.locfileid: "58242241"
---
# <a name="training-of-python-scikit-learn-models-on-azure"></a><span data-ttu-id="4ebe6-103">Trainieren von Python-Modellen vom Typ „scikit-learn“ in Azure</span><span class="sxs-lookup"><span data-stu-id="4ebe6-103">Training of Python scikit-learn models on Azure</span></span>

<span data-ttu-id="4ebe6-104">Diese Referenzarchitektur veranschaulicht bewährte Methoden für die Optimierung der Hyperparameter (Trainingsparameter) eines Python-Modells vom Typ [scikit-learn][scikit].</span><span class="sxs-lookup"><span data-stu-id="4ebe6-104">This reference architecture shows recommended practices for tuning the hyperparameters (training parameters) of a [scikit-learn][scikit] Python model.</span></span> <span data-ttu-id="4ebe6-105">Eine Referenzimplementierung für diese Architektur ist auf [GitHub][github] verfügbar.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-105">A reference implementation for this architecture is available on [GitHub][github].</span></span>

![Architekturdiagramm][0]

<span data-ttu-id="4ebe6-107">**Szenario:** Hier wird der Abgleich von häufig gestellten Fragen (FAQs) behandelt.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-107">**Scenario:** The problem addressed here is Frequently Asked Question (FAQ) matching.</span></span> <span data-ttu-id="4ebe6-108">In diesem Szenario wird eine Teilmenge der Stack Overflow-Fragedaten verwendet, die die ursprünglichen Fragen (als JavaScript markiert), die zugehörigen doppelten Fragen und Antworten umfasst.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-108">This scenario uses a subset of Stack Overflow question data that includes original questions tagged as JavaScript, their duplicate questions, and their answers.</span></span> <span data-ttu-id="4ebe6-109">Das Szenario dient zum Optimieren einer scikit-learn-Pipeline für die Vorhersage der Wahrscheinlichkeit, dass eine doppelte Frage einer der ursprünglichen Fragen entspricht.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-109">It tunes a scikit-learn pipeline to predict the probability that a duplicate question matches one of the original questions.</span></span>

<span data-ttu-id="4ebe6-110">Die Verarbeitung dieses Szenarios umfasst folgende Schritte:</span><span class="sxs-lookup"><span data-stu-id="4ebe6-110">Processing in this scenario involves the following steps:</span></span>

1. <span data-ttu-id="4ebe6-111">Das Python-Trainingsskript wird an [Azure Machine Learning Service][aml] übermittelt.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-111">The training Python script is submitted to the [Azure Machine Learning service][aml].</span></span>

1. <span data-ttu-id="4ebe6-112">Das Skript wird in Docker-Containern ausgeführt, die auf den einzelnen Knoten erstellt werden.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-112">The script runs in Docker containers that are created on each node.</span></span>

1. <span data-ttu-id="4ebe6-113">Dieses Skript ruft Trainings- und Testdaten aus [Azure Storage][storage] ab.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-113">That script retrieves training and testing data from [Azure Storage][storage].</span></span>

1. <span data-ttu-id="4ebe6-114">Das Skript lernt anhand der Trainingsdaten unter Verwendung der entsprechenden Kombination aus Trainingsparametern ein Modell.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-114">The script learns a model from the training data using its combination of training parameters.</span></span>

1. <span data-ttu-id="4ebe6-115">Die Leistung des Modells wird anhand der Testdaten ermittelt und in Azure Storage geschrieben.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-115">The model's performance is evaluated on the testing data, and is written to Azure Storage.</span></span>

1. <span data-ttu-id="4ebe6-116">Das Modell mit der besten Leistung wird bei Azure Machine Learning Service registriert.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-116">The best performing model is registered with the Azure Machine Learning service.</span></span>

<span data-ttu-id="4ebe6-117">Überlegungen im Zusammenhang mit dem Trainieren von Deep  Learning-Modellen mit GPUs finden Sie [hier][training-deep-learning].</span><span class="sxs-lookup"><span data-stu-id="4ebe6-117">See also considerations for training [deep learning models][training-deep-learning] with GPUs.</span></span>

## <a name="architecture"></a><span data-ttu-id="4ebe6-118">Architecture</span><span class="sxs-lookup"><span data-stu-id="4ebe6-118">Architecture</span></span>

<span data-ttu-id="4ebe6-119">Diese Architektur besteht aus mehreren Azure-Clouddiensten, die Ressourcen nach Bedarf skalieren.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-119">This architecture consists of several Azure cloud services that scale resources according to need.</span></span> <span data-ttu-id="4ebe6-120">Im Anschluss werden die Dienste und ihre Rollen in dieser Lösung beschrieben.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-120">The services and their roles in this solution are described below.</span></span>

<span data-ttu-id="4ebe6-121">[Microsoft Data Science Virtual Machine][dsvm] (DSVM) ist ein VM-Image, das mit Tools für die Datenanalyse und für maschinelles Lernen konfiguriert ist.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-121">[Microsoft Data Science Virtual Machine][dsvm] (DSVM) is a VM image configured with tools used for data analytics and machine learning.</span></span> <span data-ttu-id="4ebe6-122">Es sind sowohl Windows Server- als auch Linux-Versionen verfügbar.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-122">Both Windows Server and Linux versions are available.</span></span> <span data-ttu-id="4ebe6-123">In dieser Bereitstellung werden die Linux-Editionen von DSVM unter Ubuntu 16.04 LTS verwendet.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-123">This deployment uses the Linux editions of the DSVM on Ubuntu 16.04 LTS.</span></span>

<span data-ttu-id="4ebe6-124">[Azure Machine Learning Service][aml] dient zum Trainieren, Bereitstellen, Automatisieren und Verwalten von Machine Learning-Modellen in der Cloud.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-124">[Azure Machine Learning service][aml] is used to train, deploy, automate, and manage machine learning models at cloud scale.</span></span> <span data-ttu-id="4ebe6-125">Der Dienst wird in dieser Architektur verwendet, um die Zuordnung und Verwendung der weiter unten beschriebenen Azure-Ressourcen zu verwalten.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-125">It's used in this architecture to manage the allocation and use of the Azure resources described below.</span></span>

<span data-ttu-id="4ebe6-126">Die Ressource [Azure Machine Learning Compute][aml-compute] wird verwendet, um Machine Learning- und KI-Modelle in Azure bedarfsabhängig zu trainieren und zu testen.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-126">[Azure Machine Learning Compute][aml-compute] is the resource used to train and test machine learning and AI models at scale in Azure.</span></span> <span data-ttu-id="4ebe6-127">Das [Computeziel][target] ist in diesem Szenario ein Cluster mit Knoten, die nach Bedarf auf der Grundlage einer automatischen [Skalierungsoption][scaling] zugeordnet werden.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-127">The [compute target][target] in this scenario is a cluster of nodes that are allocated on demand based on an automatic [scaling][scaling] option.</span></span> <span data-ttu-id="4ebe6-128">Jeder Knoten ist ein virtueller Computer, der einen Trainingsauftrag für bestimmte [Hyperparameter][hyperparameter] ausführt.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-128">Each node is a VM that runs a training job for a particular [hyperparameter][hyperparameter] set.</span></span>

<span data-ttu-id="4ebe6-129">[Azure Container Registry][acr] speichert Images für alle Arten von Docker-Containerbereitstellungen.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-129">[Azure Container Registry][acr] stores images for all types of Docker container deployments.</span></span> <span data-ttu-id="4ebe6-130">Diese Container werden auf jedem Knoten erstellt und zum Ausführen des Python-Trainingsskripts verwendet.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-130">These containers are created on each node and used to run the training Python script.</span></span> <span data-ttu-id="4ebe6-131">Das im Machine Learning Compute-Cluster verwendete Image wird von Machine Learning Service in den Notebooks für die lokale Ausführung und die Hyperparameteroptimierung erstellt und anschließend mithilfe von Push an Container Registry übertragen.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-131">The image used in the Machine Learning Compute cluster is created by the Machine Learning service in the local run and hyperparameter tuning notebooks, and then is pushed to Container Registry.</span></span>

<span data-ttu-id="4ebe6-132">[Azure Blob Storage][blob] empfängt die vom Python-Trainingsskript verwendeten Trainings- und Testdatasets von Machine Learning Service.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-132">[Azure Blob][blob] storage receives the training and test data sets from the Machine Learning service that are used by the training Python script.</span></span> <span data-ttu-id="4ebe6-133">Storage wird als virtuelles Laufwerk auf jedem Knoten eines Machine Learning Compute-Clusters eingebunden.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-133">Storage is mounted as a virtual drive onto each node of a Machine Learning Compute cluster.</span></span> 

## <a name="performance-considerations"></a><span data-ttu-id="4ebe6-134">Überlegungen zur Leistung</span><span class="sxs-lookup"><span data-stu-id="4ebe6-134">Performance considerations</span></span>

<span data-ttu-id="4ebe6-135">Die einzelnen Gruppen von [Hyperparametern][hyperparameter] werden jeweils auf einem Knoten des Machine Learning-[Computeziels][target] ausgeführt.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-135">Each set of [hyperparameters][hyperparameter] runs on one node of the Machine Learning [compute target][target].</span></span> <span data-ttu-id="4ebe6-136">In dieser Architektur ist jeder Knoten ein virtueller Computer vom Typ „Standard D4 v2“ mit vier Kernen.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-136">For this architecture, each node is a Standard D4 v2 VM, which has four cores.</span></span> <span data-ttu-id="4ebe6-137">Diese Architektur verwendet eine [LightGBM][lightgbm]-Klassifizierung für Machine Learning (ein Gradient Boosting-Framework).</span><span class="sxs-lookup"><span data-stu-id="4ebe6-137">This architecture uses a [LightGBM][lightgbm] classifier for machine learning, a gradient boosting framework.</span></span> <span data-ttu-id="4ebe6-138">Diese Software kann parallel auf allen vier Kernen ausgeführt werden und somit jede Ausführung um das bis zu Vierfache beschleunigen.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-138">This software can run on all four cores at the same time, speeding up each run by a factor of up to four.</span></span> <span data-ttu-id="4ebe6-139">Verglichen mit der Ausführung auf einem Machine Learning-Computeziel mit virtuellen Computern vom Typ „Standard D1 v2“, die jeweils nur über einen einzelnen Kern verfügen, lässt sich dadurch die Gesamtdauer der Hyperparameteroptimierung auf bis zu ein Viertel der Zeit verkürzen.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-139">That way, the whole hyperparameter tuning run takes up to one-quarter of the time it would take had it been run on a Machine Learning Compute target based on Standard D1 v2 VMs, which have only one core each.</span></span>

<span data-ttu-id="4ebe6-140">Die maximale Anzahl von Machine Learning Compute-Knoten wirkt sich auf die Gesamtlaufzeit aus.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-140">The maximum number of Machine Learning Compute nodes affects the total run time.</span></span> <span data-ttu-id="4ebe6-141">Die empfohlene Mindestanzahl für die Knoten ist Null.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-141">The recommended minimum number of nodes is zero.</span></span> <span data-ttu-id="4ebe6-142">Bei Verwendung dieser Einstellung beinhaltet die Zeit, die bis zum Start eines Auftrags vergeht, einige Minuten für die automatische Skalierung auf mindestens einen Knoten im Cluster.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-142">With this setting, the time it takes for a job to start up includes some minutes for auto-scaling at least one node into the cluster.</span></span> <span data-ttu-id="4ebe6-143">Wenn die Hyperparameteroptimierung allerdings nicht lange dauert, erhöht sich durch zentrales Hochskalieren des Auftrags der Mehraufwand.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-143">If the hyperparameter tuning runs for a short time, however, scaling up the job adds to the overhead.</span></span> <span data-ttu-id="4ebe6-144">So kann es beispielsweise sein, dass ein Auftrag in unter fünf Minuten ausgeführt wird, das zentrale Hochskalieren auf einen Knoten jedoch weitere fünf Minuten dauert.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-144">For example, a job can run in under five minutes, but scaling up to one node might take another five minutes.</span></span> <span data-ttu-id="4ebe6-145">In diesem Fall ist es schneller, das Minimum auf einen einzelnen Knoten festzulegen. Dadurch fallen allerdings höhere Kosten an.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-145">In this case, setting the minimum to one node saves time but adds to the cost.</span></span>

## <a name="monitoring-and-logging-considerations"></a><span data-ttu-id="4ebe6-146">Überlegungen zur Überwachung und Protokollierung</span><span class="sxs-lookup"><span data-stu-id="4ebe6-146">Monitoring and logging considerations</span></span>

<span data-ttu-id="4ebe6-147">Übermitteln Sie eine [HyperDrive][hyperparameter]-Laufzeitkonfiguration, um ein Ausführungsobjekt zur Überwachung des Ausführungsfortschritts zurückzugeben.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-147">Submit a [HyperDrive][hyperparameter] run configuration to return a Run object for use in monitoring the run's progress.</span></span>

### <a name="rundetails-jupyter-widget"></a><span data-ttu-id="4ebe6-148">Jupyter-Widget „RunDetails“</span><span class="sxs-lookup"><span data-stu-id="4ebe6-148">RunDetails Jupyter Widget</span></span>

<span data-ttu-id="4ebe6-149">Verwenden Sie das Ausführungsobjekt mit dem [Jupyter-Widget][jupyter] „RunDetails“, um beim Hinzufügen zur Warteschlange sowie beim Ausführen der entsprechenden untergeordneten Aufträge bequem den Fortschritt zu überwachen.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-149">Use the Run object with the RunDetails [Jupyter widget][jupyter] to conveniently monitor its progress at queuing and when running its children jobs.</span></span> <span data-ttu-id="4ebe6-150">Das Widget zeigt auch die in Echtzeit protokollierten Werte der primären Statistik an.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-150">It also shows the values of the primary statistic that they log in real time.</span></span>

### <a name="azure-portal"></a><span data-ttu-id="4ebe6-151">Azure-Portal</span><span class="sxs-lookup"><span data-stu-id="4ebe6-151">Azure portal</span></span>

<span data-ttu-id="4ebe6-152">Geben Sie ein Ausführungsobjekt aus, um einen Link zur Seite der Ausführung im Azure-Portal anzuzeigen:</span><span class="sxs-lookup"><span data-stu-id="4ebe6-152">Print a Run object to display a link to the run's page in Azure portal like this:</span></span>

![Ausführungsobjekt][1]

<span data-ttu-id="4ebe6-154">Auf dieser Seite können Sie den Status der Ausführung und der dazugehörigen untergeordneten Ausführungen überwachen.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-154">Use this page to monitor the status of the run and its children runs.</span></span> <span data-ttu-id="4ebe6-155">Jede untergeordnete Ausführung verfügt über ein Treiberprotokoll mit der Ausgabe des ausgeführten Trainingsskripts.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-155">Each child run has a driver log containing the output of the training script it has run.</span></span>

## <a name="cost-considerations"></a><span data-ttu-id="4ebe6-156">Kostenbetrachtung</span><span class="sxs-lookup"><span data-stu-id="4ebe6-156">Cost considerations</span></span>

<span data-ttu-id="4ebe6-157">Die Kosten für die Ausführung einer Hyperparameteroptimierung hängen direkt davon ab, welche VM-Größe für Machine Learning Compute gewählt wurde, ob Knoten mit niedriger Priorität verwendet werden und wie viele Knoten im Cluster maximal zulässig sind.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-157">The cost of a hyperparameter tuning run depends linearly on the choice of Machine Learning Compute VM size, whether low-priority nodes are used, and the maximum number of nodes allowed in the cluster.</span></span>

<span data-ttu-id="4ebe6-158">Die laufenden Kosten während der Nichtverwendung des Clusters hängen davon ab, wie viele Knoten der Cluster mindestens benötigt.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-158">Ongoing costs when the cluster is not in use depend on the minimum number of nodes required by the cluster.</span></span> <span data-ttu-id="4ebe6-159">Durch die automatische Clusterskalierung fügt das System automatisch eine der Auftragsanzahl entsprechende Anzahl von Knoten hinzu, bis der zulässige Maximalwert erreicht ist. Wenn die Knoten nicht mehr benötigt werden, werden sie wieder entfernt, bis nur noch die angeforderte Mindestanzahl vorhanden ist.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-159">With cluster autoscaling, the system automatically adds nodes up to the allowed maximum to match the number of jobs, and then removes nodes down to the requested minimum as they are no longer needed.</span></span> <span data-ttu-id="4ebe6-160">Falls der Cluster auf null Knoten herunterskaliert werden kann, fallen für den Cluster keinerlei Kosten an, wenn er nicht verwendet wird.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-160">If the cluster can autoscale down to zero nodes, it does not cost anything when it is not in use.</span></span>

## <a name="security-considerations"></a><span data-ttu-id="4ebe6-161">Sicherheitshinweise</span><span class="sxs-lookup"><span data-stu-id="4ebe6-161">Security considerations</span></span>

### <a name="restrict-access-to-azure-blob-storage"></a><span data-ttu-id="4ebe6-162">Beschränken des Zugriffs auf Azure Blob Storage</span><span class="sxs-lookup"><span data-stu-id="4ebe6-162">Restrict access to Azure Blob Storage</span></span>

<span data-ttu-id="4ebe6-163">In dieser Architektur werden [Speicherkontoschlüssel][storage-security] für den Zugriff auf Blob Storage verwendet.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-163">This architecture uses [storage account keys][storage-security] to access the Blob storage.</span></span> <span data-ttu-id="4ebe6-164">Für noch mehr Kontrolle und Schutz sollten Sie stattdessen Shared Access Signatur (SAS) verwenden.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-164">For further control and protection, consider using a shared access signature (SAS) instead.</span></span> <span data-ttu-id="4ebe6-165">Dadurch wird der Zugriff auf die gespeicherten Objekte eingeschränkt, ohne dass die Kontoschlüssel hartcodiert oder als Klartext gespeichert werden müssen.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-165">This grants limited access to objects in storage, without needing to hard-code the account keys or save them in plaintext.</span></span> <span data-ttu-id="4ebe6-166">Mit SAS können Sie außerdem sicherstellen, dass das Speicherkonto über eine ordnungsgemäße Governance verfügt und der Zugriff nur ausgewählten Personen gewährt wird.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-166">Using a SAS also helps to ensure that the storage account has proper governance, and that access is granted only to the people intended to have it.</span></span>

<span data-ttu-id="4ebe6-167">Stellen Sie in Szenarien mit sensibleren Daten sicher, dass alle Ihre Speicherschlüssel geschützt sind, weil diese Schlüssel den Vollzugriff auf alle Ein- und Ausgabedaten der Workload ermöglichen.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-167">For scenarios with more sensitive data, make sure that all of your storage keys are protected, because these keys grant full access to all input and output data from the workload.</span></span>

### <a name="encrypt-data-at-rest-and-in-motion"></a><span data-ttu-id="4ebe6-168">Verschlüsseln von ruhenden und übertragenen Daten</span><span class="sxs-lookup"><span data-stu-id="4ebe6-168">Encrypt data at rest and in motion</span></span>

<span data-ttu-id="4ebe6-169">In Szenarien mit sensiblen Daten müssen ruhende Daten (Daten im Speicher) verschlüsselt werden.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-169">In scenarios that use sensitive data, encrypt the data at rest—that is, the data in storage.</span></span> <span data-ttu-id="4ebe6-170">Bei Datenübertragungen müssen die Daten mithilfe von SSL geschützt werden.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-170">Each time data moves from one location to the next, use SSL to secure the data transfer.</span></span> <span data-ttu-id="4ebe6-171">Weitere Informationen finden Sie im [Azure Storage-Sicherheitsleitfaden][storage-security].</span><span class="sxs-lookup"><span data-stu-id="4ebe6-171">For more information, see the [Azure Storage security guide][storage-security].</span></span>

### <a name="secure-data-in-a-virtual-network"></a><span data-ttu-id="4ebe6-172">Schützen von Daten in einem virtuellen Netzwerk</span><span class="sxs-lookup"><span data-stu-id="4ebe6-172">Secure data in a virtual network</span></span>

<span data-ttu-id="4ebe6-173">Bei Produktionsbereitstellungen empfiehlt es sich ggf., den Cluster in einem Subnetz eines von Ihnen angegebenen virtuellen Netzwerks bereitzustellen.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-173">For production deployments, consider deploying the cluster into a subnet of a virtual network that you specify.</span></span> <span data-ttu-id="4ebe6-174">Dadurch können die Computeknoten im Cluster sicher mit anderen virtuellen Computern oder mit einem lokalen Netzwerk kommunizieren.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-174">This allows the compute nodes in the cluster to communicate securely with other virtual machines or with an on-premises network.</span></span> <span data-ttu-id="4ebe6-175">Sie können auch [Dienstendpunkte][endpoints] mit Blob Storage verwenden, um den Zugriff über ein virtuelles Netzwerk zu ermöglichen, oder ein NFS mit einem einzelnen Knoten innerhalb des virtuellen Netzwerks mit Azure Machine Learning Service.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-175">You can also use [service endpoints][endpoints] with blob storage to grant access from a virtual network or use a single-node NFS inside the virtual network with Azure Machine Learning service.</span></span>

## <a name="deployment"></a><span data-ttu-id="4ebe6-176">Bereitstellung</span><span class="sxs-lookup"><span data-stu-id="4ebe6-176">Deployment</span></span>

<span data-ttu-id="4ebe6-177">Führen Sie die Schritte im [GitHub-Repository][github] aus, um die Referenzimplementierung für diese Architektur bereitzustellen.</span><span class="sxs-lookup"><span data-stu-id="4ebe6-177">To deploy the reference implementation for this architecture, follow the steps in the [GitHub][github] repo.</span></span>

[0]: ./_images//training-python-models.png
[1]: ./_images/run-object.png
[acr]: /azure/container-registry/container-registry-intro
[ai]: /azure/application-insights/app-insights-overview
[aml]: /azure/machine-learning/service/overview-what-is-azure-ml
[aml-compute]: /azure/machine-learning/service/how-to-set-up-training-targets
[amls]: /azure/machine-learning/service/overview-what-is-azure-ml
[blob]: /azure/storage/blobs/storage-blobs-introduction
[dsvm]: /azure/machine-learning/data-science-virtual-machine/overview
[endpoints]: /azure/storage/common/storage-network-security?toc=%2fazure%2fvirtual-network%2ftoc.json#grant-access-from-a-virtual-network
[github]: https://github.com/Microsoft/MLHyperparameterTuning
[hyperparameter]: /azure/machine-learning/service/how-to-tune-hyperparameters
[jupyter]: http://jupyter.org/widgets
[lightgbm]: https://github.com/Microsoft/LightGBM
[scaling]: /azure/virtual-machine-scale-sets/overview
[scikit]: https://pypi.org/project/scikit-learn/
[storage]: /azure/storage/common/storage-introduction
[storage-security]: /azure/storage/common/storage-security-guide
[target]: /azure/machine-learning/service/how-to-auto-train-remote
[training-deep-learning]: /azure/architecture/reference-architectures/ai/training-deep-learning