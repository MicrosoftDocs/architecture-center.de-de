---
title: Batchbewertung von Python-Modellen in Azure
description: Erstellen Sie mit Azure Machine Learning Service eine skalierbare Lösung für die parallele Batchbewertung von Modellen nach einem Zeitplan.
author: njray
ms.date: 01/30/2019
ms.topic: reference-architecture
ms.service: architecture-center
ms.subservice: reference-architecture
ms.custom: azcat-ai, AI
ms.openlocfilehash: 81dc353735eaa6573c72d9e588c949fe96a329ef
ms.sourcegitcommit: eee3a35dd5a5a2f0dc117fa1c30f16d6db213ba2
ms.translationtype: HT
ms.contentlocale: de-DE
ms.lasthandoff: 02/06/2019
ms.locfileid: "55782012"
---
# <a name="batch-scoring-of-python-models-on-azure"></a><span data-ttu-id="cdbae-103">Batchbewertung von Python-Modellen in Azure</span><span class="sxs-lookup"><span data-stu-id="cdbae-103">Batch scoring of Python models on Azure</span></span>

<span data-ttu-id="cdbae-104">Diese Referenzarchitektur veranschaulicht, wie Sie mit Azure Machine Learning Service eine skalierbare Lösung für die parallele Batchbewertung vieler Modelle nach einem Zeitplan erstellen.</span><span class="sxs-lookup"><span data-stu-id="cdbae-104">This reference architecture shows how to build a scalable solution for batch scoring many models on a schedule in parallel using Azure Machine Learning Service.</span></span> <span data-ttu-id="cdbae-105">Die Lösung kann als Vorlage genutzt und für unterschiedliche Probleme generalisiert werden.</span><span class="sxs-lookup"><span data-stu-id="cdbae-105">The solution can be used as a template and can generalize to different problems.</span></span>

<span data-ttu-id="cdbae-106">Eine Referenzimplementierung für diese Architektur ist auf [GitHub][github] verfügbar.</span><span class="sxs-lookup"><span data-stu-id="cdbae-106">A reference implementation for this architecture is available on [GitHub][github].</span></span>

![Batchbewertung von Python-Modellen in Azure](./_images/batch-scoring-python.png)

<span data-ttu-id="cdbae-108">**Szenario:** Diese Lösung überwacht den Betrieb einer großen Zahl von Geräten unter einer IoT-Einstellung, wobei jedes Gerät fortlaufend Sensormesswerte sendet.</span><span class="sxs-lookup"><span data-stu-id="cdbae-108">**Scenario**: This solution monitors the operation of a large number of devices in an IoT setting where each device sends sensor readings continuously.</span></span> <span data-ttu-id="cdbae-109">Es wird vorausgesetzt, dass jedem Gerät vorab trainierte Modelle für die Anomalieerkennung zugeordnet sind, um Folgendes vorherzusagen: Entspricht eine Reihe von Messwerten, die für ein vordefiniertes Zeitintervall aggregiert werden, einer Anomalie?</span><span class="sxs-lookup"><span data-stu-id="cdbae-109">Each device is assumed to be associated with pretrained anomaly detection models that need to be used to predict whether a series of measurements, that are aggregated over a predefined time interval, correspond to an anomaly or not.</span></span> <span data-ttu-id="cdbae-110">In der Praxis kann dies ein Datenstrom mit Sensormesswerten sein, die gefiltert und aggregiert werden müssen, bevor sie für das Training oder für Echtzeitbewertungen verwendet werden.</span><span class="sxs-lookup"><span data-stu-id="cdbae-110">In real-world scenarios, this could be a stream of sensor readings that need to be filtered and aggregated before being used in training or real-time scoring.</span></span> <span data-ttu-id="cdbae-111">Der Einfachheit halber wird für diese Lösung beim Ausführen von Bewertungsaufträgen dieselbe Datendatei verwendet.</span><span class="sxs-lookup"><span data-stu-id="cdbae-111">For simplicity, this solution uses the same data file when executing scoring jobs.</span></span>

<span data-ttu-id="cdbae-112">Diese Referenzarchitektur ist für Workloads ausgelegt, die anhand eines Zeitplans ausgelöst werden.</span><span class="sxs-lookup"><span data-stu-id="cdbae-112">This reference architecture is designed for workloads that are triggered on a schedule.</span></span> <span data-ttu-id="cdbae-113">Die Verarbeitung umfasst die folgenden Schritte:</span><span class="sxs-lookup"><span data-stu-id="cdbae-113">Processing involves the following steps:</span></span>
1.  <span data-ttu-id="cdbae-114">Senden von Sensormesswerten für die Erfassung in Azure Event Hubs</span><span class="sxs-lookup"><span data-stu-id="cdbae-114">Send sensor readings for ingestion to Azure Event Hubs.</span></span>
2.  <span data-ttu-id="cdbae-115">Durchführen der Datenstromverarbeitung und Speichern der Rohdaten</span><span class="sxs-lookup"><span data-stu-id="cdbae-115">Perform stream processing and store the raw data.</span></span>
3.  <span data-ttu-id="cdbae-116">Senden der Daten an einen Machine Learning-Cluster, der für die Durchführung von Aufgaben bereit ist.</span><span class="sxs-lookup"><span data-stu-id="cdbae-116">Send the data to a Machine Learning cluster that is ready to start taking work.</span></span> <span data-ttu-id="cdbae-117">Auf jedem Knoten im Cluster wird ein Bewertungsauftrag für einen bestimmten Sensor ausgeführt.</span><span class="sxs-lookup"><span data-stu-id="cdbae-117">Each node in the cluster runs a scoring job for a specific sensor.</span></span> 
4.  <span data-ttu-id="cdbae-118">Ausführen der Bewertungspipeline, über die die Bewertungsaufträge mit Machine Learning-Python-Skripts parallel ausgeführt werden.</span><span class="sxs-lookup"><span data-stu-id="cdbae-118">Execute the scoring pipeline, which runs the scoring jobs in parallel using Machine Learning Python scripts.</span></span> <span data-ttu-id="cdbae-119">Die Pipeline wird erstellt und veröffentlicht, und es wird ein Zeitplan für die Ausführung nach einem vordefinierten Zeitintervall erstellt.</span><span class="sxs-lookup"><span data-stu-id="cdbae-119">The pipeline is created, published, and scheduled to run on a predefined interval of time.</span></span>
5.  <span data-ttu-id="cdbae-120">Generieren von Vorhersagen und Speichern im Blobspeicher zur späteren Verwendung</span><span class="sxs-lookup"><span data-stu-id="cdbae-120">Generate predictions and store them in Blob storage for later consumption.</span></span>

## <a name="architecture"></a><span data-ttu-id="cdbae-121">Architecture</span><span class="sxs-lookup"><span data-stu-id="cdbae-121">Architecture</span></span>

<span data-ttu-id="cdbae-122">Diese Architektur umfasst die folgenden Komponenten:</span><span class="sxs-lookup"><span data-stu-id="cdbae-122">This architecture consists of the following components:</span></span>

<span data-ttu-id="cdbae-123">[Azure Event Hubs][event-hubs]:</span><span class="sxs-lookup"><span data-stu-id="cdbae-123">[Azure Event Hubs][event-hubs].</span></span> <span data-ttu-id="cdbae-124">Mit diesem Dienst für die Nachrichtenerfassung können Millionen von Ereignismeldungen pro Sekunde erfasst werden.</span><span class="sxs-lookup"><span data-stu-id="cdbae-124">This message ingestion service can ingest millions of event messages per second.</span></span> <span data-ttu-id="cdbae-125">In dieser Architektur senden Sensoren einen Datenstrom an den Event Hub.</span><span class="sxs-lookup"><span data-stu-id="cdbae-125">In this architecture, sensors send a stream of data to the event hub.</span></span>

<span data-ttu-id="cdbae-126">[Azure Stream Analytics][stream-analytics]:</span><span class="sxs-lookup"><span data-stu-id="cdbae-126">[Azure Stream Analytics][stream-analytics].</span></span> <span data-ttu-id="cdbae-127">Ein Modul für die Ereignisverarbeitung.</span><span class="sxs-lookup"><span data-stu-id="cdbae-127">An event-processing engine.</span></span> <span data-ttu-id="cdbae-128">Ein Stream Analytics-Auftrag liest die Datenströme aus dem Event Hub und führt die Datenstromverarbeitung durch.</span><span class="sxs-lookup"><span data-stu-id="cdbae-128">A Stream Analytics job reads the data streams from the event hub and performs stream processing.</span></span>

<span data-ttu-id="cdbae-129">[Azure SQL-Datenbank][sql-database]:</span><span class="sxs-lookup"><span data-stu-id="cdbae-129">[Azure SQL Database][sql-database].</span></span> <span data-ttu-id="cdbae-130">Daten der Sensormesswerte werden in SQL-Datenbank geladen.</span><span class="sxs-lookup"><span data-stu-id="cdbae-130">Data from the sensor readings is loaded into SQL Database.</span></span> <span data-ttu-id="cdbae-131">SQL ist eine vertraute Möglichkeit, die verarbeiteten gestreamten Daten (tabellarisch und strukturiert) zu speichern, aber es können auch andere Datenspeicher verwendet werden.</span><span class="sxs-lookup"><span data-stu-id="cdbae-131">SQL is a familiar way to store the processed, streamed data (which is tabular and structured), but other data stores can be used.</span></span>

<span data-ttu-id="cdbae-132">[Azure Machine Learning Service][amls]:</span><span class="sxs-lookup"><span data-stu-id="cdbae-132">[Azure Machine Learning Service][amls].</span></span> <span data-ttu-id="cdbae-133">Machine Learning ist ein Clouddienst für das bedarfsorientierte Trainieren, Bewerten, Bereitstellen und Verwalten von Machine Learning-Modellen.</span><span class="sxs-lookup"><span data-stu-id="cdbae-133">Machine Learning is a cloud service for training, scoring, deploying, and managing machine learning models at scale.</span></span> <span data-ttu-id="cdbae-134">Im Kontext der Batchbewertung wird bei Machine Learning bedarfsabhängig ein Cluster mit virtuellen Computern erstellt, der über eine Option für die automatische Skalierung verfügt, und jeder Knoten führt einen Bewertungsauftrag für einen bestimmten Sensor aus.</span><span class="sxs-lookup"><span data-stu-id="cdbae-134">In the context of batch scoring, Machine Learning creates a cluster of virtual machines on demand with an automatic scaling option, where each node in the cluster runs a scoring job for a specific sensor.</span></span> <span data-ttu-id="cdbae-135">Die Bewertungsaufträge werden parallel als Python-Skriptschritte ausgeführt, die von Machine Learning in eine Warteschlange eingereiht und verwaltet werden.</span><span class="sxs-lookup"><span data-stu-id="cdbae-135">The scoring jobs are executed in parallel as Python-script steps that are queued and managed by Machine Learning.</span></span> <span data-ttu-id="cdbae-136">Diese Schritte sind Teil einer Machine Learning-Pipeline, die erstellt und veröffentlicht wird und für die die Ausführung nach einem vordefinierten Zeitintervall geplant wird.</span><span class="sxs-lookup"><span data-stu-id="cdbae-136">These steps are part of a Machine Learning pipeline that is created, published, and scheduled to run on a predefined interval of time.</span></span>

<span data-ttu-id="cdbae-137">[Azure Blob Storage][storage]:</span><span class="sxs-lookup"><span data-stu-id="cdbae-137">[Azure Blob Storage][storage].</span></span> <span data-ttu-id="cdbae-138">Blobcontainer werden zum Speichern der vorab trainierten Modelle, der Daten und der Ausgabevorhersagen verwendet.</span><span class="sxs-lookup"><span data-stu-id="cdbae-138">Blob containers are used to store the pretrained models, the data, and the output predictions.</span></span> <span data-ttu-id="cdbae-139">Die Modelle werden im Notebook [01_create_resources.ipynb][create-resources] in den Blobspeicher hochgeladen.</span><span class="sxs-lookup"><span data-stu-id="cdbae-139">The models are uploaded to Blob storage in the [01_create_resources.ipynb][create-resources] notebook.</span></span> <span data-ttu-id="cdbae-140">Diese Modelle vom Typ [Einklassige SVM][one-class-svm] werden mit Daten trainiert, die Werte unterschiedlicher Sensoren für unterschiedliche Geräte repräsentieren.</span><span class="sxs-lookup"><span data-stu-id="cdbae-140">These [one-class SVM][one-class-svm] models are trained on data that represents values of different sensors for different devices.</span></span> <span data-ttu-id="cdbae-141">Bei dieser Lösung wird davon ausgegangen, dass die Datenwerte während eines festen Zeitintervalls aggregiert werden.</span><span class="sxs-lookup"><span data-stu-id="cdbae-141">This solution assumes that the data values are aggregated over a fixed interval of time.</span></span>

<span data-ttu-id="cdbae-142">[Azure Container Registry][acr]:</span><span class="sxs-lookup"><span data-stu-id="cdbae-142">[Azure Container Registry][acr].</span></span> <span data-ttu-id="cdbae-143">Das [Python-Skript][pyscript] für die Bewertung wird in Docker-Containern ausgeführt, die auf jedem Knoten des Clusters erstellt werden. Hiermit werden die relevanten Sensordaten gelesen und Vorhersagen generiert und im Blobspeicher gespeichert.</span><span class="sxs-lookup"><span data-stu-id="cdbae-143">The scoring Python [script][pyscript] runs in Docker containers that are created on each node of the cluster, where it reads the relevant sensor data, generates predictions and stores them in Blob storage.</span></span>

## <a name="performance-considerations"></a><span data-ttu-id="cdbae-144">Überlegungen zur Leistung</span><span class="sxs-lookup"><span data-stu-id="cdbae-144">Performance considerations</span></span>

<span data-ttu-id="cdbae-145">Für Python-Standardmodelle sind CPUs, die zum Bewältigen der Workload ausreichen, in der Regel akzeptabel.</span><span class="sxs-lookup"><span data-stu-id="cdbae-145">For standard Python models, it's generally accepted that CPUs are sufficient to handle the workload.</span></span> <span data-ttu-id="cdbae-146">In dieser Architektur werden CPUs verwendet.</span><span class="sxs-lookup"><span data-stu-id="cdbae-146">This architecture uses CPUs.</span></span> <span data-ttu-id="cdbae-147">Bei [Deep Learning-Workloads][deep] bieten GPUs aber eine deutlich bessere Leistung als CPUs. In der Regel wird ein großer Cluster mit CPUs benötigt, um eine vergleichbare Leistung zu erzielen.</span><span class="sxs-lookup"><span data-stu-id="cdbae-147">However, for [deep learning workloads][deep], GPUs generally outperform CPUs by a considerable amount—a sizeable cluster of CPUs is usually needed to get comparable performance.</span></span>

### <a name="parallelizing-across-vms-vs-cores"></a><span data-ttu-id="cdbae-148">Vergleich zwischen Parallelisieren auf VMs und Kernen</span><span class="sxs-lookup"><span data-stu-id="cdbae-148">Parallelizing across VMs vs cores</span></span>

<span data-ttu-id="cdbae-149">Beim Ausführen von Bewertungsprozessen für viele Modelle im Batchmodus müssen die Aufträge VM-übergreifend parallelisiert werden.</span><span class="sxs-lookup"><span data-stu-id="cdbae-149">When running scoring processes of many models in batch mode, the jobs need to be parallelized across VMs.</span></span> <span data-ttu-id="cdbae-150">Zwei Ansätze sind möglich:</span><span class="sxs-lookup"><span data-stu-id="cdbae-150">Two approaches are possible:</span></span>

* <span data-ttu-id="cdbae-151">Erstellen eines größeren Clusters mit kostengünstigen VMs</span><span class="sxs-lookup"><span data-stu-id="cdbae-151">Create a larger cluster using low-cost VMs.</span></span>

* <span data-ttu-id="cdbae-152">Erstellen eines kleineren Clusters mit Hochleistungs-VMs, die jeweils über mehr Kerne verfügen</span><span class="sxs-lookup"><span data-stu-id="cdbae-152">Create a smaller cluster using high performing VMs with more cores available on each.</span></span>

<span data-ttu-id="cdbae-153">Im Allgemeinen ist das Bewerten von Python-Standardmodellen nicht so anspruchsvoll wie das Bewerten von Deep Learning-Modellen. Mit einem kleinen Cluster sollte es möglich sein, eine große Zahl von in der Warteschlange befindlichen Modellen effizient zu verarbeiten.</span><span class="sxs-lookup"><span data-stu-id="cdbae-153">In general, scoring of standard Python models is not as demanding as scoring of deep learning models, and a small cluster should be able to handle a large number of queued models efficiently.</span></span> <span data-ttu-id="cdbae-154">Sie können die Anzahl von Clusterknoten erhöhen, wenn die Größe der Datasets zunimmt.</span><span class="sxs-lookup"><span data-stu-id="cdbae-154">You can increase the number of cluster nodes as the dataset sizes increase.</span></span>

<span data-ttu-id="cdbae-155">Der Einfachheit halber wird in diesem Szenario für einen Machine Learning-Pipelineschritt nur eine Bewertungsaufgabe übermittelt.</span><span class="sxs-lookup"><span data-stu-id="cdbae-155">For convenience in this scenario, one scoring task is submitted within a single Machine Learning pipeline step.</span></span> <span data-ttu-id="cdbae-156">Es kann aber auch effizienter sein, mehrere Datenblöcke innerhalb desselben Pipelineschritts zu bewerten.</span><span class="sxs-lookup"><span data-stu-id="cdbae-156">However, it can be more efficient to score multiple data chunks within the same pipeline step.</span></span> <span data-ttu-id="cdbae-157">Schreiben Sie in diesen Fällen benutzerdefinierten Code, mit dem mehrere Datasets eingelesen werden und das entsprechende Bewertungsskript während eines einzelnen Schritts ausgeführt wird.</span><span class="sxs-lookup"><span data-stu-id="cdbae-157">In those cases, write custom code to read in multiple datasets and execute the scoring script for those during a single-step execution.</span></span>

## <a name="management-considerations"></a><span data-ttu-id="cdbae-158">Überlegungen zur Verwaltung</span><span class="sxs-lookup"><span data-stu-id="cdbae-158">Management considerations</span></span>

- <span data-ttu-id="cdbae-159">**Überwachen von Aufträgen**:</span><span class="sxs-lookup"><span data-stu-id="cdbae-159">**Monitor jobs**.</span></span> <span data-ttu-id="cdbae-160">Es ist wichtig, den Status von ausgeführten Aufträgen zu überwachen, aber es kann eine ziemliche Herausforderung darstellen, einen gesamten Cluster mit aktiven Knoten zu überwachen.</span><span class="sxs-lookup"><span data-stu-id="cdbae-160">It's important to monitor the progress of running jobs, but it can be a challenge to monitor across a cluster of active nodes.</span></span> <span data-ttu-id="cdbae-161">Verwenden Sie für die Untersuchung des Zustands der Knoten im Cluster das [Azure-Portal][portal], um den [Machine Learning-Arbeitsbereich][ml-workspace] zu verwalten.</span><span class="sxs-lookup"><span data-stu-id="cdbae-161">To inspect the state of the nodes in the cluster, use the [Azure Portal][portal] to manage the [machine learning workspace][ml-workspace].</span></span> <span data-ttu-id="cdbae-162">Wenn ein Knoten inaktiv oder ein Auftrag fehlgeschlagen ist, werden die Fehlerprotokolle im Blobspeicher gespeichert und sind auch über den Abschnitt „Pipelines“ zugänglich.</span><span class="sxs-lookup"><span data-stu-id="cdbae-162">If a node is inactive or a job has failed, the error logs are saved to blob storage, and are also accessible in the Pipelines section.</span></span> <span data-ttu-id="cdbae-163">Verbinden Sie zum Durchführen einer umfassenderen Überwachung Protokolle mit [Application Insights][app-insights], oder führen Sie separate Prozesse aus, um den Status des Clusters und der zugehörigen Aufträge abzufragen.</span><span class="sxs-lookup"><span data-stu-id="cdbae-163">For richer monitoring, connect logs to [Application Insights][app-insights], or run separate processes to poll for the state of the cluster and its jobs.</span></span>
-   <span data-ttu-id="cdbae-164">**Protokollierung**:</span><span class="sxs-lookup"><span data-stu-id="cdbae-164">**Logging**.</span></span> <span data-ttu-id="cdbae-165">Machine Learning Service protokolliert alle stdout/stderr-Vorgänge für das zugeordnete Azure Storage-Konto.</span><span class="sxs-lookup"><span data-stu-id="cdbae-165">Machine Learning Service logs all stdout/stderr to the associated Azure Storage account.</span></span> <span data-ttu-id="cdbae-166">Verwenden Sie ein Speichernavigationstool, z.B. [Azure Storage-Explorer][explorer], um die Protokolldateien leicht anzeigen zu können.</span><span class="sxs-lookup"><span data-stu-id="cdbae-166">To easily view the log files, use a storage navigation tool such as [Azure Storage Explorer][explorer].</span></span>

## <a name="cost-considerations"></a><span data-ttu-id="cdbae-167">Kostenbetrachtung</span><span class="sxs-lookup"><span data-stu-id="cdbae-167">Cost considerations</span></span>

<span data-ttu-id="cdbae-168">Die teuersten Komponenten, die in dieser Referenzarchitektur genutzt werden, sind die Computeressourcen.</span><span class="sxs-lookup"><span data-stu-id="cdbae-168">The most expensive components used in this reference architecture are the compute resources.</span></span> <span data-ttu-id="cdbae-169">Die Größe des Computeclusters wird je nach den Aufträgen in der Warteschlange zentral hoch- und herunterskaliert.</span><span class="sxs-lookup"><span data-stu-id="cdbae-169">The compute cluster size scales up and down depending on the jobs in the queue.</span></span> <span data-ttu-id="cdbae-170">Aktivieren Sie die automatische Skalierung programmgesteuert über das Python SDK, indem Sie die Bereitstellungskonfiguration der Computeumgebung ändern.</span><span class="sxs-lookup"><span data-stu-id="cdbae-170">Enable automatic scaling programmatically through the Python SDK by modifying the compute’s provisioning configuration.</span></span> <span data-ttu-id="cdbae-171">Sie können auch die [Azure CLI][cli] verwenden, um die Parameter für die automatische Skalierung des Clusters festzulegen.</span><span class="sxs-lookup"><span data-stu-id="cdbae-171">Or use the [Azure CLI][cli] to set the automatic scaling parameters of the cluster.</span></span>

<span data-ttu-id="cdbae-172">Konfigurieren Sie für Aufträge, die nicht direkt verarbeitet werden müssen, die Formel für die automatische Skalierung so, dass der Standardzustand (Minimum) ein Cluster von null Knoten ist.</span><span class="sxs-lookup"><span data-stu-id="cdbae-172">For work that doesn't require immediate processing, configure the automatic scaling formula so the default state (minimum) is a cluster of zero nodes.</span></span> <span data-ttu-id="cdbae-173">Bei dieser Konfiguration hat der Cluster anfangs null Knoten. Er skaliert nur dann zentral hoch, wenn er Aufträge in der Warteschlange erkennt.</span><span class="sxs-lookup"><span data-stu-id="cdbae-173">With this configuration, the cluster starts with zero nodes and only scales up when it detects jobs in the queue.</span></span> <span data-ttu-id="cdbae-174">Wenn die Batchbewertung maximal einige Male am Tag ausgeführt wird, können Sie mithilfe dieser Einstellung eine erhebliche Kosteneinsparung erzielen.</span><span class="sxs-lookup"><span data-stu-id="cdbae-174">If the batch scoring process happens only a few times a day or less, this setting enables significant cost savings.</span></span>

<span data-ttu-id="cdbae-175">Die automatische Skalierung ist ggf. nicht für Batchaufträge geeignet, die zeitlich zu nahe beieinander liegen.</span><span class="sxs-lookup"><span data-stu-id="cdbae-175">Automatic scaling may not be appropriate for batch jobs that happen too close to each other.</span></span> <span data-ttu-id="cdbae-176">Für die benötigte Zeit zum Erstellen und Entfernen eines Clusters fallen ebenfalls Kosten an. Wenn eine Batchworkload also nur wenige Minuten nach dem Ende des vorherigen Auftrags startet, ist es ggf. kostengünstiger, den Cluster permanent auszuführen – also auch in der Zeit zwischen den Aufträgen.</span><span class="sxs-lookup"><span data-stu-id="cdbae-176">The time that it takes for a cluster to spin up and spin down also incurs a cost, so if a batch workload begins only a few minutes after the previous job ends, it might be more cost effective to keep the cluster running between jobs.</span></span> <span data-ttu-id="cdbae-177">Dies hängt davon ab, ob die Ausführung von Bewertungsprozessen mit hoher Häufigkeit (z.B. jede Stunde) oder geringerer Häufigkeit (z.B. einmal pro Monat) geplant ist.</span><span class="sxs-lookup"><span data-stu-id="cdbae-177">That depends on whether scoring processes are scheduled to run at a high frequency (every hour, for example), or less frequently (once a month, for example).</span></span>


## <a name="deployment"></a><span data-ttu-id="cdbae-178">Bereitstellung</span><span class="sxs-lookup"><span data-stu-id="cdbae-178">Deployment</span></span>

<span data-ttu-id="cdbae-179">Befolgen Sie die Schritte im Abschnitt [GitHub-Repository][github], um diese Referenzarchitektur bereitzustellen.</span><span class="sxs-lookup"><span data-stu-id="cdbae-179">To deploy this reference architecture, follow the steps described in the [GitHub repo][github].</span></span>

[acr]: /azure/container-registry/container-registry-intro
[ai]: /azure/application-insights/app-insights-overview
[aml-compute]: /azure/machine-learning/service/how-to-set-up-training-targets#amlcompute
[amls]: /azure/machine-learning/service/overview-what-is-azure-ml
[automatic-scaling]: /azure/batch/batch-automatic-scaling
[azure-files]: /azure/storage/files/storage-files-introduction
[cli]: https://docs.microsoft.com/en-us/cli/azure
[create-resources]: https://github.com/Microsoft/AMLBatchScoringPipeline/blob/master/01_create_resources.ipynb
[deep]: /azure/architecture/reference-architectures/ai/batch-scoring-deep-learning
[event-hubs]: /azure/event-hubs/event-hubs-geo-dr
[explorer]: https://azure.microsoft.com/en-us/features/storage-explorer/
[github]: https://github.com/Microsoft/AMLBatchScoringPipeline
[one-class-svm]: http://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html
[portal]: https://portal.azure.com
[ml-workspace]: https://docs.microsoft.com/en-us/azure/machine-learning/studio/create-workspace
[python-script]: https://github.com/Azure/BatchAIAnomalyDetection/blob/master/batchai/predict.py
[pyscript]: https://github.com/Microsoft/AMLBatchScoringPipeline/blob/master/scripts/predict.py
[storage]: /azure/storage/blobs/storage-blobs-overview
[stream-analytics]: /azure/stream-analytics/
[sql-database]: https://docs.microsoft.com/en-us/azure/sql-database/
[app-insights]: https://docs.microsoft.com/en-us/azure/application-insights/app-insights-overview
