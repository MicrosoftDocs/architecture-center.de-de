---
title: Batchbewertung für Deep Learning-Modelle
titleSuffix: Azure Reference Architectures
description: Diese Referenzarchitektur zeigt, wie Sie mit Azure Machine Learning die neuronale Stilübertragung auf ein Video anwenden.
author: jiata
ms.date: 02/06/2019
ms.topic: reference-architecture
ms.service: architecture-center
ms.subservice: reference-architecture
ms.custom: azcat-ai
ms.openlocfilehash: a1c0701185c85f8e7bcbc183b32c4834529fc524
ms.sourcegitcommit: 1a3cc91530d56731029ea091db1f15d41ac056af
ms.translationtype: HT
ms.contentlocale: de-DE
ms.lasthandoff: 04/03/2019
ms.locfileid: "58887861"
---
# <a name="batch-scoring-of-deep-learning-models-on-azure"></a><span data-ttu-id="6a191-103">Batchbewertung von Deep Learning-Modellen in Azure</span><span class="sxs-lookup"><span data-stu-id="6a191-103">Batch scoring of deep learning models on Azure</span></span>

<span data-ttu-id="6a191-104">Diese Referenzarchitektur zeigt, wie Sie mit Azure Machine Learning die neuronale Stilübertragung auf ein Video anwenden.</span><span class="sxs-lookup"><span data-stu-id="6a191-104">This reference architecture shows how to apply neural style transfer to a video, using Azure Machine Learning.</span></span> <span data-ttu-id="6a191-105">*Stilübertragung* ist eine Deep Learning-Technik, bei der ein vorhandenes Bild im Stil eines anderen Bildes erstellt wird.</span><span class="sxs-lookup"><span data-stu-id="6a191-105">*Style transfer* is a deep learning technique that composes an existing image in the style of another image.</span></span> <span data-ttu-id="6a191-106">Diese Architektur kann generell für jedes Szenario für Batchbewertung mit Deep Learning verwendet werden.</span><span class="sxs-lookup"><span data-stu-id="6a191-106">This architecture can be generalized for any scenario that uses batch scoring with deep learning.</span></span> <span data-ttu-id="6a191-107">[**Stellen Sie diese Lösung bereit**](#deploy-the-solution).</span><span class="sxs-lookup"><span data-stu-id="6a191-107">[**Deploy this solution**](#deploy-the-solution).</span></span>

![Architekturdiagramm für Deep Learning-Modelle mit Azure Machine Learning](./_images/aml-scoring-deep-learning.png)

<span data-ttu-id="6a191-109">**Szenario:** Ein Medienunternehmen möchte den Stil eines Videos so ändern, dass er dem eines bestimmten Gemäldes entspricht.</span><span class="sxs-lookup"><span data-stu-id="6a191-109">**Scenario**: A media organization has a video whose style they want to change to look like a specific painting.</span></span> <span data-ttu-id="6a191-110">Das Unternehmen möchte diesen Stil schnell und automatisiert auf alle Videoframes anwenden.</span><span class="sxs-lookup"><span data-stu-id="6a191-110">The organization wants to be able to apply this style to all frames of the video in a timely manner and in an automated fashion.</span></span> <span data-ttu-id="6a191-111">Weitere Informationen zu Algorithmen für die neuronale Stilübertragung finden Sie unter [Image Style Transfer Using Convolutional Neural Networks][image-style-transfer] („Bildstilübertragung mit Convolutional Neural Networks“, PDF).</span><span class="sxs-lookup"><span data-stu-id="6a191-111">For more background about neural style transfer algorithms, see [Image Style Transfer Using Convolutional Neural Networks][image-style-transfer] (PDF).</span></span>

<!-- markdownlint-disable MD033 -->

| <span data-ttu-id="6a191-112">Stilbild:</span><span class="sxs-lookup"><span data-stu-id="6a191-112">Style image:</span></span> | <span data-ttu-id="6a191-113">Eingabe-/Inhaltsvideo:</span><span class="sxs-lookup"><span data-stu-id="6a191-113">Input/content video:</span></span> | <span data-ttu-id="6a191-114">Ausgabevideo:</span><span class="sxs-lookup"><span data-stu-id="6a191-114">Output video:</span></span> |
|--------|--------|---------|
| <img src="https://happypathspublic.blob.core.windows.net/assets/batch_scoring_for_dl/style_image.jpg" width="300"> | <span data-ttu-id="6a191-115">[<img src="https://happypathspublic.blob.core.windows.net/assets/batch_scoring_for_dl/input_video_image_0.jpg" width="300" height="300">](https://happypathspublic.blob.core.windows.net/assets/batch_scoring_for_dl/input_video.mp4 "Eingabevideo") *Zum Wiedergeben klicken*</span><span class="sxs-lookup"><span data-stu-id="6a191-115">[<img src="https://happypathspublic.blob.core.windows.net/assets/batch_scoring_for_dl/input_video_image_0.jpg" width="300" height="300">](https://happypathspublic.blob.core.windows.net/assets/batch_scoring_for_dl/input_video.mp4 "Input Video") *click to view video*</span></span> | <span data-ttu-id="6a191-116">[<img src="https://happypathspublic.blob.core.windows.net/assets/batch_scoring_for_dl/output_video_image_0.jpg" width="300" height="300">](https://happypathspublic.blob.core.windows.net/assets/batch_scoring_for_dl/output_video.mp4 "Ausgabevideo") *Zur Wiedergeben klicken*</span><span class="sxs-lookup"><span data-stu-id="6a191-116">[<img src="https://happypathspublic.blob.core.windows.net/assets/batch_scoring_for_dl/output_video_image_0.jpg" width="300" height="300">](https://happypathspublic.blob.core.windows.net/assets/batch_scoring_for_dl/output_video.mp4 "Output Video") *click to view video*</span></span> |

<!-- markdownlint-enable MD033 -->

<span data-ttu-id="6a191-117">Diese Referenzarchitektur ist für Workloads konzipiert, die durch das Vorhandensein neuer Medien im Azure-Speicher ausgelöst werden.</span><span class="sxs-lookup"><span data-stu-id="6a191-117">This reference architecture is designed for workloads that are triggered by the presence of new media in Azure storage.</span></span>

<span data-ttu-id="6a191-118">Die Verarbeitung umfasst die folgenden Schritte:</span><span class="sxs-lookup"><span data-stu-id="6a191-118">Processing involves the following steps:</span></span>

1. <span data-ttu-id="6a191-119">Eine Videodatei wird in den Speicher hochgeladen.</span><span class="sxs-lookup"><span data-stu-id="6a191-119">Upload a video file to storage.</span></span>
1. <span data-ttu-id="6a191-120">Die Videodatei löst für eine Logik-App das Senden einer Anforderung an den Endpunkt aus, der von der Azure Machine Learning-Pipeline veröffentlicht wird.</span><span class="sxs-lookup"><span data-stu-id="6a191-120">The video file triggers a Logic App to send a request to the Azure Machine Learning pipeline published endpoint.</span></span>
1. <span data-ttu-id="6a191-121">Die Pipeline verarbeitet das Video, wendet die Stilübertragung mit MPI an und führt die Nachbearbeitung des Videos durch.</span><span class="sxs-lookup"><span data-stu-id="6a191-121">The pipeline processes the video, applies style transfer with MPI, and postprocesses the video.</span></span>
1. <span data-ttu-id="6a191-122">Die Ausgabe wird wieder im Blobspeicher gespeichert, nachdem die Pipeline abgeschlossen wurde.</span><span class="sxs-lookup"><span data-stu-id="6a191-122">The output is saved back to blob storage once the pipeline is completed.</span></span>

## <a name="architecture"></a><span data-ttu-id="6a191-123">Architecture</span><span class="sxs-lookup"><span data-stu-id="6a191-123">Architecture</span></span>

<span data-ttu-id="6a191-124">Diese Architektur umfasst die folgenden Komponenten.</span><span class="sxs-lookup"><span data-stu-id="6a191-124">This architecture consists of the following components.</span></span>

### <a name="compute"></a><span data-ttu-id="6a191-125">Compute</span><span class="sxs-lookup"><span data-stu-id="6a191-125">Compute</span></span>

<span data-ttu-id="6a191-126">Für **[Azure Machine Learning Service][amls]** werden Azure Machine Learning-Pipelines verwendet, um reproduzierbare und einfach zu verwaltende Berechnungssequenzen zu erstellen.</span><span class="sxs-lookup"><span data-stu-id="6a191-126">**[Azure Machine Learning Service][amls]** uses Azure Machine Learning Pipelines to create reproducible and easy-to-manage sequences of computation.</span></span> <span data-ttu-id="6a191-127">Darüber hinaus ist ein verwaltetes Computeziel mit dem Namen [Azure Machine Learning Compute][aml-compute] (auf dem eine Pipelineberechnung durchgeführt werden kann) verfügbar, mit dem Machine Learning-Modelle trainiert, bereitgestellt und bewertet werden können.</span><span class="sxs-lookup"><span data-stu-id="6a191-127">It also offers a managed compute target (on which a pipeline computation can run) called [Azure Machine Learning Compute][aml-compute] for training, deploying, and scoring machine learning models.</span></span>

### <a name="storage"></a><span data-ttu-id="6a191-128">Storage</span><span class="sxs-lookup"><span data-stu-id="6a191-128">Storage</span></span>

<span data-ttu-id="6a191-129">**[Blobspeicher][blob-storage]** wird verwendet, um alle Bilder (Eingabebilder, Stilbilder und Ausgabebilder) zu speichern.</span><span class="sxs-lookup"><span data-stu-id="6a191-129">**[Blob storage][blob-storage]** is used to store all images (input images, style images, and output images).</span></span> <span data-ttu-id="6a191-130">Azure Machine Learning Service wird mit Blobspeicher integriert, damit Benutzer Daten nicht manuell über Computeplattformen und Blobspeicher hinweg verschieben müssen.</span><span class="sxs-lookup"><span data-stu-id="6a191-130">Azure Machine Learning Service integrates with Blob storage so that users do not have to manually move data across compute platforms and Blob storage.</span></span> <span data-ttu-id="6a191-131">Blob Storage ist außerdem sehr kostengünstig für die Leistung, die diese Workload erfordert.</span><span class="sxs-lookup"><span data-stu-id="6a191-131">Blob storage is also very cost-effective for the performance that this workload requires.</span></span>

### <a name="trigger--scheduling"></a><span data-ttu-id="6a191-132">Trigger/Planung</span><span class="sxs-lookup"><span data-stu-id="6a191-132">Trigger / scheduling</span></span>

<span data-ttu-id="6a191-133">**[Azure Logic Apps][logic-apps]** löst den Workflow aus.</span><span class="sxs-lookup"><span data-stu-id="6a191-133">**[Azure Logic Apps][logic-apps]** is used to trigger the workflow.</span></span> <span data-ttu-id="6a191-134">Wenn die Logik-App erkennt, dass dem Container ein Blob hinzugefügt wurde, löst sie die Azure Machine Learning-Pipeline aus.</span><span class="sxs-lookup"><span data-stu-id="6a191-134">When the Logic App detects that a blob has been added to the container, it triggers the Azure Machine Learning Pipeline.</span></span> <span data-ttu-id="6a191-135">Logic Apps passt gut zu dieser Referenzarchitektur, da mit dem Dienst Änderungen an Blob Storage einfach erkannt und Trigger leicht geändert werden können.</span><span class="sxs-lookup"><span data-stu-id="6a191-135">Logic Apps is a good fit for this reference architecture because it's an easy way to detect changes to blob storage and provides an easy process for changing the trigger.</span></span>

### <a name="preprocessing-and-postprocessing-our-data"></a><span data-ttu-id="6a191-136">Vorabverarbeiten und Nachbearbeiten unserer Daten</span><span class="sxs-lookup"><span data-stu-id="6a191-136">Preprocessing and postprocessing our data</span></span>

<span data-ttu-id="6a191-137">Diese Referenzarchitektur verwendet Videomaterial von einem Orang-Utan auf einem Baum.</span><span class="sxs-lookup"><span data-stu-id="6a191-137">This reference architecture uses video footage of an orangutan in a tree.</span></span> <span data-ttu-id="6a191-138">Sie können das Material [hier][source-video] herunterladen.</span><span class="sxs-lookup"><span data-stu-id="6a191-138">You can download the footage from [here][source-video].</span></span>

1. <span data-ttu-id="6a191-139">Verwenden Sie [FFmpeg][ffmpeg], um die Audiodatei aus dem Videomaterial zu extrahieren, damit sie später wieder mit dem Ausgabevideo zusammengefügt werden kann.</span><span class="sxs-lookup"><span data-stu-id="6a191-139">Use [FFmpeg][ffmpeg] to extract the audio file from the video footage, so that the audio file can be stitched back into the output video later.</span></span>
1. <span data-ttu-id="6a191-140">Teilen Sie das Video mithilfe von FFmpeg in einzelne Frames auf.</span><span class="sxs-lookup"><span data-stu-id="6a191-140">Use FFmpeg to break the video into individual frames.</span></span> <span data-ttu-id="6a191-141">Die Frames werden unabhängig voneinander parallel verarbeitet.</span><span class="sxs-lookup"><span data-stu-id="6a191-141">The frames will be processed independently, in parallel.</span></span>
1. <span data-ttu-id="6a191-142">An diesem Punkt können wir die neuronale Stilübertragung parallel auf die einzelnen Frames anwenden.</span><span class="sxs-lookup"><span data-stu-id="6a191-142">At this point, we can apply neural style transfer to each individual frame in parallel.</span></span>
1. <span data-ttu-id="6a191-143">Nachdem die einzelnen Frames verarbeitet wurden, müssen wir FFmpeg verwenden, um die Frames wieder zusammenzufügen.</span><span class="sxs-lookup"><span data-stu-id="6a191-143">One each frame has been processed, we need to use FFmpeg to restitch the frames back together.</span></span>
1. <span data-ttu-id="6a191-144">Abschließend fügen wir die Audiodatei wieder an das zusammengefügte Material an.</span><span class="sxs-lookup"><span data-stu-id="6a191-144">Finally we reattach the audio file to the restitched footage.</span></span>

## <a name="performance-considerations"></a><span data-ttu-id="6a191-145">Überlegungen zur Leistung</span><span class="sxs-lookup"><span data-stu-id="6a191-145">Performance considerations</span></span>

### <a name="gpu-versus-cpu"></a><span data-ttu-id="6a191-146">Vergleich von GPU und CPU</span><span class="sxs-lookup"><span data-stu-id="6a191-146">GPU versus CPU</span></span>

<span data-ttu-id="6a191-147">Bei Deep Learning-Workloads bieten GPUs eine deutlich bessere Leistung als CPUs, sodass in der Regel ein großer Cluster von CPUs benötigt wird, um eine vergleichbare Leistung zu erzielen.</span><span class="sxs-lookup"><span data-stu-id="6a191-147">For deep learning workloads, GPUs will generally out-perform CPUs by a considerable amount, to the extent that a sizeable cluster of CPUs is usually needed to get comparable performance.</span></span> <span data-ttu-id="6a191-148">Obwohl die Option besteht, in dieser Architektur nur CPUs zu verwenden, bieten GPUs ein viel besseres Preis-Leistungs-Verhältnis.</span><span class="sxs-lookup"><span data-stu-id="6a191-148">While it's an option to use only CPUs in this architecture, GPUs will provide a much better cost/performance profile.</span></span> <span data-ttu-id="6a191-149">Es wird empfohlen, die neueste GPU-optimierte VM-Größe (NCv3-Serie) zu verwenden.</span><span class="sxs-lookup"><span data-stu-id="6a191-149">We recommend using the latest [NCv3 series]vm-sizes-gpu of GPU optimized VMs.</span></span>

<span data-ttu-id="6a191-150">GPUs sind nicht in allen Regionen standardmäßig aktiviert.</span><span class="sxs-lookup"><span data-stu-id="6a191-150">GPUs are not enabled by default in all regions.</span></span> <span data-ttu-id="6a191-151">Wählen Sie deshalb eine Region aus, in der GPUs aktiviert sind.</span><span class="sxs-lookup"><span data-stu-id="6a191-151">Make sure to select a region with GPUs enabled.</span></span> <span data-ttu-id="6a191-152">Darüber hinaus haben Abonnements ein Standardkontingent von null Kernen für GPU-optimierte VMs.</span><span class="sxs-lookup"><span data-stu-id="6a191-152">In addition, subscriptions have a default quota of zero cores for GPU-optimized VMs.</span></span> <span data-ttu-id="6a191-153">Sie können dieses Kontingent erhöhen, indem Sie eine Supportanfrage stellen.</span><span class="sxs-lookup"><span data-stu-id="6a191-153">You can raise this quota by opening a support request.</span></span> <span data-ttu-id="6a191-154">Stellen Sie sicher, dass Ihr Abonnement über ausreichend Kontingent verfügt, um Ihre Workload auszuführen.</span><span class="sxs-lookup"><span data-stu-id="6a191-154">Make sure that your subscription has enough quota to run your workload.</span></span>

### <a name="parallelizing-across-vms-versus-cores"></a><span data-ttu-id="6a191-155">Vergleich des Parallelisierens auf VMs und Kernen</span><span class="sxs-lookup"><span data-stu-id="6a191-155">Parallelizing across VMs versus cores</span></span>

<span data-ttu-id="6a191-156">Wenn eine Stilübertragung als Batchauftrag ausgeführt wird, müssen die Aufträge, die hauptsächlich auf GPUs ausgeführt werden, über VMs hinweg parallelisiert werden.</span><span class="sxs-lookup"><span data-stu-id="6a191-156">When running a style transfer process as a batch job, the jobs that run primarily on GPUs will have to be parallelized across VMs.</span></span> <span data-ttu-id="6a191-157">Zwei Ansätze sind möglich: Sie können einen größeren Cluster aus virtuellen Computern mit einer einzelnen GPU oder einen kleineren Cluster aus virtuellen Computern mit vielen GPUs erstellen.</span><span class="sxs-lookup"><span data-stu-id="6a191-157">Two approaches are possible: You can create a larger cluster using VMs that have a single GPU, or create a smaller cluster using VMs with many GPUs.</span></span>

<span data-ttu-id="6a191-158">Die beiden Optionen bieten für diese Workload eine vergleichbare Leistung.</span><span class="sxs-lookup"><span data-stu-id="6a191-158">For this workload, these two options will have comparable performance.</span></span> <span data-ttu-id="6a191-159">Die Verwendung von weniger VMs mit mehr GPUs pro VM kann dazu beitragen, die Datenverschiebung zu reduzieren.</span><span class="sxs-lookup"><span data-stu-id="6a191-159">Using fewer VMs with more GPUs per VM can help to reduce data movement.</span></span> <span data-ttu-id="6a191-160">Das Datenvolumen pro Auftrag für diese Workload ist jedoch nicht sehr groß, sodass Blob Storage keine umfangreiche Drosselung vornehmen wird.</span><span class="sxs-lookup"><span data-stu-id="6a191-160">However, the data volume per job for this workload is not very big, so you won't observe much throttling by blob storage.</span></span>

### <a name="mpi-step"></a><span data-ttu-id="6a191-161">MPI-Schritt</span><span class="sxs-lookup"><span data-stu-id="6a191-161">MPI step</span></span>

<span data-ttu-id="6a191-162">Beim Erstellen der Pipeline in Azure Machine Learning ist einer der Schritte zum Durchführen der parallelen Berechnung der MPI-Schritt.</span><span class="sxs-lookup"><span data-stu-id="6a191-162">When creating the pipeline in Azure Machine Learning, one of the steps used to perform parallel computation is the MPI step.</span></span> <span data-ttu-id="6a191-163">Im MPI-Schritt werden die Daten gleichmäßig auf die verfügbaren Knoten aufgeteilt.</span><span class="sxs-lookup"><span data-stu-id="6a191-163">The MPI step will help split the data evenly across the available nodes.</span></span> <span data-ttu-id="6a191-164">Der MPI-Schritt wird erst ausgeführt, wenn alle angeforderten Knoten bereit sind.</span><span class="sxs-lookup"><span data-stu-id="6a191-164">The MPI step will not executed until all the requested nodes are ready.</span></span> <span data-ttu-id="6a191-165">Falls ein Knoten ausfällt oder vorzeitig entfernt wird (bei einem virtuellen Computer mit niedriger Priorität), muss der MPI-Schritt erneut ausgeführt werden.</span><span class="sxs-lookup"><span data-stu-id="6a191-165">Should one node fail or get pre-empted (if it is a low-priority virtual machine), the MPI step will have to be re-run.</span></span>

## <a name="security-considerations"></a><span data-ttu-id="6a191-166">Sicherheitshinweise</span><span class="sxs-lookup"><span data-stu-id="6a191-166">Security considerations</span></span>

### <a name="restricting-access-to-azure-blob-storage"></a><span data-ttu-id="6a191-167">Einschränken des Zugriffs auf Azure Blob Storage</span><span class="sxs-lookup"><span data-stu-id="6a191-167">Restricting access to Azure blob storage</span></span>

<span data-ttu-id="6a191-168">In dieser Referenzarchitektur ist Azure Blob Storage die wichtigste Speicherkomponente, die geschützt werden muss.</span><span class="sxs-lookup"><span data-stu-id="6a191-168">In this reference architecture, Azure blob storage is the main storage component that needs to be protected.</span></span> <span data-ttu-id="6a191-169">Die im GitHub-Repository angezeigte Baselinebereitstellung verwendet Speicherkontoschlüssel für den Zugriff auf Blob Storage.</span><span class="sxs-lookup"><span data-stu-id="6a191-169">The baseline deployment shown in the GitHub repo uses storage account keys to access the blob storage.</span></span> <span data-ttu-id="6a191-170">Für noch mehr Kontrolle und Schutz sollten Sie stattdessen Shared Access Signatur (SAS) verwenden.</span><span class="sxs-lookup"><span data-stu-id="6a191-170">For further control and protection, consider using a shared access signature (SAS) instead.</span></span> <span data-ttu-id="6a191-171">Dadurch wird eingeschränkter Zugriff auf die gespeicherten Objekte gewährt, ohne dass die Kontoschlüssel hartcodiert oder im Klartext gespeichert werden müssen.</span><span class="sxs-lookup"><span data-stu-id="6a191-171">This grants limited access to objects in storage, without needing to hard code the account keys or save them in plaintext.</span></span> <span data-ttu-id="6a191-172">Dieser Ansatz ist besonders nützlich, weil Kontoschlüssel im Klartext der Logik-App-Designerschnittstelle sichtbar sind.</span><span class="sxs-lookup"><span data-stu-id="6a191-172">This approach is especially useful because account keys are visible in plaintext inside of Logic App's designer interface.</span></span> <span data-ttu-id="6a191-173">Mit SAS können Sie außerdem sicherstellen, dass das Speicherkonto über eine ordnungsgemäße Governance verfügt und der Zugriff nur ausgewählten Personen gewährt wird.</span><span class="sxs-lookup"><span data-stu-id="6a191-173">Using an SAS also helps to ensure that the storage account has proper governance, and that access is granted only to the people intended to have it.</span></span>

<span data-ttu-id="6a191-174">Stellen Sie in Szenarien mit sensibleren Daten sicher, dass alle Ihre Speicherschlüssel geschützt sind, weil diese Schlüssel den Vollzugriff auf alle Ein- und Ausgabedaten der Workload ermöglichen.</span><span class="sxs-lookup"><span data-stu-id="6a191-174">For scenarios with more sensitive data, make sure that all of your storage keys are protected, because these keys grant full access to all input and output data from the workload.</span></span>

### <a name="data-encryption-and-data-movement"></a><span data-ttu-id="6a191-175">Datenverschlüsselung und Datenverschiebung</span><span class="sxs-lookup"><span data-stu-id="6a191-175">Data encryption and data movement</span></span>

<span data-ttu-id="6a191-176">Diese Referenzarchitektur verwendet Stilübertragung als Beispiel für einen Batchbewertungsvorgang.</span><span class="sxs-lookup"><span data-stu-id="6a191-176">This reference architecture uses style transfer as an example of a batch scoring process.</span></span> <span data-ttu-id="6a191-177">Für Szenarien mit noch sensibleren Daten sollten die gespeicherten Daten im Ruhezustand verschlüsselt werden.</span><span class="sxs-lookup"><span data-stu-id="6a191-177">For more data-sensitive scenarios, the data in storage should be encrypted at rest.</span></span> <span data-ttu-id="6a191-178">Sichern Sie die Datenübertragung jedes Mal mit SSL, wenn Daten von einem Ort an einen anderen verschoben werden.</span><span class="sxs-lookup"><span data-stu-id="6a191-178">Each time data is moved from one location to the next, use SSL to secure the data transfer.</span></span> <span data-ttu-id="6a191-179">Weitere Informationen finden Sie im [Azure Storage-Sicherheitsleitfaden][storage-security].</span><span class="sxs-lookup"><span data-stu-id="6a191-179">For more information, see [Azure Storage security guide][storage-security].</span></span>

### <a name="securing-your-computation-in-a-virtual-network"></a><span data-ttu-id="6a191-180">Schützen Ihrer Berechnung in einem virtuellen Netzwerk</span><span class="sxs-lookup"><span data-stu-id="6a191-180">Securing your computation in a virtual network</span></span>

<span data-ttu-id="6a191-181">Beim Bereitstellen Ihres Machine Learning Compute-Clusters können Sie diesen so konfigurieren, dass er im Subnetz eines [virtuellen Netzwerks][virtual-network] bereitgestellt wird.</span><span class="sxs-lookup"><span data-stu-id="6a191-181">When deploying your Machine Learning compute cluster, you can configure your cluster to be provisioned inside a subnet of a [virtual network][virtual-network].</span></span> <span data-ttu-id="6a191-182">Auf diese Weise können die Computeknoten im Cluster sicher mit anderen virtuellen Computern kommunizieren.</span><span class="sxs-lookup"><span data-stu-id="6a191-182">This allows the compute nodes in the cluster to communicate securely with other virtual machines.</span></span>

### <a name="protecting-against-malicious-activity"></a><span data-ttu-id="6a191-183">Schützen vor schädlichen Aktivitäten</span><span class="sxs-lookup"><span data-stu-id="6a191-183">Protecting against malicious activity</span></span>

<span data-ttu-id="6a191-184">Stellen Sie in Szenarien mit mehreren Benutzern sicher, dass sensible Daten vor schädlichen Aktivitäten geschützt sind.</span><span class="sxs-lookup"><span data-stu-id="6a191-184">In scenarios where there are multiple users, make sure that sensitive data is protected against malicious activity.</span></span> <span data-ttu-id="6a191-185">Wenn Sie anderen Benutzern Zugriff auf diese Bereitstellung gewähren, um die Eingabedaten anzupassen, beachten Sie die folgenden Vorsichtsmaßnahmen und Überlegungen:</span><span class="sxs-lookup"><span data-stu-id="6a191-185">If other users are given access to this deployment to customize the input data, take note of the following precautions and considerations:</span></span>

- <span data-ttu-id="6a191-186">Verwenden Sie die rollenbasierte Zugriffssteuerung (RBAC), um den Zugriff von Benutzern auf die Ressourcen zu beschränken, die sie benötigen.</span><span class="sxs-lookup"><span data-stu-id="6a191-186">Use RBAC to limit users' access to only the resources they need.</span></span>
- <span data-ttu-id="6a191-187">Stellen Sie zwei separate Speicherkonten bereit.</span><span class="sxs-lookup"><span data-stu-id="6a191-187">Provision two separate storage accounts.</span></span> <span data-ttu-id="6a191-188">Speichern Sie Eingabe-und Ausgabedaten im ersten Konto.</span><span class="sxs-lookup"><span data-stu-id="6a191-188">Store input and output data in the first account.</span></span> <span data-ttu-id="6a191-189">Externen Benutzern kann Zugriff auf dieses Konto gewährt werden.</span><span class="sxs-lookup"><span data-stu-id="6a191-189">External users can be given access to this account.</span></span> <span data-ttu-id="6a191-190">Speichern Sie ausführbare Skripts und ausgegebene Protokolldateien im anderen Konto.</span><span class="sxs-lookup"><span data-stu-id="6a191-190">Store executable scripts and output log files in the other account.</span></span> <span data-ttu-id="6a191-191">Externe Benutzer sollten keinen Zugriff auf dieses Konto haben.</span><span class="sxs-lookup"><span data-stu-id="6a191-191">External users should not have access to this account.</span></span> <span data-ttu-id="6a191-192">So wird sichergestellt, dass externe Benutzer keine ausführbaren Dateien ändern (um schädlichen Code einzufügen) und keinen Zugriff auf Protokolldateien haben, die ggf. vertrauliche Informationen enthalten.</span><span class="sxs-lookup"><span data-stu-id="6a191-192">This will ensure that external users cannot modify any executable files (to inject malicious code), and don't have access to logfiles, which could hold sensitive information.</span></span>
- <span data-ttu-id="6a191-193">Böswillige Benutzer können einen DDoS auf die Auftragswarteschlange starten oder ungültige, nicht verarbeitbare Nachrichten in die Auftragswarteschlange einfügen, wodurch Systemsperren und Fehler beim Entfernen aus der Warteschlange entstehen können.</span><span class="sxs-lookup"><span data-stu-id="6a191-193">Malicious users can DDOS the job queue or inject malformed poison messages in the job queue, causing the system to lock up or causing dequeuing errors.</span></span>

## <a name="monitoring-and-logging"></a><span data-ttu-id="6a191-194">Überwachung und Protokollierung</span><span class="sxs-lookup"><span data-stu-id="6a191-194">Monitoring and logging</span></span>

### <a name="monitoring-batch-jobs"></a><span data-ttu-id="6a191-195">Überwachen von Batch-Aufträgen</span><span class="sxs-lookup"><span data-stu-id="6a191-195">Monitoring Batch jobs</span></span>

<span data-ttu-id="6a191-196">Beim Ausführen Ihres Auftrags ist es wichtig, den Fortschritt zu überwachen und zu überprüfen, ob alles wie erwartet funktioniert.</span><span class="sxs-lookup"><span data-stu-id="6a191-196">While running your job, it's important to monitor the progress and make sure that things are working as expected.</span></span> <span data-ttu-id="6a191-197">Es kann jedoch eine Herausforderung sein, über einen Cluster von aktiven Knoten hinweg zu überwachen.</span><span class="sxs-lookup"><span data-stu-id="6a191-197">However, it can be a challenge to monitor across a cluster of active nodes.</span></span>

<span data-ttu-id="6a191-198">Um einen Eindruck vom Gesamtzustand des Clusters zu erhalten, können Sie im Azure-Portal zum Blatt „Machine Learning“ navigieren und den Zustand der Knoten im Cluster überprüfen.</span><span class="sxs-lookup"><span data-stu-id="6a191-198">To get a sense of the overall state of the cluster, go to the Machine Learning blade of the Azure Portal to inspect the state of the nodes in the cluster.</span></span> <span data-ttu-id="6a191-199">Wenn ein Knoten inaktiv oder ein Auftrag fehlgeschlagen ist, werden die Fehlerprotokolle im Blobspeicher gespeichert und sind auch im Azure-Portal verfügbar.</span><span class="sxs-lookup"><span data-stu-id="6a191-199">If a node is inactive or a job has failed, the error logs are saved to blob storage, and are also accessible in the Azure Portal.</span></span>

<span data-ttu-id="6a191-200">Die Überwachung kann durch das Verbinden von Protokollen mit Application Insights oder durch das Ausführen separater Prozesse zum Abrufen des Zustands des Clusters und seiner Aufträge verbessert werden.</span><span class="sxs-lookup"><span data-stu-id="6a191-200">Monitoring can be further enriched by connecting logs to Application Insights or by running separate processes to poll for the state of the cluster and its jobs.</span></span>

### <a name="logging-with-azure-machine-learning"></a><span data-ttu-id="6a191-201">Protokollieren mit Azure Machine Learning</span><span class="sxs-lookup"><span data-stu-id="6a191-201">Logging with Azure Machine Learning</span></span>

<span data-ttu-id="6a191-202">Azure Machine Learning protokolliert automatisch alle stdout/stderr-Ereignisse im entsprechenden Blobspeicherkonto.</span><span class="sxs-lookup"><span data-stu-id="6a191-202">Azure Machine Learing will automatically log all stdout/stderr to the associate blob storage account.</span></span> <span data-ttu-id="6a191-203">Sofern nicht anders angegeben, stellt Ihr Azure Machine Learning-Arbeitsbereich automatisch ein Speicherkonto bereit und legt darin eine Sicherung Ihrer Protokolle an.</span><span class="sxs-lookup"><span data-stu-id="6a191-203">Unless otherwise specified, your Azure Machine Learning Workspace will automatically provision a storage account and dump your logs into it.</span></span> <span data-ttu-id="6a191-204">Sie können auch Speichernavigationstools verwenden, z.B. den Azure Storage-Explorer, um die Navigation durch Protokolldateien erheblich zu vereinfachen.</span><span class="sxs-lookup"><span data-stu-id="6a191-204">You can also use a storage navigation tool such as Storage Explorer which will provide a much easier experience for navigating log files.</span></span>

## <a name="cost-considerations"></a><span data-ttu-id="6a191-205">Kostenbetrachtung</span><span class="sxs-lookup"><span data-stu-id="6a191-205">Cost considerations</span></span>

<span data-ttu-id="6a191-206">Im Vergleich zu den Speicher- und Planungskomponenten fallen für die in dieser Referenzarchitektur verwendeten Computeressourcen bei Weitem die meisten Kosten an.</span><span class="sxs-lookup"><span data-stu-id="6a191-206">Compared to the storage and scheduling components, the compute resources used in this reference architecture by far dominate in terms of costs.</span></span> <span data-ttu-id="6a191-207">Eine der größten Herausforderungen besteht darin, Aufträge über ein Cluster von GPU-fähigen VMs hinweg effektiv zu parallelisieren.</span><span class="sxs-lookup"><span data-stu-id="6a191-207">One of the main challenges is effectively parallelizing the work across a cluster of GPU-enabled machines.</span></span>

<span data-ttu-id="6a191-208">Die Größe des Machine Learning Compute-Clusters kann je nach Auftrag in der Warteschlange automatisch zentral hoch- und herunterskaliert werden.</span><span class="sxs-lookup"><span data-stu-id="6a191-208">The Machine Learning Compute cluster size can automatically scale up and down depending on the jobs in the queue.</span></span> <span data-ttu-id="6a191-209">Sie können die automatische Skalierung programmgesteuert aktivieren, indem Sie die minimalen und maximalen Knoten festlegen.</span><span class="sxs-lookup"><span data-stu-id="6a191-209">You can enable auto-scale programmatically by setting the minimum and maximum nodes.</span></span>

<span data-ttu-id="6a191-210">Konfigurieren Sie für Aufträge, die nicht direkt verarbeitet werden müssen, die automatische Skalierung so, dass der Standardzustand (Minimum) ein Cluster von null Knoten ist.</span><span class="sxs-lookup"><span data-stu-id="6a191-210">For work that doesn't require immediate processing, configure auto-scale so the default state (minimum) is a cluster of zero nodes.</span></span> <span data-ttu-id="6a191-211">Bei dieser Konfiguration hat der Cluster anfangs null Knoten. Er skaliert nur dann zentral hoch, wenn er Aufträge in der Warteschlange erkennt.</span><span class="sxs-lookup"><span data-stu-id="6a191-211">With this configuration, the cluster starts with zero nodes and only scales up when it detects jobs in the queue.</span></span> <span data-ttu-id="6a191-212">Wenn die Batchbewertung maximal einige Male am Tag ausgeführt wird, können Sie mithilfe dieser Einstellung erheblich Kosten sparen.</span><span class="sxs-lookup"><span data-stu-id="6a191-212">If the batch scoring process only happens a few times a day or less, this setting enables significant cost savings.</span></span>

<span data-ttu-id="6a191-213">Die automatische Skalierung ist ggf. nicht für Batchaufträge geeignet, die zeitlich zu nahe beieinander liegen.</span><span class="sxs-lookup"><span data-stu-id="6a191-213">Auto-scaling may not be appropriate for batch jobs that happen too close to each other.</span></span> <span data-ttu-id="6a191-214">Für die benötigte Zeit zum Erstellen und Entfernen eines Cluster fallen ebenfalls Kosten an. Das heißt, wenn eine Batchworkload nur wenige Minuten nach dem Ende des vorherigen Auftrags startet, ist es ggf. kostengünstiger den Cluster permanent, also auch zwischen den Aufträgen, auszuführen.</span><span class="sxs-lookup"><span data-stu-id="6a191-214">The time that it takes for a cluster to spin up and spin down also incur a cost, so if a batch workload begins only a few minutes after the previous job ends, it might be more cost effective to keep the cluster running between jobs.</span></span>

<span data-ttu-id="6a191-215">Machine Learning Compute unterstützt auch virtuelle Computer mit niedriger Priorität.</span><span class="sxs-lookup"><span data-stu-id="6a191-215">Machine Learning Compute also supports low-priority virtual machines.</span></span> <span data-ttu-id="6a191-216">Auf diese Weise können Sie Ihre Berechnung auf virtuellen Computern ausführen, für die ein Rabatt gilt. Der Nachteil ist aber, dass diese jederzeit vorzeitig entfernt werden können.</span><span class="sxs-lookup"><span data-stu-id="6a191-216">This allows you to run your computation on discounted virtual machines, with the caveat that they may be pre-empted at any time.</span></span> <span data-ttu-id="6a191-217">Virtuelle Computer mit niedriger Priorität sind für nicht kritische Batchbewertungsworkloads ideal geeignet.</span><span class="sxs-lookup"><span data-stu-id="6a191-217">Low-priority virtual machines are ideal for non-critical batch scoring workloads.</span></span>

## <a name="deploy-the-solution"></a><span data-ttu-id="6a191-218">Bereitstellen der Lösung</span><span class="sxs-lookup"><span data-stu-id="6a191-218">Deploy the solution</span></span>

<span data-ttu-id="6a191-219">Befolgen Sie die Schritte im Abschnitt [GitHub-Repository][deployment], um diese Referenzarchitektur bereitzustellen.</span><span class="sxs-lookup"><span data-stu-id="6a191-219">To deploy this reference architecture, follow the steps described in the [GitHub repo][deployment].</span></span>

> [!NOTE]
> <span data-ttu-id="6a191-220">Sie können auch eine Batchbewertungsarchitektur für Deep Learning-Modelle bereitstellen, indem Sie den Azure Kubernetes Service verwenden.</span><span class="sxs-lookup"><span data-stu-id="6a191-220">You can also deploy a batch scoring architecture for deep learning models using the Azure Kubernetes Service.</span></span> <span data-ttu-id="6a191-221">Führen Sie die Schritte aus, die in diesem [GitHub-Repository][deployment2] beschrieben sind.</span><span class="sxs-lookup"><span data-stu-id="6a191-221">Follow the steps described in this [Github repo][deployment2].</span></span>

<!-- links -->

[aml-compute]: /azure/machine-learning/service/how-to-set-up-training-targets#amlcompute
[amls]: /azure/machine-learning/service/overview-what-is-azure-ml
[azcopy]: /azure/storage/common/storage-use-azcopy-linux
[blob-storage]: /azure/storage/blobs/storage-blobs-introduction
[container-instances]: /azure/container-instances/
[container-registry]: /azure/container-registry/
[deployment]: https://github.com/Azure/Batch-Scoring-Deep-Learning-Models-With-AML
[deployment2]: https://github.com/Azure/Batch-Scoring-Deep-Learning-Models-With-AKS
[ffmpeg]: https://www.ffmpeg.org/
[image-style-transfer]: https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf
[logic-apps]: /azure/logic-apps/
[source-video]: https://happypathspublic.blob.core.windows.net/videos/orangutan.mp4
[storage-security]: /azure/storage/common/storage-security-guide
[vm-sizes-gpu]: /azure/virtual-machines/windows/sizes-gpu
[virtual-network]: /azure/machine-learning/service/how-to-enable-virtual-network
