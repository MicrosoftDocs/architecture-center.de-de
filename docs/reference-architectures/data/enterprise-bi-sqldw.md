---
title: Enterprise BI mit SQL Data Warehouse
description: Verwenden von Azure, um aus lokal gespeicherten relationalen Daten Einblicke in Geschäftsvorgänge zu gewinnen
author: MikeWasson
ms.date: 11/06/2018
ms.openlocfilehash: 2822cf6d2a75d521f182c267f4bf2bac462d2b7f
ms.sourcegitcommit: 877777094b554559dc9cb1f0d9214d6d38197439
ms.translationtype: HT
ms.contentlocale: de-DE
ms.lasthandoff: 11/11/2018
ms.locfileid: "51527710"
---
# <a name="enterprise-bi-in-azure-with-sql-data-warehouse"></a><span data-ttu-id="fbc53-103">Enterprise BI in Azure mit SQL Data Warehouse</span><span class="sxs-lookup"><span data-stu-id="fbc53-103">Enterprise BI in Azure with SQL Data Warehouse</span></span>

<span data-ttu-id="fbc53-104">Diese Referenzarchitektur implementiert eine [ELT](../../data-guide/relational-data/etl.md#extract-load-and-transform-elt)-Pipeline (Extract-Load-Transform), die Daten aus einer lokalen SQL Server-Datenbank in SQL Data Warehouse verschiebt und die Daten für die Analyse transformiert.</span><span class="sxs-lookup"><span data-stu-id="fbc53-104">This reference architecture implements an [ELT](../../data-guide/relational-data/etl.md#extract-load-and-transform-elt) (extract-load-transform) pipeline that moves data from an on-premises SQL Server database into SQL Data Warehouse and transforms the data for analysis.</span></span> 

<span data-ttu-id="fbc53-105">Eine Referenzimplementierung für diese Architektur ist auf [GitHub][github-folder] verfügbar.</span><span class="sxs-lookup"><span data-stu-id="fbc53-105">A reference implementation for this architecture is available on [GitHub][github-folder]</span></span>

![](./images/enterprise-bi-sqldw.png)

<span data-ttu-id="fbc53-106">**Szenario**: Ein großes OLTP-Dataset einer Organisation ist in einer SQL Server-Datenbank lokal gespeichert.</span><span class="sxs-lookup"><span data-stu-id="fbc53-106">**Scenario**: An organization has a large OLTP data set stored in a SQL Server database on premises.</span></span> <span data-ttu-id="fbc53-107">Die Organisation möchte mittels SQL Data Warehouse eine Analyse mit Power BI ausführen.</span><span class="sxs-lookup"><span data-stu-id="fbc53-107">The organization wants to use SQL Data Warehouse to perform analysis using Power BI.</span></span> 

<span data-ttu-id="fbc53-108">Diese Referenzarchitektur ist für einmalige oder bedarfsgesteuerte Aufträge bestimmt.</span><span class="sxs-lookup"><span data-stu-id="fbc53-108">This reference architecture is designed for one-time or on-demand jobs.</span></span> <span data-ttu-id="fbc53-109">Wenn Sie fortlaufend (stündlich oder täglich) Daten verschieben müssen, sollten Sie mit Azure Data Factory einen automatisierten Workflow definieren.</span><span class="sxs-lookup"><span data-stu-id="fbc53-109">If you need to move data on a continuing basis (hourly or daily), we recommend using Azure Data Factory to define an automated workflow.</span></span> <span data-ttu-id="fbc53-110">Eine Referenzarchitektur, die Data Factory verwendet, finden Sie unter [Automatisierte Enterprise BI-Instanz mit SQL Data Warehouse und Azure Data Factory][adf-ra].</span><span class="sxs-lookup"><span data-stu-id="fbc53-110">For a reference architecture that uses Data Factory, see [Automated enterprise BI with SQL Data Warehouse and Azure Data Factory][adf-ra].</span></span>

## <a name="architecture"></a><span data-ttu-id="fbc53-111">Architecture</span><span class="sxs-lookup"><span data-stu-id="fbc53-111">Architecture</span></span>

<span data-ttu-id="fbc53-112">Die Architektur umfasst die folgenden Komponenten.</span><span class="sxs-lookup"><span data-stu-id="fbc53-112">The architecture consists of the following components.</span></span>

### <a name="data-source"></a><span data-ttu-id="fbc53-113">Datenquelle</span><span class="sxs-lookup"><span data-stu-id="fbc53-113">Data source</span></span>

<span data-ttu-id="fbc53-114">**SQL Server**.</span><span class="sxs-lookup"><span data-stu-id="fbc53-114">**SQL Server**.</span></span> <span data-ttu-id="fbc53-115">Die Quelldaten befinden sich in einer lokalen SQL Server-Datenbank.</span><span class="sxs-lookup"><span data-stu-id="fbc53-115">The source data is located in a SQL Server database on premises.</span></span> <span data-ttu-id="fbc53-116">Um die lokale Umgebung zu simulieren, stellen die Bereitstellungsskripts für diese Architektur einen virtuellen Computer in Azure bereit, auf dem SQL Server installiert ist.</span><span class="sxs-lookup"><span data-stu-id="fbc53-116">To simulate the on-premises environment, the deployment scripts for this architecture provision a VM in Azure with SQL Server installed.</span></span> <span data-ttu-id="fbc53-117">Die [OLTP-Beispieldatenbank von Wide World Importers][wwi] wird als Datenquelle verwendet.</span><span class="sxs-lookup"><span data-stu-id="fbc53-117">The [Wide World Importers OLTP sample database][wwi] is used as the source data.</span></span>

### <a name="ingestion-and-data-storage"></a><span data-ttu-id="fbc53-118">Erfassung und Datenspeicherung</span><span class="sxs-lookup"><span data-stu-id="fbc53-118">Ingestion and data storage</span></span>

<span data-ttu-id="fbc53-119">**Blobspeicher**.</span><span class="sxs-lookup"><span data-stu-id="fbc53-119">**Blob Storage**.</span></span> <span data-ttu-id="fbc53-120">Blobspeicher wird als Stagingbereich zum Kopieren der Daten vor dem Laden in SQL Data Warehouse verwendet.</span><span class="sxs-lookup"><span data-stu-id="fbc53-120">Blob storage is used as a staging area to copy the data before loading it into SQL Data Warehouse.</span></span>

<span data-ttu-id="fbc53-121">**Azure SQL Data Warehouse**.</span><span class="sxs-lookup"><span data-stu-id="fbc53-121">**Azure SQL Data Warehouse**.</span></span> <span data-ttu-id="fbc53-122">[SQL Data Warehouse](/azure/sql-data-warehouse/) ist ein verteiltes System für die Analyse großer Datenmengen.</span><span class="sxs-lookup"><span data-stu-id="fbc53-122">[SQL Data Warehouse](/azure/sql-data-warehouse/) is a distributed system designed to perform analytics on large data.</span></span> <span data-ttu-id="fbc53-123">Es unterstützt massive Parallelverarbeitung (Massive Parallel Processing, MPP), die die Ausführung von Hochleistungsanalysen ermöglicht.</span><span class="sxs-lookup"><span data-stu-id="fbc53-123">It supports massive parallel processing (MPP), which makes it suitable for running high-performance analytics.</span></span> 

### <a name="analysis-and-reporting"></a><span data-ttu-id="fbc53-124">Analysen und Berichte</span><span class="sxs-lookup"><span data-stu-id="fbc53-124">Analysis and reporting</span></span>

<span data-ttu-id="fbc53-125">**Azure Analysis Services**:</span><span class="sxs-lookup"><span data-stu-id="fbc53-125">**Azure Analysis Services**.</span></span> <span data-ttu-id="fbc53-126">[Analysis Services](/azure/analysis-services/) ist ein vollständig verwalteter Dienst, der Datenmodellierungsfunktionen ermöglicht.</span><span class="sxs-lookup"><span data-stu-id="fbc53-126">[Analysis Services](/azure/analysis-services/) is a fully managed service that provides data modeling capabilities.</span></span> <span data-ttu-id="fbc53-127">Verwenden Sie Analysis Services zum Erstellen eines semantischen Modells, das Benutzer abfragen können.</span><span class="sxs-lookup"><span data-stu-id="fbc53-127">Use Analysis Services to create a semantic model that users can query.</span></span> <span data-ttu-id="fbc53-128">Analysis Services ist in einem Szenario mit BI-Dashboard besonders nützlich.</span><span class="sxs-lookup"><span data-stu-id="fbc53-128">Analysis Services is especially useful in a BI dashboard scenario.</span></span> <span data-ttu-id="fbc53-129">In dieser Architektur liest Analysis Services Daten aus dem Data Warehouse, um das semantische Modell zu verarbeiten, und bedient Dashboardabfragen effizient.</span><span class="sxs-lookup"><span data-stu-id="fbc53-129">In this architecture, Analysis Services reads data from the data warehouse to process the semantic model, and efficiently serves dashboard queries.</span></span> <span data-ttu-id="fbc53-130">Darüber hinaus unterstützt der Dienst auch die elastische Parallelität durch zentrales Hochskalieren von Replikaten zur schnelleren Abfragenverarbeitung.</span><span class="sxs-lookup"><span data-stu-id="fbc53-130">It also supports elastic concurrency, by scaling out replicas for faster query processing.</span></span>

<span data-ttu-id="fbc53-131">Zurzeit unterstützt Azure Analysis Services tabellarische Modelle, aber keine mehrdimensionalen Modelle.</span><span class="sxs-lookup"><span data-stu-id="fbc53-131">Currently, Azure Analysis Services supports tabular models but not multidimensional models.</span></span> <span data-ttu-id="fbc53-132">Tabellarische Modelle verwenden relationale Modellierungskonstrukte (Tabellen und Spalten), wohingegen mehrdimensionale Modelle OLAP-Modellierungskonstrukte (Cubes, Dimensionen und Measures) verwenden.</span><span class="sxs-lookup"><span data-stu-id="fbc53-132">Tabular models use relational modeling constructs (tables and columns), whereas multidimensional models use OLAP modeling constructs (cubes, dimensions, and measures).</span></span> <span data-ttu-id="fbc53-133">Wenn Sie mehrdimensionale Modelle benötigen, verwenden Sie SQL Server Analysis Services (SSAS).</span><span class="sxs-lookup"><span data-stu-id="fbc53-133">If you require multidimensional models, use SQL Server Analysis Services (SSAS).</span></span> <span data-ttu-id="fbc53-134">Weitere Informationen finden Sie unter [Vergleichen von tabellarischen und mehrdimensionalen Lösungen](/sql/analysis-services/comparing-tabular-and-multidimensional-solutions-ssas).</span><span class="sxs-lookup"><span data-stu-id="fbc53-134">For more information, see [Comparing tabular and multidimensional solutions](/sql/analysis-services/comparing-tabular-and-multidimensional-solutions-ssas).</span></span>

<span data-ttu-id="fbc53-135">**Power BI**:</span><span class="sxs-lookup"><span data-stu-id="fbc53-135">**Power BI**.</span></span> <span data-ttu-id="fbc53-136">Power BI ist eine Suite aus Business Analytics-Tools zum Analysieren von Daten für Einblicke in Geschäftsvorgänge.</span><span class="sxs-lookup"><span data-stu-id="fbc53-136">Power BI is a suite of business analytics tools to analyze data for business insights.</span></span> <span data-ttu-id="fbc53-137">In dieser Architektur dient sie zum Abfragen des in Analysis Services gespeicherten semantischen Modells.</span><span class="sxs-lookup"><span data-stu-id="fbc53-137">In this architecture, it queries the semantic model stored in Analysis Services.</span></span>

### <a name="authentication"></a><span data-ttu-id="fbc53-138">Authentifizierung</span><span class="sxs-lookup"><span data-stu-id="fbc53-138">Authentication</span></span>

<span data-ttu-id="fbc53-139">**Azure Active Directory** (Azure AD) authentifiziert Benutzer, die über Power BI eine Verbindung mit dem Analysis Services-Server herstellen.</span><span class="sxs-lookup"><span data-stu-id="fbc53-139">**Azure Active Directory** (Azure AD) authenticates users who connect to the Analysis Services server through Power BI.</span></span>

## <a name="data-pipeline"></a><span data-ttu-id="fbc53-140">Datenpipeline</span><span class="sxs-lookup"><span data-stu-id="fbc53-140">Data pipeline</span></span>
 
<span data-ttu-id="fbc53-141">Diese Referenzarchitektur verwendet die Beispieldatenbank [WorldWideImporters](/sql/sample/world-wide-importers/wide-world-importers-oltp-database) als Datenquelle.</span><span class="sxs-lookup"><span data-stu-id="fbc53-141">This reference architecture uses the [WorldWideImporters](/sql/sample/world-wide-importers/wide-world-importers-oltp-database) sample database as a data source.</span></span> <span data-ttu-id="fbc53-142">Die Phasen der Datenpipeline sind:</span><span class="sxs-lookup"><span data-stu-id="fbc53-142">The data pipeline has the following stages:</span></span>

1. <span data-ttu-id="fbc53-143">Exportieren der Daten aus SQL Server in Flatfiles (BCP-Hilfsprogramm).</span><span class="sxs-lookup"><span data-stu-id="fbc53-143">Export the data from SQL Server to flat files (bcp utility).</span></span>
2. <span data-ttu-id="fbc53-144">Kopieren der Flatfiles in Azure Blob Storage (AzCopy).</span><span class="sxs-lookup"><span data-stu-id="fbc53-144">Copy the flat files to Azure Blob Storage (AzCopy).</span></span>
3. <span data-ttu-id="fbc53-145">Laden der Daten in SQL Data Warehouse (PolyBase).</span><span class="sxs-lookup"><span data-stu-id="fbc53-145">Load the data into SQL Data Warehouse (PolyBase).</span></span>
4. <span data-ttu-id="fbc53-146">Transformieren der Daten in ein Sternschema (T-SQL).</span><span class="sxs-lookup"><span data-stu-id="fbc53-146">Transform the data into a star schema (T-SQL).</span></span>
5. <span data-ttu-id="fbc53-147">Laden eines Semantikmodells in Analysis Services (SQL Server Data Tools).</span><span class="sxs-lookup"><span data-stu-id="fbc53-147">Load a semantic model into Analysis Services (SQL Server Data Tools).</span></span>

![](./images/enterprise-bi-sqldw-pipeline.png)
 
> [!NOTE]
> <span data-ttu-id="fbc53-148">Erwägen Sie für die Schritte 1 &ndash; 3 die Verwendung von Redgate Data Platform Studio.</span><span class="sxs-lookup"><span data-stu-id="fbc53-148">For steps 1 &ndash; 3, consider using Redgate Data Platform Studio.</span></span> <span data-ttu-id="fbc53-149">Data Platform Studio wendet optimal abgestimmte Kompatibilitätspatches und Optimierungen an und ermöglicht so den schnellsten Einstieg in die Verwendung von SQL Data Warehouse.</span><span class="sxs-lookup"><span data-stu-id="fbc53-149">Data Platform Studio applies the most appropriate compatibility fixes and optimizations, so it's the quickest way to get started with SQL Data Warehouse.</span></span> <span data-ttu-id="fbc53-150">Weitere Informationen finden Sie unter [Laden von Daten mit Redgate Data Platform Studio](/azure/sql-data-warehouse/sql-data-warehouse-load-with-redgate).</span><span class="sxs-lookup"><span data-stu-id="fbc53-150">For more information, see [Load data with Redgate Data Platform Studio](/azure/sql-data-warehouse/sql-data-warehouse-load-with-redgate).</span></span> 

<span data-ttu-id="fbc53-151">In den folgenden Abschnitten werden diese Phasen ausführlicher beschrieben.</span><span class="sxs-lookup"><span data-stu-id="fbc53-151">The next sections describe these stages in more detail.</span></span>

### <a name="export-data-from-sql-server"></a><span data-ttu-id="fbc53-152">Exportieren von Daten aus SQL Server</span><span class="sxs-lookup"><span data-stu-id="fbc53-152">Export data from SQL Server</span></span>

<span data-ttu-id="fbc53-153">Das Hilfsprogramm [BCP](/sql/tools/bcp-utility) (Bulk Copy Program) ist eine schnelle Möglichkeit zum Erstellen von Textflatfiles aus SQL-Tabellen.</span><span class="sxs-lookup"><span data-stu-id="fbc53-153">The [bcp](/sql/tools/bcp-utility) (bulk copy program) utility is a fast way to create flat text files from SQL tables.</span></span> <span data-ttu-id="fbc53-154">In diesem Schritt wählen Sie die Spalten, die Sie exportieren möchten, jedoch nicht die zu transformierenden Daten.</span><span class="sxs-lookup"><span data-stu-id="fbc53-154">In this step, you select the columns that you want to export, but don't transform the data.</span></span> <span data-ttu-id="fbc53-155">Alle Datentransformationen sollten in SQL Data Warehouse erfolgen.</span><span class="sxs-lookup"><span data-stu-id="fbc53-155">Any data transformations should happen in SQL Data Warehouse.</span></span>

<span data-ttu-id="fbc53-156">**Empfehlungen**</span><span class="sxs-lookup"><span data-stu-id="fbc53-156">**Recommendations**</span></span>

<span data-ttu-id="fbc53-157">Planen Sie die Datenextrahierung nach Möglichkeit außerhalb der Spitzenzeiten, um Ressourcenkonflikte in der Produktionsumgebung zu minimieren.</span><span class="sxs-lookup"><span data-stu-id="fbc53-157">If possible, schedule data extraction during off-peak hours, to minimize resource contention in the production environment.</span></span> 

<span data-ttu-id="fbc53-158">Führen Sie BCP nicht auf dem Datenbankserver aus.</span><span class="sxs-lookup"><span data-stu-id="fbc53-158">Avoid running bcp on the database server.</span></span> <span data-ttu-id="fbc53-159">Führen Sie BCP stattdessen auf einem anderen Computer aus.</span><span class="sxs-lookup"><span data-stu-id="fbc53-159">Instead, run it from another machine.</span></span> <span data-ttu-id="fbc53-160">Schreiben Sie die Dateien auf ein lokales Laufwerk.</span><span class="sxs-lookup"><span data-stu-id="fbc53-160">Write the files to a local drive.</span></span> <span data-ttu-id="fbc53-161">Stellen Sie sicher, dass genügend E/A-Ressourcen für gleichzeitige Schreibvorgänge bereitstehen.</span><span class="sxs-lookup"><span data-stu-id="fbc53-161">Ensure that you have sufficient I/O resources to handle the concurrent writes.</span></span> <span data-ttu-id="fbc53-162">Um die Leistung zu optimieren, exportieren Sie die Dateien auf dedizierte schnelle Speicherlaufwerke.</span><span class="sxs-lookup"><span data-stu-id="fbc53-162">For best performance, export the files to dedicated fast storage drives.</span></span>

<span data-ttu-id="fbc53-163">Sie können die Netzwerkübertragung beschleunigen, indem Sie die exportierten Daten im komprimierten Gzip-Format speichern.</span><span class="sxs-lookup"><span data-stu-id="fbc53-163">You can speed up the network transfer by saving the exported data in Gzip compressed format.</span></span> <span data-ttu-id="fbc53-164">Allerdings ist das Laden komprimierter Dateien in Warehouse langsamer als das Laden dekomprimierter Dateien, sodass ein Kompromiss zwischen schneller Netzwerkübertragung und schnellerem Laden getroffen werden muss.</span><span class="sxs-lookup"><span data-stu-id="fbc53-164">However, loading compressed files into the warehouse is slower than loading uncompressed files, so there is a tradeoff between faster network transfer versus faster loading.</span></span> <span data-ttu-id="fbc53-165">Wenn Sie die Gzip-Komprimierung verwenden möchten, erstellen Sie keine einzelne Gzip-Datei.</span><span class="sxs-lookup"><span data-stu-id="fbc53-165">If you decide to use Gzip compression, don't create a single Gzip file.</span></span> <span data-ttu-id="fbc53-166">Teilen Sie die Daten stattdessen auf mehrere komprimierte Dateien auf.</span><span class="sxs-lookup"><span data-stu-id="fbc53-166">Instead, split the data into multiple compressed files.</span></span>

### <a name="copy-flat-files-into-blob-storage"></a><span data-ttu-id="fbc53-167">Kopieren von Flatfiles in Blobspeicher</span><span class="sxs-lookup"><span data-stu-id="fbc53-167">Copy flat files into blob storage</span></span>

<span data-ttu-id="fbc53-168">Das Hilfsprogramm [AzCopy](/azure/storage/common/storage-use-azcopy) ist für das Hochleistungskopieren von Daten in den Azure-Blobspeicher bestimmt.</span><span class="sxs-lookup"><span data-stu-id="fbc53-168">The [AzCopy](/azure/storage/common/storage-use-azcopy) utility is designed for high-performance copying of data into Azure blob storage.</span></span>

<span data-ttu-id="fbc53-169">**Empfehlungen**</span><span class="sxs-lookup"><span data-stu-id="fbc53-169">**Recommendations**</span></span>

<span data-ttu-id="fbc53-170">Erstellen Sie das Speicherkonto in einer Region, die sich in der Nähe des Quelldatenspeicherorts befindet.</span><span class="sxs-lookup"><span data-stu-id="fbc53-170">Create the storage account in a region near the location of the source data.</span></span> <span data-ttu-id="fbc53-171">Stellen Sie das Speicherkonto und die SQL Data Warehouse-Instanz in der gleichen Region bereit.</span><span class="sxs-lookup"><span data-stu-id="fbc53-171">Deploy the storage account and the SQL Data Warehouse instance in the same region.</span></span> 

<span data-ttu-id="fbc53-172">Führen Sie AzCopy und Ihre Produktionsworkloads nicht auf dem gleichen Computer aus, da CPU- und E/A-Verbrauch die Produktionsworkloads beeinträchtigen können.</span><span class="sxs-lookup"><span data-stu-id="fbc53-172">Don't run AzCopy on the same machine that runs your production workloads, because the CPU and I/O consumption can interfere with the production workload.</span></span> 

<span data-ttu-id="fbc53-173">Testen Sie den Upload zuerst, um die Uploadgeschwindigkeit zu ermitteln.</span><span class="sxs-lookup"><span data-stu-id="fbc53-173">Test the upload first to see what the upload speed is like.</span></span> <span data-ttu-id="fbc53-174">Sie können in AzCopy mit der Option „/NC“ die Anzahl der gleichzeitigen Kopiervorgänge angeben.</span><span class="sxs-lookup"><span data-stu-id="fbc53-174">You can use the /NC option in AzCopy to specify the number of concurrent copy operations.</span></span> <span data-ttu-id="fbc53-175">Beginnen Sie mit dem Standardwert, und experimentieren Sie mit dieser Einstellung, um die Leistung zu optimieren.</span><span class="sxs-lookup"><span data-stu-id="fbc53-175">Start with the default value, then experiment with this setting to tune the performance.</span></span> <span data-ttu-id="fbc53-176">In einer Umgebung mit geringer Bandbreite können zu viele gleichzeitige Vorgänge die Netzwerkverbindung überlasten, sodass die Vorgänge nicht erfolgreich abgeschlossen werden können.</span><span class="sxs-lookup"><span data-stu-id="fbc53-176">In a low-bandwidth environment, too many concurrent operations can overwhelm the network connection and prevent the operations from completing successfully.</span></span>  

<span data-ttu-id="fbc53-177">AZCopy verschiebt Daten über das öffentliche Internet in den Speicher.</span><span class="sxs-lookup"><span data-stu-id="fbc53-177">AzCopy moves data to storage over the public internet.</span></span> <span data-ttu-id="fbc53-178">Wenn dies nicht schnell genug ist, sollten Sie die Einrichtung einer [ExpressRoute](/azure/expressroute/)-Verbindung erwägen.</span><span class="sxs-lookup"><span data-stu-id="fbc53-178">If this isn't fast enough, consider setting up an [ExpressRoute](/azure/expressroute/) circuit.</span></span> <span data-ttu-id="fbc53-179">ExpressRoute ist ein Dienst, der Ihre Daten über eine dedizierte private Verbindung zu Azure weiterleitet.</span><span class="sxs-lookup"><span data-stu-id="fbc53-179">ExpressRoute is a service that routes your data through a dedicated private connection to Azure.</span></span> <span data-ttu-id="fbc53-180">Wenn Ihre Netzwerkverbindung zu langsam ist, können Sie die Daten auch physisch auf einem Datenträger an ein Azure-Rechenzentrum senden.</span><span class="sxs-lookup"><span data-stu-id="fbc53-180">Another option, if your network connection is too slow, is to physically ship the data on disk to an Azure datacenter.</span></span> <span data-ttu-id="fbc53-181">Weitere Informationen finden Sie unter [Übertragen von Daten in und aus Azure](/azure/architecture/data-guide/scenarios/data-transfer).</span><span class="sxs-lookup"><span data-stu-id="fbc53-181">For more information, see [Transferring data to and from Azure](/azure/architecture/data-guide/scenarios/data-transfer).</span></span>

<span data-ttu-id="fbc53-182">Während eines Kopiervorgangs erstellt AzCopy eine temporäre Journaldatei, mit der AzCopy den Vorgang bei einer Unterbrechung (z.B. aufgrund eines Netzwerkfehlers) neu starten kann.</span><span class="sxs-lookup"><span data-stu-id="fbc53-182">During a copy operation, AzCopy creates a temporary journal file, which enables AzCopy to restart the operation if it gets interrupted (for example, due to a network error).</span></span> <span data-ttu-id="fbc53-183">Stellen Sie sicher, dass auf dem Datenträger genügend Speicherplatz zum Speichern der Journaldateien vorhanden ist.</span><span class="sxs-lookup"><span data-stu-id="fbc53-183">Make sure there is enough disk space to store the journal files.</span></span> <span data-ttu-id="fbc53-184">Mit der Option „/Z“ können Sie angeben, wohin die Journaldateien geschrieben werden.</span><span class="sxs-lookup"><span data-stu-id="fbc53-184">You can use the /Z option to specify where the journal files are written.</span></span>

### <a name="load-data-into-sql-data-warehouse"></a><span data-ttu-id="fbc53-185">Laden von Daten in SQL Data Warehouse</span><span class="sxs-lookup"><span data-stu-id="fbc53-185">Load data into SQL Data Warehouse</span></span>

<span data-ttu-id="fbc53-186">Laden Sie die Dateien mit [PolyBase](/sql/relational-databases/polybase/polybase-guide) aus dem Blobspeicher in das Data Warehouse.</span><span class="sxs-lookup"><span data-stu-id="fbc53-186">Use [PolyBase](/sql/relational-databases/polybase/polybase-guide) to load the files from blob storage into the data warehouse.</span></span> <span data-ttu-id="fbc53-187">PolyBase ist dafür ausgelegt, die MPP-Architektur (Massively Parallel Processing) von SQL Data Warehouse zu nutzen, und bietet damit die schnellste Möglichkeit, Daten in SQL Data Warehouse zu laden.</span><span class="sxs-lookup"><span data-stu-id="fbc53-187">PolyBase is designed to leverage the MPP (Massively Parallel Processing) architecture of SQL Data Warehouse, which makes it the fastest way to load data into SQL Data Warehouse.</span></span> 

<span data-ttu-id="fbc53-188">Das Laden der Daten ist ein zweistufiger Prozess:</span><span class="sxs-lookup"><span data-stu-id="fbc53-188">Loading the data is a two-step process:</span></span>

1. <span data-ttu-id="fbc53-189">Erstellen eines Satzes externer Tabellen für die Daten.</span><span class="sxs-lookup"><span data-stu-id="fbc53-189">Create a set of external tables for the data.</span></span> <span data-ttu-id="fbc53-190">Eine externe Tabelle ist eine Tabellendefinition, die auf außerhalb des Warehouse gespeicherte Daten zeigt &mdash; in diesem Fall die Flatfiles im Blobspeicher.</span><span class="sxs-lookup"><span data-stu-id="fbc53-190">An external table is a table definition that points to data stored outside of the warehouse &mdash; in this case, the flat files in blob storage.</span></span> <span data-ttu-id="fbc53-191">Dieser Schritt verschiebt keine Daten in das Warehouse.</span><span class="sxs-lookup"><span data-stu-id="fbc53-191">This step does not move any data into the warehouse.</span></span>
2. <span data-ttu-id="fbc53-192">Erstellen von Stagingtabellen und Laden der Daten in die Stagingtabellen.</span><span class="sxs-lookup"><span data-stu-id="fbc53-192">Create staging tables, and load the data into the staging tables.</span></span> <span data-ttu-id="fbc53-193">Dieser Schritt kopiert die Daten in das Warehouse.</span><span class="sxs-lookup"><span data-stu-id="fbc53-193">This step copies the data into the warehouse.</span></span>

<span data-ttu-id="fbc53-194">**Empfehlungen**</span><span class="sxs-lookup"><span data-stu-id="fbc53-194">**Recommendations**</span></span>

<span data-ttu-id="fbc53-195">Sie sollten SQL Data Warehouse verwenden, wenn Sie große Datenmengen (mehr als 1 TB) haben und eine Analyseworkload ausführen, die von der Parallelität profitiert.</span><span class="sxs-lookup"><span data-stu-id="fbc53-195">Consider SQL Data Warehouse when you have large amounts of data (more than 1 TB) and are running an analytics workload that will benefit from parallelism.</span></span> <span data-ttu-id="fbc53-196">SQL Data Warehouse ist nicht ideal für OLTP-Workloads oder kleinere Datasets (< 250GB).</span><span class="sxs-lookup"><span data-stu-id="fbc53-196">SQL Data Warehouse is not a good fit for OLTP workloads or smaller data sets (< 250GB).</span></span> <span data-ttu-id="fbc53-197">Verwenden Sie für Datasets unter 250GB Azure SQL-Datenbank oder SQL Server.</span><span class="sxs-lookup"><span data-stu-id="fbc53-197">For data sets less than 250GB, consider Azure SQL Database or SQL Server.</span></span> <span data-ttu-id="fbc53-198">Weitere Informationen finden Sie unter [Data Warehousing und Data Marts](../../data-guide/relational-data/data-warehousing.md).</span><span class="sxs-lookup"><span data-stu-id="fbc53-198">For more information, see [Data warehousing](../../data-guide/relational-data/data-warehousing.md).</span></span>

<span data-ttu-id="fbc53-199">Erstellen Sie die Stagingtabellen als Heaptabellen, die nicht indiziert werden.</span><span class="sxs-lookup"><span data-stu-id="fbc53-199">Create the staging tables as heap tables, which are not indexed.</span></span> <span data-ttu-id="fbc53-200">Die Abfragen, die die Produktionstabellen erstellen, resultieren in einem vollständigen Tabellenscan, sodass die Stagingtabellen nicht Indiziert werden müssen.</span><span class="sxs-lookup"><span data-stu-id="fbc53-200">The queries that create the production tables will result in a full table scan, so there is no reason to index the staging tables.</span></span>

<span data-ttu-id="fbc53-201">PolyBase nutzt automatisch die Vorteile der Parallelität im Warehouse.</span><span class="sxs-lookup"><span data-stu-id="fbc53-201">PolyBase automatically takes advantage of parallelism in the warehouse.</span></span> <span data-ttu-id="fbc53-202">Die Ladeleistung wird skaliert, indem Sie die DWUs heraufsetzen.</span><span class="sxs-lookup"><span data-stu-id="fbc53-202">The load performance scales as you increase DWUs.</span></span> <span data-ttu-id="fbc53-203">Die beste Leistung erzielen Sie mit einem einzelnen Ladevorgang.</span><span class="sxs-lookup"><span data-stu-id="fbc53-203">For best performance, use a single load operation.</span></span> <span data-ttu-id="fbc53-204">Die Aufteilung der Eingabedaten in Blöcke und das Ausführen mehrerer paralleler Ladevorgänge bringt keinen Leistungsvorteil.</span><span class="sxs-lookup"><span data-stu-id="fbc53-204">There is no performance benefit to breaking the input data into chunks and running multiple concurrent loads.</span></span>

<span data-ttu-id="fbc53-205">PolyBase kann mit GZip komprimierte Dateien lesen.</span><span class="sxs-lookup"><span data-stu-id="fbc53-205">PolyBase can read Gzip compressed files.</span></span> <span data-ttu-id="fbc53-206">Allerdings wird nur ein einziger Leser pro komprimierter Datei verwendet, weil das Dekomprimieren der Datei ein Singlethread-Vorgang ist.</span><span class="sxs-lookup"><span data-stu-id="fbc53-206">However, only a single reader is used per compressed file, because uncompressing the file is a single-threaded operation.</span></span> <span data-ttu-id="fbc53-207">Vermeiden Sie daher, eine einzelne große komprimierte Datei zu laden.</span><span class="sxs-lookup"><span data-stu-id="fbc53-207">Therefore, avoid loading a single large compressed file.</span></span> <span data-ttu-id="fbc53-208">Teilen Sie die Daten stattdessen in mehrere komprimierte Dateien auf, um den Vorteil der Parallelität zu nutzen.</span><span class="sxs-lookup"><span data-stu-id="fbc53-208">Instead, split the data into multiple compressed files, in order to take advantage of parallelism.</span></span> 

<span data-ttu-id="fbc53-209">Bedenken Sie dabei folgende Einschränkungen:</span><span class="sxs-lookup"><span data-stu-id="fbc53-209">Be aware of the following limitations:</span></span>

- <span data-ttu-id="fbc53-210">PolyBase unterstützt eine maximale Spaltengröße von `varchar(8000)`, `nvarchar(4000)` oder `varbinary(8000)`.</span><span class="sxs-lookup"><span data-stu-id="fbc53-210">PolyBase supports a maximum column size of `varchar(8000)`, `nvarchar(4000)`, or `varbinary(8000)`.</span></span> <span data-ttu-id="fbc53-211">Wenn Ihre Daten diese Grenzen überschreiten, können Sie die Daten in Blöcke unterteilen, wenn Sie sie exportieren, und die Blöcke nach dem Import wieder zusammensetzen.</span><span class="sxs-lookup"><span data-stu-id="fbc53-211">If you have data that exceeds these limits, one option is to break the data up into chunks when you export it, and then reassemble the chunks after import.</span></span> 

- <span data-ttu-id="fbc53-212">PolyBase verwendet das feste Zeilenabschlusszeichen „\n“ oder einen Zeilenvorschub.</span><span class="sxs-lookup"><span data-stu-id="fbc53-212">PolyBase uses a fixed row terminator of \n or newline.</span></span> <span data-ttu-id="fbc53-213">Dies kann Probleme verursachen, wenn das Zeilenumbruchzeichen in den Quelldaten vorkommt.</span><span class="sxs-lookup"><span data-stu-id="fbc53-213">This can cause problems if newline characters appear in the source data.</span></span>

- <span data-ttu-id="fbc53-214">Ihr Quelldatenschema könnte Datentypen enthalten, die in SQL Data Warehouse nicht unterstützt werden.</span><span class="sxs-lookup"><span data-stu-id="fbc53-214">Your source data schema might contain data types that are not supported in SQL Data Warehouse.</span></span>

<span data-ttu-id="fbc53-215">Um diese Einschränkungen zu umgehen, können Sie eine gespeicherte Prozedur erstellen, die die erforderlichen Konvertierungen ausführt.</span><span class="sxs-lookup"><span data-stu-id="fbc53-215">To work around these limitations, you can create a stored procedure that performs the necessary conversions.</span></span> <span data-ttu-id="fbc53-216">Verweisen Sie auf diese gespeicherte Prozedur, wenn Sie BCP ausführen.</span><span class="sxs-lookup"><span data-stu-id="fbc53-216">Reference this stored procedure when you run bcp.</span></span> <span data-ttu-id="fbc53-217">Alternativ konvertiert [Redgate Data Platform Studio](/azure/sql-data-warehouse/sql-data-warehouse-load-with-redgate) automatisch Datentypen, die in SQL Data Warehouse nicht unterstützt werden.</span><span class="sxs-lookup"><span data-stu-id="fbc53-217">Alternatively, [Redgate Data Platform Studio](/azure/sql-data-warehouse/sql-data-warehouse-load-with-redgate) automatically converts data types that aren’t supported in SQL Data Warehouse.</span></span>

<span data-ttu-id="fbc53-218">Weitere Informationen finden Sie in den folgenden Artikeln:</span><span class="sxs-lookup"><span data-stu-id="fbc53-218">For more information, see the following articles:</span></span>

- <span data-ttu-id="fbc53-219">[Bewährte Methoden zum Laden von Daten in Azure SQL Data Warehouse](/azure/sql-data-warehouse/guidance-for-loading-data)</span><span class="sxs-lookup"><span data-stu-id="fbc53-219">[Best practices for loading data into Azure SQL Data Warehouse](/azure/sql-data-warehouse/guidance-for-loading-data).</span></span>
- [<span data-ttu-id="fbc53-220">Migrieren Ihrer Schemas nach SQL Data Warehouse</span><span class="sxs-lookup"><span data-stu-id="fbc53-220">Migrate your schemas to SQL Data Warehouse</span></span>](/azure/sql-data-warehouse/sql-data-warehouse-migrate-schema)
- [<span data-ttu-id="fbc53-221">Leitfaden zum Definieren von Datentypen für Tabellen in SQL Data Warehouse</span><span class="sxs-lookup"><span data-stu-id="fbc53-221">Guidance for defining data types for tables in SQL Data Warehouse</span></span>](/azure/sql-data-warehouse/sql-data-warehouse-tables-data-types)

### <a name="transform-the-data"></a><span data-ttu-id="fbc53-222">Transformieren der Daten</span><span class="sxs-lookup"><span data-stu-id="fbc53-222">Transform the data</span></span>

<span data-ttu-id="fbc53-223">Transformieren Sie die Daten, und verschieben Sie sie in Produktionstabellen.</span><span class="sxs-lookup"><span data-stu-id="fbc53-223">Transform the data and move it into production tables.</span></span> <span data-ttu-id="fbc53-224">In diesem Schritt werden die Daten in ein Sternschema mit Dimensions- und Faktentabellen umgewandelt, sodass sie für die semantische Modellierung geeignet sind.</span><span class="sxs-lookup"><span data-stu-id="fbc53-224">In this step, the data is transformed into a star schema with dimension tables and fact tables, suitable for semantic modeling.</span></span>

<span data-ttu-id="fbc53-225">Erstellen Sie die Produktionstabellen mit gruppierten Columnstore-Indizes, die beste Abfragegesamtleistung bieten.</span><span class="sxs-lookup"><span data-stu-id="fbc53-225">Create the production tables with clustered columnstore indexes, which offer the best overall query performance.</span></span> <span data-ttu-id="fbc53-226">Columnstore-Indizes sind für Abfragen optimiert, die viele Datensätze überprüfen.</span><span class="sxs-lookup"><span data-stu-id="fbc53-226">Columnstore indexes are optimized for queries that scan many records.</span></span> <span data-ttu-id="fbc53-227">Columnstore-Indizes sind nicht für Singleton-Suchvorgänge (d.h. Suchen in einer einzelnen Zeile) geeignet.</span><span class="sxs-lookup"><span data-stu-id="fbc53-227">Columnstore indexes don't perform as well for singleton lookups (that is, looking up a single row).</span></span> <span data-ttu-id="fbc53-228">Wenn Sie häufig Singleton-Suchvorgänge ausführen müssen, können Sie einen nicht gruppierten Index einer Tabelle hinzufügen.</span><span class="sxs-lookup"><span data-stu-id="fbc53-228">If you need to perform frequent singleton lookups, you can add a non-clustered index to a table.</span></span> <span data-ttu-id="fbc53-229">Singleton-Suchvorgänge können mit einem nicht gruppierten Index erheblich schneller ausgeführt werden.</span><span class="sxs-lookup"><span data-stu-id="fbc53-229">Singleton lookups can run significantly faster using a non-clustered index.</span></span> <span data-ttu-id="fbc53-230">Jedoch sind Singleton-Suchvorgänge in der Regel in Data Warehouse-Szenarien weniger gebräuchlich als OLTP-Workloads.</span><span class="sxs-lookup"><span data-stu-id="fbc53-230">However, singleton lookups are typically less common in data warehouse scenarios than OLTP workloads.</span></span> <span data-ttu-id="fbc53-231">Weitere Informationen finden Sie unter [Indizieren von Tabellen in SQL Data Warehouse](/azure/sql-data-warehouse/sql-data-warehouse-tables-index).</span><span class="sxs-lookup"><span data-stu-id="fbc53-231">For more information, see [Indexing tables in SQL Data Warehouse](/azure/sql-data-warehouse/sql-data-warehouse-tables-index).</span></span>

> [!NOTE]
> <span data-ttu-id="fbc53-232">Gruppierte Columnstore-Tabellen unterstützen nicht die Datentypen `varchar(max)`, `nvarchar(max)` oder `varbinary(max)`.</span><span class="sxs-lookup"><span data-stu-id="fbc53-232">Clustered columnstore tables do not support `varchar(max)`, `nvarchar(max)`, or `varbinary(max)` data types.</span></span> <span data-ttu-id="fbc53-233">Ziehen Sie in diesem Fall einen Heap- oder gruppierten Index in Erwägung.</span><span class="sxs-lookup"><span data-stu-id="fbc53-233">In that case, consider a heap or clustered index.</span></span> <span data-ttu-id="fbc53-234">Sie können diese Spalten in eine separate Tabelle einfügen.</span><span class="sxs-lookup"><span data-stu-id="fbc53-234">You might put those columns into a separate table.</span></span>

<span data-ttu-id="fbc53-235">Da die Beispieldatenbank nicht sehr groß ist, haben wir replizierte Tabellen ohne Partitionen erstellt.</span><span class="sxs-lookup"><span data-stu-id="fbc53-235">Because the sample database is not very large, we created replicated tables with no partitions.</span></span> <span data-ttu-id="fbc53-236">Bei Produktionsworkloads verbessert die Verwendung von verteilten Tabellen wahrscheinlich die Abfrageleistung.</span><span class="sxs-lookup"><span data-stu-id="fbc53-236">For production workloads, using distributed tables is likely to improve query performance.</span></span> <span data-ttu-id="fbc53-237">Siehe [Leitfaden für das Entwerfen verteilter Tabellen in Azure SQL Data Warehouse](/azure/sql-data-warehouse/sql-data-warehouse-tables-distribute).</span><span class="sxs-lookup"><span data-stu-id="fbc53-237">See [Guidance for designing distributed tables in Azure SQL Data Warehouse](/azure/sql-data-warehouse/sql-data-warehouse-tables-distribute).</span></span> <span data-ttu-id="fbc53-238">Unsere Beispielskripts führen die Abfragen mithilfe einer statischen [Ressourcenklasse](/azure/sql-data-warehouse/resource-classes-for-workload-management) aus.</span><span class="sxs-lookup"><span data-stu-id="fbc53-238">Our example scripts run the queries using a static [resource class](/azure/sql-data-warehouse/resource-classes-for-workload-management).</span></span>

### <a name="load-the-semantic-model"></a><span data-ttu-id="fbc53-239">Laden des semantischen Modells</span><span class="sxs-lookup"><span data-stu-id="fbc53-239">Load the semantic model</span></span>

<span data-ttu-id="fbc53-240">Laden Sie die Daten in ein tabellarisches Modell in Azure Analysis Services.</span><span class="sxs-lookup"><span data-stu-id="fbc53-240">Load the data into a tabular model in Azure Analysis Services.</span></span> <span data-ttu-id="fbc53-241">In diesem Schritt erstellen Sie ein semantisches Datenmodell mithilfe von SQL Server Data Tools (SSDT).</span><span class="sxs-lookup"><span data-stu-id="fbc53-241">In this step, you create a semantic data model by using SQL Server Data Tools (SSDT).</span></span> <span data-ttu-id="fbc53-242">Sie können auch ein Modell erstellen, indem Sie es aus einer Power BI Desktop-Datei importieren.</span><span class="sxs-lookup"><span data-stu-id="fbc53-242">You can also create a model by importing it from a Power BI Desktop file.</span></span> <span data-ttu-id="fbc53-243">Da SQL Data Warehouse keine Fremdschlüssel unterstützt, müssen Sie dem Semantikmodell die Beziehungen hinzufügen, damit Sie eine tabellenübergreifende Verknüpfung durchführen können.</span><span class="sxs-lookup"><span data-stu-id="fbc53-243">Because SQL Data Warehouse does not support foreign keys, you must add the relationships to the semantic model, so that you can join across tables.</span></span>

### <a name="use-power-bi-to-visualize-the-data"></a><span data-ttu-id="fbc53-244">Verwenden von Power BI zum Visualisieren von Daten</span><span class="sxs-lookup"><span data-stu-id="fbc53-244">Use Power BI to visualize the data</span></span>

<span data-ttu-id="fbc53-245">Power BI unterstützt zwei Optionen zum Herstellen einer Verbindung mit Azure Analysis Services:</span><span class="sxs-lookup"><span data-stu-id="fbc53-245">Power BI supports two options for connecting to Azure Analysis Services:</span></span>

- <span data-ttu-id="fbc53-246">Importieren.</span><span class="sxs-lookup"><span data-stu-id="fbc53-246">Import.</span></span> <span data-ttu-id="fbc53-247">Die Daten werden in das Power BI-Modell importiert.</span><span class="sxs-lookup"><span data-stu-id="fbc53-247">The data is imported into the Power BI model.</span></span>
- <span data-ttu-id="fbc53-248">Liveverbindung.</span><span class="sxs-lookup"><span data-stu-id="fbc53-248">Live Connection.</span></span> <span data-ttu-id="fbc53-249">Daten werden direkt per Pull aus Analysis Services abgerufen.</span><span class="sxs-lookup"><span data-stu-id="fbc53-249">Data is pulled directly from Analysis Services.</span></span>

<span data-ttu-id="fbc53-250">Verwenden Sie die Liveverbindung, da sie kein Kopieren von Daten in das Power BI-Modell erfordert.</span><span class="sxs-lookup"><span data-stu-id="fbc53-250">We recommend Live Connection because it doesn't require copying data into the Power BI model.</span></span> <span data-ttu-id="fbc53-251">Auch stellt die Verwendung von DirectQuery sicher, dass die Ergebnisse immer mit den neuesten Quelldaten konsistent sind.</span><span class="sxs-lookup"><span data-stu-id="fbc53-251">Also, using DirectQuery ensures that results are always consistent with the latest source data.</span></span> <span data-ttu-id="fbc53-252">Weitere Informationen finden Sie unter [Herstellen einer Verbindung mit Power BI](/azure/analysis-services/analysis-services-connect-pbi).</span><span class="sxs-lookup"><span data-stu-id="fbc53-252">For more information, see [Connect with Power BI](/azure/analysis-services/analysis-services-connect-pbi).</span></span>

<span data-ttu-id="fbc53-253">**Empfehlungen**</span><span class="sxs-lookup"><span data-stu-id="fbc53-253">**Recommendations**</span></span>

<span data-ttu-id="fbc53-254">Vermeiden Sie, BI-Dashboardabfragen direkt im Data Warehouse auszuführen.</span><span class="sxs-lookup"><span data-stu-id="fbc53-254">Avoid running BI dashboard queries directly against the data warehouse.</span></span> <span data-ttu-id="fbc53-255">BI-Dashboards erfordern sehr kurze Antwortzeiten, die direkte Warehouse-Abfragen möglicherweise nicht leisten können.</span><span class="sxs-lookup"><span data-stu-id="fbc53-255">BI dashboards require very low response times, which direct queries against the warehouse may be unable to satisfy.</span></span> <span data-ttu-id="fbc53-256">Darüber hinaus schränkt das Aktualisieren des Dashboards die Anzahl gleichzeitiger Abfragen ein, was sich auf die Leistung auswirken könnte.</span><span class="sxs-lookup"><span data-stu-id="fbc53-256">Also, refreshing the dashboard will count against the number of concurrent queries, which could impact performance.</span></span> 

<span data-ttu-id="fbc53-257">Azure Analysis Services dient zum Behandeln der Abfrageanforderungen eines BI-Dashboards, daher ist die empfohlene Vorgehensweise die Abfrage von Analysis Services über Power BI.</span><span class="sxs-lookup"><span data-stu-id="fbc53-257">Azure Analysis Services is designed to handle the query requirements of a BI dashboard, so the recommended practice is to query Analysis Services from Power BI.</span></span>

## <a name="scalability-considerations"></a><span data-ttu-id="fbc53-258">Überlegungen zur Skalierbarkeit</span><span class="sxs-lookup"><span data-stu-id="fbc53-258">Scalability considerations</span></span>

### <a name="sql-data-warehouse"></a><span data-ttu-id="fbc53-259">SQL Data Warehouse</span><span class="sxs-lookup"><span data-stu-id="fbc53-259">SQL Data Warehouse</span></span>

<span data-ttu-id="fbc53-260">Sie können mit SQL Data Warehouse Serverressourcen bedarfsabhängig horizontal hochskalieren.</span><span class="sxs-lookup"><span data-stu-id="fbc53-260">With SQL Data Warehouse, you can scale out your compute resources on demand.</span></span> <span data-ttu-id="fbc53-261">Das Abfragemodul optimiert Abfragen für die parallele Verarbeitung basierend auf der Anzahl von Serverknoten und verschiebt Daten nach Bedarf zwischen Knoten.</span><span class="sxs-lookup"><span data-stu-id="fbc53-261">The query engine optimizes queries for parallel processing based on the number of compute nodes, and moves data between nodes as necessary.</span></span> <span data-ttu-id="fbc53-262">Weitere Informationen finden Sie unter [Verwalten von Computeressourcen in Azure SQL Data Warehouse](/azure/sql-data-warehouse/sql-data-warehouse-manage-compute-overview).</span><span class="sxs-lookup"><span data-stu-id="fbc53-262">For more information, see [Manage compute in Azure SQL Data Warehouse](/azure/sql-data-warehouse/sql-data-warehouse-manage-compute-overview).</span></span>

### <a name="analysis-services"></a><span data-ttu-id="fbc53-263">Analysis Services</span><span class="sxs-lookup"><span data-stu-id="fbc53-263">Analysis Services</span></span>

<span data-ttu-id="fbc53-264">Bei Produktionsworkloads sollten Sie den Standard-Tarif für Azure Analysis Services nutzen, da er Partitionierung und DirectQuery unterstützt.</span><span class="sxs-lookup"><span data-stu-id="fbc53-264">For production workloads, we recommend the Standard Tier for Azure Analysis Services, because it supports partitioning and DirectQuery.</span></span> <span data-ttu-id="fbc53-265">Innerhalb eines Tarifs bestimmt die Größe der Instanz Arbeitsspeicher und Verarbeitungsleistung.</span><span class="sxs-lookup"><span data-stu-id="fbc53-265">Within a tier, the instance size determines the memory and processing power.</span></span> <span data-ttu-id="fbc53-266">Die Verarbeitungsleistung wird in Query Processing Units (QPUs) gemessen.</span><span class="sxs-lookup"><span data-stu-id="fbc53-266">Processing power is measured in Query Processing Units (QPUs).</span></span> <span data-ttu-id="fbc53-267">Beobachten Sie Ihre QPU-Nutzung, um die geeignete Größe auszuwählen.</span><span class="sxs-lookup"><span data-stu-id="fbc53-267">Monitor your QPU usage to select the appropriate size.</span></span> <span data-ttu-id="fbc53-268">Weitere Informationen finden Sie unter [Überwachen von Servermetriken](/azure/analysis-services/analysis-services-monitor).</span><span class="sxs-lookup"><span data-stu-id="fbc53-268">For more information, see [Monitor server metrics](/azure/analysis-services/analysis-services-monitor).</span></span>

<span data-ttu-id="fbc53-269">Bei hoher Last kann die Abfrageleistung durch parallele Abfragen beeinträchtigt werden.</span><span class="sxs-lookup"><span data-stu-id="fbc53-269">Under high load, query performance can become degraded due to query concurrency.</span></span> <span data-ttu-id="fbc53-270">Sie können Analysis Services horizontal hochskalieren, indem Sie einen Pool von Replikaten zum Verarbeiten von Abfragen erstellen, sodass mehrere Abfragen gleichzeitig ausgeführt werden können.</span><span class="sxs-lookup"><span data-stu-id="fbc53-270">You can scale out Analysis Services by creating a pool of replicas to process queries, so that more queries can be performed concurrently.</span></span> <span data-ttu-id="fbc53-271">Die Verarbeitung des Datenmodells erfolgt immer auf dem primären Server.</span><span class="sxs-lookup"><span data-stu-id="fbc53-271">The work of processing the data model always happens on the primary server.</span></span> <span data-ttu-id="fbc53-272">Standardmäßig behandelt der primäre Server auch Abfragen.</span><span class="sxs-lookup"><span data-stu-id="fbc53-272">By default, the primary server also handles queries.</span></span> <span data-ttu-id="fbc53-273">Optional können Sie den primären Server ausschließlich zum Ausführen der Verarbeitung festlegen, sodass der Abfragepool alle Abfragen verarbeitet.</span><span class="sxs-lookup"><span data-stu-id="fbc53-273">Optionally, you can designate the primary server to run processing exclusively, so that the query pool handles all queries.</span></span> <span data-ttu-id="fbc53-274">Wenn Sie hohe Anforderungen an die Verarbeitung stellen, sollten Sie die Verarbeitung vom Abfragepool trennen.</span><span class="sxs-lookup"><span data-stu-id="fbc53-274">If you have high processing requirements, you should separate the processing from the query pool.</span></span> <span data-ttu-id="fbc53-275">Bei hohen Abfragelasten und relativ unaufwändiger Verarbeitung können Sie den primären Server in den Abfragepool einschließen.</span><span class="sxs-lookup"><span data-stu-id="fbc53-275">If you have high query loads, and relatively light processing, you can include the primary server in the query pool.</span></span> <span data-ttu-id="fbc53-276">Weitere Informationen finden Sie unter [Horizontales Hochskalieren von Azure Analysis Services](/azure/analysis-services/analysis-services-scale-out).</span><span class="sxs-lookup"><span data-stu-id="fbc53-276">For more information, see [Azure Analysis Services scale-out](/azure/analysis-services/analysis-services-scale-out).</span></span> 

<span data-ttu-id="fbc53-277">Um unnötigen Verarbeitungsaufwand zu verringern, sollten Sie das tabellarische Modell mit Partitionen in logische Bereiche unterteilen.</span><span class="sxs-lookup"><span data-stu-id="fbc53-277">To reduce the amount of unnecessary processing, consider using partitions to divide the tabular model into logical parts.</span></span> <span data-ttu-id="fbc53-278">Jede Partition kann separat verarbeitet werden.</span><span class="sxs-lookup"><span data-stu-id="fbc53-278">Each partition can be processed separately.</span></span> <span data-ttu-id="fbc53-279">Weitere Informationen finden Sie unter [Partitionen](/sql/analysis-services/tabular-models/partitions-ssas-tabular).</span><span class="sxs-lookup"><span data-stu-id="fbc53-279">For more information, see [Partitions](/sql/analysis-services/tabular-models/partitions-ssas-tabular).</span></span>

## <a name="security-considerations"></a><span data-ttu-id="fbc53-280">Sicherheitshinweise</span><span class="sxs-lookup"><span data-stu-id="fbc53-280">Security considerations</span></span>

### <a name="ip-whitelisting-of-analysis-services-clients"></a><span data-ttu-id="fbc53-281">IP-Positivlisten von Analysis Services-Clients</span><span class="sxs-lookup"><span data-stu-id="fbc53-281">IP whitelisting of Analysis Services clients</span></span>

<span data-ttu-id="fbc53-282">Erwägen Sie, mit dem Firewallfeature von Analysis Services Positivlisten von Client-IP-Adressen zu erstellen.</span><span class="sxs-lookup"><span data-stu-id="fbc53-282">Consider using the Analysis Services firewall feature to whitelist client IP addresses.</span></span> <span data-ttu-id="fbc53-283">Bei Aktivierung blockiert die Firewall alle Clientverbindungen, die nicht in den Firewallregeln angegeben sind.</span><span class="sxs-lookup"><span data-stu-id="fbc53-283">If enabled, the firewall blocks all client connections other than those specified in the firewall rules.</span></span> <span data-ttu-id="fbc53-284">Die Standardregeln setzen den Power BI-Dienst auf die Positivliste, aber Sie können diese Regel falls gewünscht deaktivieren.</span><span class="sxs-lookup"><span data-stu-id="fbc53-284">The default rules whitelist the Power BI service, but you can disable this rule if desired.</span></span> <span data-ttu-id="fbc53-285">Weitere Informationen finden Sie unter [Härtung von Azure Analysis Services mit der neuen Firewallfunktion](https://azure.microsoft.com/blog/hardening-azure-analysis-services-with-the-new-firewall-capability/).</span><span class="sxs-lookup"><span data-stu-id="fbc53-285">For more information, see [Hardening Azure Analysis Services with the new firewall capability](https://azure.microsoft.com/blog/hardening-azure-analysis-services-with-the-new-firewall-capability/).</span></span>

### <a name="authorization"></a><span data-ttu-id="fbc53-286">Autorisierung</span><span class="sxs-lookup"><span data-stu-id="fbc53-286">Authorization</span></span>

<span data-ttu-id="fbc53-287">Azure Analysis Services authentifiziert mit Azure Active Directory (Azure AD) Benutzer, die eine Verbindung mit dem Analysis Services-Server herstellen.</span><span class="sxs-lookup"><span data-stu-id="fbc53-287">Azure Analysis Services uses Azure Active Directory (Azure AD) to authenticate users who connect to an Analysis Services server.</span></span> <span data-ttu-id="fbc53-288">Sie können einschränken, welche Daten ein bestimmter Benutzer anzeigen kann, indem Sie Rollen erstellen und dann Azure AD-Benutzer oder Gruppen diesen Rollen zuweisen.</span><span class="sxs-lookup"><span data-stu-id="fbc53-288">You can restrict what data a particular user is able to view, by creating roles and then assigning Azure AD users or groups to those roles.</span></span> <span data-ttu-id="fbc53-289">Für jede Rolle können Sie:</span><span class="sxs-lookup"><span data-stu-id="fbc53-289">For each role, you can:</span></span> 

- <span data-ttu-id="fbc53-290">Tabellen oder einzelne Spalten schützen.</span><span class="sxs-lookup"><span data-stu-id="fbc53-290">Protect tables or individual columns.</span></span> 
- <span data-ttu-id="fbc53-291">Einzelne Zeilen basierend auf Filterausdrücken schützen.</span><span class="sxs-lookup"><span data-stu-id="fbc53-291">Protect individual rows based on filter expressions.</span></span> 

<span data-ttu-id="fbc53-292">Weitere Informationen finden Sie unter [Verwalten von Datenbankrollen und Benutzern](/azure/analysis-services/analysis-services-database-users).</span><span class="sxs-lookup"><span data-stu-id="fbc53-292">For more information, see [Manage database roles and users](/azure/analysis-services/analysis-services-database-users).</span></span>

## <a name="deploy-the-solution"></a><span data-ttu-id="fbc53-293">Bereitstellen der Lösung</span><span class="sxs-lookup"><span data-stu-id="fbc53-293">Deploy the solution</span></span>

<span data-ttu-id="fbc53-294">Führen Sie zum Bereitstellen und Ausführen der Referenzimplementierung die Schritte in der [GitHub-Infodatei][github-folder] aus.</span><span class="sxs-lookup"><span data-stu-id="fbc53-294">To the deploy and run the reference implementation, follow the steps in the [GitHub readme][github-folder].</span></span> <span data-ttu-id="fbc53-295">Folgendes wird bereitgestellt:</span><span class="sxs-lookup"><span data-stu-id="fbc53-295">It deploys the following:</span></span>

  * <span data-ttu-id="fbc53-296">Eine Windows-VM, um einen lokalen Datenbankserver zu simulieren.</span><span class="sxs-lookup"><span data-stu-id="fbc53-296">A Windows VM to simulate an on-premises database server.</span></span> <span data-ttu-id="fbc53-297">Sie enthält SQL Server 2017 und zugehörige Tools zusammen mit Power BI Desktop.</span><span class="sxs-lookup"><span data-stu-id="fbc53-297">It includes SQL Server 2017 and related tools, along with Power BI Desktop.</span></span>
  * <span data-ttu-id="fbc53-298">Ein Azure Storage-Konto, das Blobspeicher zum Speichern von Daten bereitstellt, die aus SQL Server-Datenbank exportiert wurden.</span><span class="sxs-lookup"><span data-stu-id="fbc53-298">An Azure storage account that provides Blob storage to hold data exported from the SQL Server database.</span></span>
  * <span data-ttu-id="fbc53-299">Eine Instanz von Azure SQL Data Warehouse.</span><span class="sxs-lookup"><span data-stu-id="fbc53-299">An Azure SQL Data Warehouse instance.</span></span>
  * <span data-ttu-id="fbc53-300">Eine Azure Analysis Services-Instanz.</span><span class="sxs-lookup"><span data-stu-id="fbc53-300">An Azure Analysis Services instance.</span></span>


## <a name="next-steps"></a><span data-ttu-id="fbc53-301">Nächste Schritte</span><span class="sxs-lookup"><span data-stu-id="fbc53-301">Next steps</span></span>

- <span data-ttu-id="fbc53-302">Verwenden Sie Azure Data Factory, um die ELT-Pipeline zu automatisieren.</span><span class="sxs-lookup"><span data-stu-id="fbc53-302">Use Azure Data Factory to automate the ELT pipeline.</span></span> <span data-ttu-id="fbc53-303">Siehe [Automatisierte Enterprise BI-Instanz mit SQL Data Warehouse und Azure Data Factory][adf-ra].</span><span class="sxs-lookup"><span data-stu-id="fbc53-303">See [Automated enterprise BI with SQL Data Warehouse and Azure Data Factory][adf-ra].</span></span>

<!-- links -->

[adf-ra]: ./enterprise-bi-adf.md
[github-folder]: https://github.com/mspnp/reference-architectures/tree/master/data/enterprise_bi_sqldw
[wwi]: /sql/sample/world-wide-importers/wide-world-importers-oltp-database

