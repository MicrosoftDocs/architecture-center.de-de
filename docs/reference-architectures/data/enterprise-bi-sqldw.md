---
title: Enterprise Business Intelligence
titleSuffix: Azure Reference Architectures
description: Verwenden Sie Azure, um anhand von lokal gespeicherten relationalen Daten Einblicke in Geschäftsvorgänge zu gewinnen.
author: MikeWasson
ms.date: 11/06/2018
ms.custom: seodec18
ms.openlocfilehash: 656bf6f1bd342856fd8a2d2aa0b62a9dd4d4f87f
ms.sourcegitcommit: 88a68c7e9b6b772172b7faa4b9fd9c061a9f7e9d
ms.translationtype: HT
ms.contentlocale: de-DE
ms.lasthandoff: 12/08/2018
ms.locfileid: "53120083"
---
# <a name="enterprise-bi-in-azure-with-sql-data-warehouse"></a><span data-ttu-id="b4f80-103">Enterprise BI in Azure mit SQL Data Warehouse</span><span class="sxs-lookup"><span data-stu-id="b4f80-103">Enterprise BI in Azure with SQL Data Warehouse</span></span>

<span data-ttu-id="b4f80-104">Diese Referenzarchitektur implementiert eine [ELT-Pipeline](../../data-guide/relational-data/etl.md#extract-load-and-transform-elt) (Extrahieren, Laden und Transformieren), die Daten aus einer lokalen SQL Server-Datenbank in SQL Data Warehouse verschiebt und die Daten für die Analyse transformiert.</span><span class="sxs-lookup"><span data-stu-id="b4f80-104">This reference architecture implements an [extract, load, and transform (ELT)](../../data-guide/relational-data/etl.md#extract-load-and-transform-elt) pipeline that moves data from an on-premises SQL Server database into SQL Data Warehouse and transforms the data for analysis.</span></span>

<span data-ttu-id="b4f80-105">Eine Referenzimplementierung für diese Architektur ist auf [GitHub][github-folder] verfügbar.</span><span class="sxs-lookup"><span data-stu-id="b4f80-105">A reference implementation for this architecture is available on [GitHub][github-folder].</span></span>

![Architekturdiagramm für Enterprise BI in Azure mit SQL Data Warehouse](./images/enterprise-bi-sqldw.png)

<span data-ttu-id="b4f80-107">**Szenario:** Ein großes OLTP-Dataset einer Organisation ist lokal in einer SQL Server-Datenbank gespeichert.</span><span class="sxs-lookup"><span data-stu-id="b4f80-107">**Scenario**: An organization has a large OLTP data set stored in a SQL Server database on premises.</span></span> <span data-ttu-id="b4f80-108">Die Organisation möchte mittels SQL Data Warehouse eine Analyse mit Power BI ausführen.</span><span class="sxs-lookup"><span data-stu-id="b4f80-108">The organization wants to use SQL Data Warehouse to perform analysis using Power BI.</span></span>

<span data-ttu-id="b4f80-109">Diese Referenzarchitektur ist für einmalige oder bedarfsgesteuerte Aufträge bestimmt.</span><span class="sxs-lookup"><span data-stu-id="b4f80-109">This reference architecture is designed for one-time or on-demand jobs.</span></span> <span data-ttu-id="b4f80-110">Wenn Sie fortlaufend (stündlich oder täglich) Daten verschieben müssen, sollten Sie mit Azure Data Factory einen automatisierten Workflow definieren.</span><span class="sxs-lookup"><span data-stu-id="b4f80-110">If you need to move data on a continuing basis (hourly or daily), we recommend using Azure Data Factory to define an automated workflow.</span></span> <span data-ttu-id="b4f80-111">Eine Referenzarchitektur, die Data Factory verwendet, finden Sie unter [Automatisierte Enterprise BI-Instanz mit SQL Data Warehouse und Azure Data Factory][adf-ra].</span><span class="sxs-lookup"><span data-stu-id="b4f80-111">For a reference architecture that uses Data Factory, see [Automated enterprise BI with SQL Data Warehouse and Azure Data Factory][adf-ra].</span></span>

## <a name="architecture"></a><span data-ttu-id="b4f80-112">Architecture</span><span class="sxs-lookup"><span data-stu-id="b4f80-112">Architecture</span></span>

<span data-ttu-id="b4f80-113">Die Architektur umfasst die folgenden Komponenten.</span><span class="sxs-lookup"><span data-stu-id="b4f80-113">The architecture consists of the following components.</span></span>

### <a name="data-source"></a><span data-ttu-id="b4f80-114">Datenquelle</span><span class="sxs-lookup"><span data-stu-id="b4f80-114">Data source</span></span>

<span data-ttu-id="b4f80-115">**SQL Server**.</span><span class="sxs-lookup"><span data-stu-id="b4f80-115">**SQL Server**.</span></span> <span data-ttu-id="b4f80-116">Die Quelldaten befinden sich in einer lokalen SQL Server-Datenbank.</span><span class="sxs-lookup"><span data-stu-id="b4f80-116">The source data is located in a SQL Server database on premises.</span></span> <span data-ttu-id="b4f80-117">Um die lokale Umgebung zu simulieren, stellen die Bereitstellungsskripts für diese Architektur einen virtuellen Computer in Azure bereit, auf dem SQL Server installiert ist.</span><span class="sxs-lookup"><span data-stu-id="b4f80-117">To simulate the on-premises environment, the deployment scripts for this architecture provision a VM in Azure with SQL Server installed.</span></span> <span data-ttu-id="b4f80-118">Die [OLTP-Beispieldatenbank von Wide World Importers][wwi] wird als Datenquelle verwendet.</span><span class="sxs-lookup"><span data-stu-id="b4f80-118">The [Wide World Importers OLTP sample database][wwi] is used as the source data.</span></span>

### <a name="ingestion-and-data-storage"></a><span data-ttu-id="b4f80-119">Erfassung und Datenspeicherung</span><span class="sxs-lookup"><span data-stu-id="b4f80-119">Ingestion and data storage</span></span>

<span data-ttu-id="b4f80-120">**Blobspeicher**.</span><span class="sxs-lookup"><span data-stu-id="b4f80-120">**Blob Storage**.</span></span> <span data-ttu-id="b4f80-121">Blobspeicher wird als Stagingbereich zum Kopieren der Daten vor dem Laden in SQL Data Warehouse verwendet.</span><span class="sxs-lookup"><span data-stu-id="b4f80-121">Blob storage is used as a staging area to copy the data before loading it into SQL Data Warehouse.</span></span>

<span data-ttu-id="b4f80-122">**Azure SQL Data Warehouse**.</span><span class="sxs-lookup"><span data-stu-id="b4f80-122">**Azure SQL Data Warehouse**.</span></span> <span data-ttu-id="b4f80-123">[SQL Data Warehouse](/azure/sql-data-warehouse/) ist ein verteiltes System für die Analyse großer Datenmengen.</span><span class="sxs-lookup"><span data-stu-id="b4f80-123">[SQL Data Warehouse](/azure/sql-data-warehouse/) is a distributed system designed to perform analytics on large data.</span></span> <span data-ttu-id="b4f80-124">Es unterstützt massive Parallelverarbeitung (Massive Parallel Processing, MPP), die die Ausführung von Hochleistungsanalysen ermöglicht.</span><span class="sxs-lookup"><span data-stu-id="b4f80-124">It supports massive parallel processing (MPP), which makes it suitable for running high-performance analytics.</span></span>

### <a name="analysis-and-reporting"></a><span data-ttu-id="b4f80-125">Analysen und Berichte</span><span class="sxs-lookup"><span data-stu-id="b4f80-125">Analysis and reporting</span></span>

<span data-ttu-id="b4f80-126">**Azure Analysis Services**:</span><span class="sxs-lookup"><span data-stu-id="b4f80-126">**Azure Analysis Services**.</span></span> <span data-ttu-id="b4f80-127">[Analysis Services](/azure/analysis-services/) ist ein vollständig verwalteter Dienst, der Datenmodellierungsfunktionen ermöglicht.</span><span class="sxs-lookup"><span data-stu-id="b4f80-127">[Analysis Services](/azure/analysis-services/) is a fully managed service that provides data modeling capabilities.</span></span> <span data-ttu-id="b4f80-128">Verwenden Sie Analysis Services zum Erstellen eines semantischen Modells, das Benutzer abfragen können.</span><span class="sxs-lookup"><span data-stu-id="b4f80-128">Use Analysis Services to create a semantic model that users can query.</span></span> <span data-ttu-id="b4f80-129">Analysis Services ist in einem Szenario mit BI-Dashboard besonders nützlich.</span><span class="sxs-lookup"><span data-stu-id="b4f80-129">Analysis Services is especially useful in a BI dashboard scenario.</span></span> <span data-ttu-id="b4f80-130">In dieser Architektur liest Analysis Services Daten aus dem Data Warehouse, um das semantische Modell zu verarbeiten, und bedient Dashboardabfragen effizient.</span><span class="sxs-lookup"><span data-stu-id="b4f80-130">In this architecture, Analysis Services reads data from the data warehouse to process the semantic model, and efficiently serves dashboard queries.</span></span> <span data-ttu-id="b4f80-131">Darüber hinaus unterstützt der Dienst auch die elastische Parallelität durch zentrales Hochskalieren von Replikaten zur schnelleren Abfragenverarbeitung.</span><span class="sxs-lookup"><span data-stu-id="b4f80-131">It also supports elastic concurrency, by scaling out replicas for faster query processing.</span></span>

<span data-ttu-id="b4f80-132">Zurzeit unterstützt Azure Analysis Services tabellarische Modelle, aber keine mehrdimensionalen Modelle.</span><span class="sxs-lookup"><span data-stu-id="b4f80-132">Currently, Azure Analysis Services supports tabular models but not multidimensional models.</span></span> <span data-ttu-id="b4f80-133">Tabellarische Modelle verwenden relationale Modellierungskonstrukte (Tabellen und Spalten), wohingegen mehrdimensionale Modelle OLAP-Modellierungskonstrukte (Cubes, Dimensionen und Measures) verwenden.</span><span class="sxs-lookup"><span data-stu-id="b4f80-133">Tabular models use relational modeling constructs (tables and columns), whereas multidimensional models use OLAP modeling constructs (cubes, dimensions, and measures).</span></span> <span data-ttu-id="b4f80-134">Wenn Sie mehrdimensionale Modelle benötigen, verwenden Sie SQL Server Analysis Services (SSAS).</span><span class="sxs-lookup"><span data-stu-id="b4f80-134">If you require multidimensional models, use SQL Server Analysis Services (SSAS).</span></span> <span data-ttu-id="b4f80-135">Weitere Informationen finden Sie unter [Vergleichen von tabellarischen und mehrdimensionalen Lösungen](/sql/analysis-services/comparing-tabular-and-multidimensional-solutions-ssas).</span><span class="sxs-lookup"><span data-stu-id="b4f80-135">For more information, see [Comparing tabular and multidimensional solutions](/sql/analysis-services/comparing-tabular-and-multidimensional-solutions-ssas).</span></span>

<span data-ttu-id="b4f80-136">**Power BI**:</span><span class="sxs-lookup"><span data-stu-id="b4f80-136">**Power BI**.</span></span> <span data-ttu-id="b4f80-137">Power BI ist eine Suite aus Business Analytics-Tools zum Analysieren von Daten für Einblicke in Geschäftsvorgänge.</span><span class="sxs-lookup"><span data-stu-id="b4f80-137">Power BI is a suite of business analytics tools to analyze data for business insights.</span></span> <span data-ttu-id="b4f80-138">In dieser Architektur dient sie zum Abfragen des in Analysis Services gespeicherten semantischen Modells.</span><span class="sxs-lookup"><span data-stu-id="b4f80-138">In this architecture, it queries the semantic model stored in Analysis Services.</span></span>

### <a name="authentication"></a><span data-ttu-id="b4f80-139">Authentifizierung</span><span class="sxs-lookup"><span data-stu-id="b4f80-139">Authentication</span></span>

<span data-ttu-id="b4f80-140">**Azure Active Directory (Azure AD)** authentifiziert Benutzer, die über Power BI eine Verbindung mit dem Analysis Services-Server herstellen.</span><span class="sxs-lookup"><span data-stu-id="b4f80-140">**Azure Active Directory (Azure AD)** authenticates users who connect to the Analysis Services server through Power BI.</span></span>

## <a name="data-pipeline"></a><span data-ttu-id="b4f80-141">Datenpipeline</span><span class="sxs-lookup"><span data-stu-id="b4f80-141">Data pipeline</span></span>

<span data-ttu-id="b4f80-142">Diese Referenzarchitektur verwendet die Beispieldatenbank [WorldWideImporters](/sql/sample/world-wide-importers/wide-world-importers-oltp-database) als Datenquelle.</span><span class="sxs-lookup"><span data-stu-id="b4f80-142">This reference architecture uses the [WorldWideImporters](/sql/sample/world-wide-importers/wide-world-importers-oltp-database) sample database as a data source.</span></span> <span data-ttu-id="b4f80-143">Die Phasen der Datenpipeline sind:</span><span class="sxs-lookup"><span data-stu-id="b4f80-143">The data pipeline has the following stages:</span></span>

1. <span data-ttu-id="b4f80-144">Exportieren der Daten aus SQL Server in Flatfiles (BCP-Hilfsprogramm).</span><span class="sxs-lookup"><span data-stu-id="b4f80-144">Export the data from SQL Server to flat files (bcp utility).</span></span>
2. <span data-ttu-id="b4f80-145">Kopieren der Flatfiles in Azure Blob Storage (AzCopy).</span><span class="sxs-lookup"><span data-stu-id="b4f80-145">Copy the flat files to Azure Blob Storage (AzCopy).</span></span>
3. <span data-ttu-id="b4f80-146">Laden der Daten in SQL Data Warehouse (PolyBase).</span><span class="sxs-lookup"><span data-stu-id="b4f80-146">Load the data into SQL Data Warehouse (PolyBase).</span></span>
4. <span data-ttu-id="b4f80-147">Transformieren der Daten in ein Sternschema (T-SQL).</span><span class="sxs-lookup"><span data-stu-id="b4f80-147">Transform the data into a star schema (T-SQL).</span></span>
5. <span data-ttu-id="b4f80-148">Laden eines Semantikmodells in Analysis Services (SQL Server Data Tools).</span><span class="sxs-lookup"><span data-stu-id="b4f80-148">Load a semantic model into Analysis Services (SQL Server Data Tools).</span></span>

![Diagramm der Enterprise BI-Pipeline](./images/enterprise-bi-sqldw-pipeline.png)

> [!NOTE]
> <span data-ttu-id="b4f80-150">Erwägen Sie für die Schritte 1 &ndash; 3 die Verwendung von Redgate Data Platform Studio.</span><span class="sxs-lookup"><span data-stu-id="b4f80-150">For steps 1 &ndash; 3, consider using Redgate Data Platform Studio.</span></span> <span data-ttu-id="b4f80-151">Data Platform Studio wendet optimal abgestimmte Kompatibilitätspatches und Optimierungen an und ermöglicht so den schnellsten Einstieg in die Verwendung von SQL Data Warehouse.</span><span class="sxs-lookup"><span data-stu-id="b4f80-151">Data Platform Studio applies the most appropriate compatibility fixes and optimizations, so it's the quickest way to get started with SQL Data Warehouse.</span></span> <span data-ttu-id="b4f80-152">Weitere Informationen finden Sie unter [Laden von Daten mit Redgate Data Platform Studio](/azure/sql-data-warehouse/sql-data-warehouse-load-with-redgate).</span><span class="sxs-lookup"><span data-stu-id="b4f80-152">For more information, see [Load data with Redgate Data Platform Studio](/azure/sql-data-warehouse/sql-data-warehouse-load-with-redgate).</span></span>
>

<span data-ttu-id="b4f80-153">In den folgenden Abschnitten werden diese Phasen ausführlicher beschrieben.</span><span class="sxs-lookup"><span data-stu-id="b4f80-153">The next sections describe these stages in more detail.</span></span>

### <a name="export-data-from-sql-server"></a><span data-ttu-id="b4f80-154">Exportieren von Daten aus SQL Server</span><span class="sxs-lookup"><span data-stu-id="b4f80-154">Export data from SQL Server</span></span>

<span data-ttu-id="b4f80-155">Das Hilfsprogramm [BCP](/sql/tools/bcp-utility) (Bulk Copy Program) ist eine schnelle Möglichkeit zum Erstellen von Textflatfiles aus SQL-Tabellen.</span><span class="sxs-lookup"><span data-stu-id="b4f80-155">The [bcp](/sql/tools/bcp-utility) (bulk copy program) utility is a fast way to create flat text files from SQL tables.</span></span> <span data-ttu-id="b4f80-156">In diesem Schritt wählen Sie die Spalten, die Sie exportieren möchten, jedoch nicht die zu transformierenden Daten.</span><span class="sxs-lookup"><span data-stu-id="b4f80-156">In this step, you select the columns that you want to export, but don't transform the data.</span></span> <span data-ttu-id="b4f80-157">Alle Datentransformationen sollten in SQL Data Warehouse erfolgen.</span><span class="sxs-lookup"><span data-stu-id="b4f80-157">Any data transformations should happen in SQL Data Warehouse.</span></span>

<span data-ttu-id="b4f80-158">**Empfehlungen**</span><span class="sxs-lookup"><span data-stu-id="b4f80-158">**Recommendations**</span></span>

<span data-ttu-id="b4f80-159">Planen Sie die Datenextrahierung nach Möglichkeit außerhalb der Spitzenzeiten, um Ressourcenkonflikte in der Produktionsumgebung zu minimieren.</span><span class="sxs-lookup"><span data-stu-id="b4f80-159">If possible, schedule data extraction during off-peak hours, to minimize resource contention in the production environment.</span></span>

<span data-ttu-id="b4f80-160">Führen Sie BCP nicht auf dem Datenbankserver aus.</span><span class="sxs-lookup"><span data-stu-id="b4f80-160">Avoid running bcp on the database server.</span></span> <span data-ttu-id="b4f80-161">Führen Sie BCP stattdessen auf einem anderen Computer aus.</span><span class="sxs-lookup"><span data-stu-id="b4f80-161">Instead, run it from another machine.</span></span> <span data-ttu-id="b4f80-162">Schreiben Sie die Dateien auf ein lokales Laufwerk.</span><span class="sxs-lookup"><span data-stu-id="b4f80-162">Write the files to a local drive.</span></span> <span data-ttu-id="b4f80-163">Stellen Sie sicher, dass genügend E/A-Ressourcen für gleichzeitige Schreibvorgänge bereitstehen.</span><span class="sxs-lookup"><span data-stu-id="b4f80-163">Ensure that you have sufficient I/O resources to handle the concurrent writes.</span></span> <span data-ttu-id="b4f80-164">Um die Leistung zu optimieren, exportieren Sie die Dateien auf dedizierte schnelle Speicherlaufwerke.</span><span class="sxs-lookup"><span data-stu-id="b4f80-164">For best performance, export the files to dedicated fast storage drives.</span></span>

<span data-ttu-id="b4f80-165">Sie können die Netzwerkübertragung beschleunigen, indem Sie die exportierten Daten im komprimierten Gzip-Format speichern.</span><span class="sxs-lookup"><span data-stu-id="b4f80-165">You can speed up the network transfer by saving the exported data in Gzip compressed format.</span></span> <span data-ttu-id="b4f80-166">Allerdings ist das Laden komprimierter Dateien in Warehouse langsamer als das Laden dekomprimierter Dateien, sodass ein Kompromiss zwischen schneller Netzwerkübertragung und schnellerem Laden getroffen werden muss.</span><span class="sxs-lookup"><span data-stu-id="b4f80-166">However, loading compressed files into the warehouse is slower than loading uncompressed files, so there is a tradeoff between faster network transfer versus faster loading.</span></span> <span data-ttu-id="b4f80-167">Wenn Sie die Gzip-Komprimierung verwenden möchten, erstellen Sie keine einzelne Gzip-Datei.</span><span class="sxs-lookup"><span data-stu-id="b4f80-167">If you decide to use Gzip compression, don't create a single Gzip file.</span></span> <span data-ttu-id="b4f80-168">Teilen Sie die Daten stattdessen auf mehrere komprimierte Dateien auf.</span><span class="sxs-lookup"><span data-stu-id="b4f80-168">Instead, split the data into multiple compressed files.</span></span>

### <a name="copy-flat-files-into-blob-storage"></a><span data-ttu-id="b4f80-169">Kopieren von Flatfiles in Blobspeicher</span><span class="sxs-lookup"><span data-stu-id="b4f80-169">Copy flat files into blob storage</span></span>

<span data-ttu-id="b4f80-170">Das Hilfsprogramm [AzCopy](/azure/storage/common/storage-use-azcopy) ist für das Hochleistungskopieren von Daten in den Azure-Blobspeicher bestimmt.</span><span class="sxs-lookup"><span data-stu-id="b4f80-170">The [AzCopy](/azure/storage/common/storage-use-azcopy) utility is designed for high-performance copying of data into Azure blob storage.</span></span>

<span data-ttu-id="b4f80-171">**Empfehlungen**</span><span class="sxs-lookup"><span data-stu-id="b4f80-171">**Recommendations**</span></span>

<span data-ttu-id="b4f80-172">Erstellen Sie das Speicherkonto in einer Region, die sich in der Nähe des Quelldatenspeicherorts befindet.</span><span class="sxs-lookup"><span data-stu-id="b4f80-172">Create the storage account in a region near the location of the source data.</span></span> <span data-ttu-id="b4f80-173">Stellen Sie das Speicherkonto und die SQL Data Warehouse-Instanz in der gleichen Region bereit.</span><span class="sxs-lookup"><span data-stu-id="b4f80-173">Deploy the storage account and the SQL Data Warehouse instance in the same region.</span></span>

<span data-ttu-id="b4f80-174">Führen Sie AzCopy und Ihre Produktionsworkloads nicht auf dem gleichen Computer aus, da CPU- und E/A-Verbrauch die Produktionsworkloads beeinträchtigen können.</span><span class="sxs-lookup"><span data-stu-id="b4f80-174">Don't run AzCopy on the same machine that runs your production workloads, because the CPU and I/O consumption can interfere with the production workload.</span></span>

<span data-ttu-id="b4f80-175">Testen Sie den Upload zuerst, um die Uploadgeschwindigkeit zu ermitteln.</span><span class="sxs-lookup"><span data-stu-id="b4f80-175">Test the upload first to see what the upload speed is like.</span></span> <span data-ttu-id="b4f80-176">Sie können in AzCopy mit der Option „/NC“ die Anzahl der gleichzeitigen Kopiervorgänge angeben.</span><span class="sxs-lookup"><span data-stu-id="b4f80-176">You can use the /NC option in AzCopy to specify the number of concurrent copy operations.</span></span> <span data-ttu-id="b4f80-177">Beginnen Sie mit dem Standardwert, und experimentieren Sie mit dieser Einstellung, um die Leistung zu optimieren.</span><span class="sxs-lookup"><span data-stu-id="b4f80-177">Start with the default value, then experiment with this setting to tune the performance.</span></span> <span data-ttu-id="b4f80-178">In einer Umgebung mit geringer Bandbreite können zu viele gleichzeitige Vorgänge die Netzwerkverbindung überlasten, sodass die Vorgänge nicht erfolgreich abgeschlossen werden können.</span><span class="sxs-lookup"><span data-stu-id="b4f80-178">In a low-bandwidth environment, too many concurrent operations can overwhelm the network connection and prevent the operations from completing successfully.</span></span>

<span data-ttu-id="b4f80-179">AZCopy verschiebt Daten über das öffentliche Internet in den Speicher.</span><span class="sxs-lookup"><span data-stu-id="b4f80-179">AzCopy moves data to storage over the public internet.</span></span> <span data-ttu-id="b4f80-180">Wenn dies nicht schnell genug ist, sollten Sie die Einrichtung einer [ExpressRoute](/azure/expressroute/)-Verbindung erwägen.</span><span class="sxs-lookup"><span data-stu-id="b4f80-180">If this isn't fast enough, consider setting up an [ExpressRoute](/azure/expressroute/) circuit.</span></span> <span data-ttu-id="b4f80-181">ExpressRoute ist ein Dienst, der Ihre Daten über eine dedizierte private Verbindung zu Azure weiterleitet.</span><span class="sxs-lookup"><span data-stu-id="b4f80-181">ExpressRoute is a service that routes your data through a dedicated private connection to Azure.</span></span> <span data-ttu-id="b4f80-182">Wenn Ihre Netzwerkverbindung zu langsam ist, können Sie die Daten auch physisch auf einem Datenträger an ein Azure-Rechenzentrum senden.</span><span class="sxs-lookup"><span data-stu-id="b4f80-182">Another option, if your network connection is too slow, is to physically ship the data on disk to an Azure datacenter.</span></span> <span data-ttu-id="b4f80-183">Weitere Informationen finden Sie unter [Übertragen von Daten in und aus Azure](/azure/architecture/data-guide/scenarios/data-transfer).</span><span class="sxs-lookup"><span data-stu-id="b4f80-183">For more information, see [Transferring data to and from Azure](/azure/architecture/data-guide/scenarios/data-transfer).</span></span>

<span data-ttu-id="b4f80-184">Während eines Kopiervorgangs erstellt AzCopy eine temporäre Journaldatei, mit der AzCopy den Vorgang bei einer Unterbrechung (z.B. aufgrund eines Netzwerkfehlers) neu starten kann.</span><span class="sxs-lookup"><span data-stu-id="b4f80-184">During a copy operation, AzCopy creates a temporary journal file, which enables AzCopy to restart the operation if it gets interrupted (for example, due to a network error).</span></span> <span data-ttu-id="b4f80-185">Stellen Sie sicher, dass auf dem Datenträger genügend Speicherplatz zum Speichern der Journaldateien vorhanden ist.</span><span class="sxs-lookup"><span data-stu-id="b4f80-185">Make sure there is enough disk space to store the journal files.</span></span> <span data-ttu-id="b4f80-186">Mit der Option „/Z“ können Sie angeben, wohin die Journaldateien geschrieben werden.</span><span class="sxs-lookup"><span data-stu-id="b4f80-186">You can use the /Z option to specify where the journal files are written.</span></span>

### <a name="load-data-into-sql-data-warehouse"></a><span data-ttu-id="b4f80-187">Laden von Daten in SQL Data Warehouse</span><span class="sxs-lookup"><span data-stu-id="b4f80-187">Load data into SQL Data Warehouse</span></span>

<span data-ttu-id="b4f80-188">Laden Sie die Dateien mit [PolyBase](/sql/relational-databases/polybase/polybase-guide) aus dem Blobspeicher in das Data Warehouse.</span><span class="sxs-lookup"><span data-stu-id="b4f80-188">Use [PolyBase](/sql/relational-databases/polybase/polybase-guide) to load the files from blob storage into the data warehouse.</span></span> <span data-ttu-id="b4f80-189">PolyBase ist dafür ausgelegt, die MPP-Architektur (Massively Parallel Processing) von SQL Data Warehouse zu nutzen, und bietet damit die schnellste Möglichkeit, Daten in SQL Data Warehouse zu laden.</span><span class="sxs-lookup"><span data-stu-id="b4f80-189">PolyBase is designed to leverage the MPP (Massively Parallel Processing) architecture of SQL Data Warehouse, which makes it the fastest way to load data into SQL Data Warehouse.</span></span>

<span data-ttu-id="b4f80-190">Das Laden der Daten ist ein zweistufiger Prozess:</span><span class="sxs-lookup"><span data-stu-id="b4f80-190">Loading the data is a two-step process:</span></span>

1. <span data-ttu-id="b4f80-191">Erstellen eines Satzes externer Tabellen für die Daten.</span><span class="sxs-lookup"><span data-stu-id="b4f80-191">Create a set of external tables for the data.</span></span> <span data-ttu-id="b4f80-192">Eine externe Tabelle ist eine Tabellendefinition, die auf außerhalb des Warehouse gespeicherte Daten zeigt &mdash; in diesem Fall die Flatfiles im Blobspeicher.</span><span class="sxs-lookup"><span data-stu-id="b4f80-192">An external table is a table definition that points to data stored outside of the warehouse &mdash; in this case, the flat files in blob storage.</span></span> <span data-ttu-id="b4f80-193">Dieser Schritt verschiebt keine Daten in das Warehouse.</span><span class="sxs-lookup"><span data-stu-id="b4f80-193">This step does not move any data into the warehouse.</span></span>
2. <span data-ttu-id="b4f80-194">Erstellen von Stagingtabellen und Laden der Daten in die Stagingtabellen.</span><span class="sxs-lookup"><span data-stu-id="b4f80-194">Create staging tables, and load the data into the staging tables.</span></span> <span data-ttu-id="b4f80-195">Dieser Schritt kopiert die Daten in das Warehouse.</span><span class="sxs-lookup"><span data-stu-id="b4f80-195">This step copies the data into the warehouse.</span></span>

<span data-ttu-id="b4f80-196">**Empfehlungen**</span><span class="sxs-lookup"><span data-stu-id="b4f80-196">**Recommendations**</span></span>

<span data-ttu-id="b4f80-197">Sie sollten SQL Data Warehouse verwenden, wenn Sie große Datenmengen (mehr als 1 TB) haben und eine Analyseworkload ausführen, die von der Parallelität profitiert.</span><span class="sxs-lookup"><span data-stu-id="b4f80-197">Consider SQL Data Warehouse when you have large amounts of data (more than 1 TB) and are running an analytics workload that will benefit from parallelism.</span></span> <span data-ttu-id="b4f80-198">SQL Data Warehouse ist nicht ideal für OLTP-Workloads oder kleinere Datasets (< 250GB).</span><span class="sxs-lookup"><span data-stu-id="b4f80-198">SQL Data Warehouse is not a good fit for OLTP workloads or smaller data sets (< 250GB).</span></span> <span data-ttu-id="b4f80-199">Verwenden Sie für Datasets unter 250GB Azure SQL-Datenbank oder SQL Server.</span><span class="sxs-lookup"><span data-stu-id="b4f80-199">For data sets less than 250GB, consider Azure SQL Database or SQL Server.</span></span> <span data-ttu-id="b4f80-200">Weitere Informationen finden Sie unter [Data Warehousing und Data Marts](../../data-guide/relational-data/data-warehousing.md).</span><span class="sxs-lookup"><span data-stu-id="b4f80-200">For more information, see [Data warehousing](../../data-guide/relational-data/data-warehousing.md).</span></span>

<span data-ttu-id="b4f80-201">Erstellen Sie die Stagingtabellen als Heaptabellen, die nicht indiziert werden.</span><span class="sxs-lookup"><span data-stu-id="b4f80-201">Create the staging tables as heap tables, which are not indexed.</span></span> <span data-ttu-id="b4f80-202">Die Abfragen, die die Produktionstabellen erstellen, resultieren in einem vollständigen Tabellenscan, sodass die Stagingtabellen nicht Indiziert werden müssen.</span><span class="sxs-lookup"><span data-stu-id="b4f80-202">The queries that create the production tables will result in a full table scan, so there is no reason to index the staging tables.</span></span>

<span data-ttu-id="b4f80-203">PolyBase nutzt automatisch die Vorteile der Parallelität im Warehouse.</span><span class="sxs-lookup"><span data-stu-id="b4f80-203">PolyBase automatically takes advantage of parallelism in the warehouse.</span></span> <span data-ttu-id="b4f80-204">Die Ladeleistung wird skaliert, indem Sie die DWUs heraufsetzen.</span><span class="sxs-lookup"><span data-stu-id="b4f80-204">The load performance scales as you increase DWUs.</span></span> <span data-ttu-id="b4f80-205">Die beste Leistung erzielen Sie mit einem einzelnen Ladevorgang.</span><span class="sxs-lookup"><span data-stu-id="b4f80-205">For best performance, use a single load operation.</span></span> <span data-ttu-id="b4f80-206">Die Aufteilung der Eingabedaten in Blöcke und das Ausführen mehrerer paralleler Ladevorgänge bringt keinen Leistungsvorteil.</span><span class="sxs-lookup"><span data-stu-id="b4f80-206">There is no performance benefit to breaking the input data into chunks and running multiple concurrent loads.</span></span>

<span data-ttu-id="b4f80-207">PolyBase kann mit GZip komprimierte Dateien lesen.</span><span class="sxs-lookup"><span data-stu-id="b4f80-207">PolyBase can read Gzip compressed files.</span></span> <span data-ttu-id="b4f80-208">Allerdings wird nur ein einziger Leser pro komprimierter Datei verwendet, weil das Dekomprimieren der Datei ein Singlethread-Vorgang ist.</span><span class="sxs-lookup"><span data-stu-id="b4f80-208">However, only a single reader is used per compressed file, because uncompressing the file is a single-threaded operation.</span></span> <span data-ttu-id="b4f80-209">Vermeiden Sie daher, eine einzelne große komprimierte Datei zu laden.</span><span class="sxs-lookup"><span data-stu-id="b4f80-209">Therefore, avoid loading a single large compressed file.</span></span> <span data-ttu-id="b4f80-210">Teilen Sie die Daten stattdessen in mehrere komprimierte Dateien auf, um den Vorteil der Parallelität zu nutzen.</span><span class="sxs-lookup"><span data-stu-id="b4f80-210">Instead, split the data into multiple compressed files, in order to take advantage of parallelism.</span></span> 

<span data-ttu-id="b4f80-211">Bedenken Sie dabei folgende Einschränkungen:</span><span class="sxs-lookup"><span data-stu-id="b4f80-211">Be aware of the following limitations:</span></span>

- <span data-ttu-id="b4f80-212">PolyBase unterstützt eine maximale Spaltengröße von `varchar(8000)`, `nvarchar(4000)` oder `varbinary(8000)`.</span><span class="sxs-lookup"><span data-stu-id="b4f80-212">PolyBase supports a maximum column size of `varchar(8000)`, `nvarchar(4000)`, or `varbinary(8000)`.</span></span> <span data-ttu-id="b4f80-213">Wenn Ihre Daten diese Grenzen überschreiten, können Sie die Daten in Blöcke unterteilen, wenn Sie sie exportieren, und die Blöcke nach dem Import wieder zusammensetzen.</span><span class="sxs-lookup"><span data-stu-id="b4f80-213">If you have data that exceeds these limits, one option is to break the data up into chunks when you export it, and then reassemble the chunks after import.</span></span>

- <span data-ttu-id="b4f80-214">PolyBase verwendet das feste Zeilenabschlusszeichen „\n“ oder einen Zeilenvorschub.</span><span class="sxs-lookup"><span data-stu-id="b4f80-214">PolyBase uses a fixed row terminator of \n or newline.</span></span> <span data-ttu-id="b4f80-215">Dies kann Probleme verursachen, wenn das Zeilenumbruchzeichen in den Quelldaten vorkommt.</span><span class="sxs-lookup"><span data-stu-id="b4f80-215">This can cause problems if newline characters appear in the source data.</span></span>

- <span data-ttu-id="b4f80-216">Ihr Quelldatenschema könnte Datentypen enthalten, die in SQL Data Warehouse nicht unterstützt werden.</span><span class="sxs-lookup"><span data-stu-id="b4f80-216">Your source data schema might contain data types that are not supported in SQL Data Warehouse.</span></span>

<span data-ttu-id="b4f80-217">Um diese Einschränkungen zu umgehen, können Sie eine gespeicherte Prozedur erstellen, die die erforderlichen Konvertierungen ausführt.</span><span class="sxs-lookup"><span data-stu-id="b4f80-217">To work around these limitations, you can create a stored procedure that performs the necessary conversions.</span></span> <span data-ttu-id="b4f80-218">Verweisen Sie auf diese gespeicherte Prozedur, wenn Sie BCP ausführen.</span><span class="sxs-lookup"><span data-stu-id="b4f80-218">Reference this stored procedure when you run bcp.</span></span> <span data-ttu-id="b4f80-219">Alternativ konvertiert [Redgate Data Platform Studio](/azure/sql-data-warehouse/sql-data-warehouse-load-with-redgate) automatisch Datentypen, die in SQL Data Warehouse nicht unterstützt werden.</span><span class="sxs-lookup"><span data-stu-id="b4f80-219">Alternatively, [Redgate Data Platform Studio](/azure/sql-data-warehouse/sql-data-warehouse-load-with-redgate) automatically converts data types that aren’t supported in SQL Data Warehouse.</span></span>

<span data-ttu-id="b4f80-220">Weitere Informationen finden Sie in den folgenden Artikeln:</span><span class="sxs-lookup"><span data-stu-id="b4f80-220">For more information, see the following articles:</span></span>

- <span data-ttu-id="b4f80-221">[Bewährte Methoden zum Laden von Daten in Azure SQL Data Warehouse](/azure/sql-data-warehouse/guidance-for-loading-data)</span><span class="sxs-lookup"><span data-stu-id="b4f80-221">[Best practices for loading data into Azure SQL Data Warehouse](/azure/sql-data-warehouse/guidance-for-loading-data).</span></span>
- [<span data-ttu-id="b4f80-222">Migrieren Ihrer Schemas nach SQL Data Warehouse</span><span class="sxs-lookup"><span data-stu-id="b4f80-222">Migrate your schemas to SQL Data Warehouse</span></span>](/azure/sql-data-warehouse/sql-data-warehouse-migrate-schema)
- [<span data-ttu-id="b4f80-223">Leitfaden zum Definieren von Datentypen für Tabellen in SQL Data Warehouse</span><span class="sxs-lookup"><span data-stu-id="b4f80-223">Guidance for defining data types for tables in SQL Data Warehouse</span></span>](/azure/sql-data-warehouse/sql-data-warehouse-tables-data-types)

### <a name="transform-the-data"></a><span data-ttu-id="b4f80-224">Transformieren der Daten</span><span class="sxs-lookup"><span data-stu-id="b4f80-224">Transform the data</span></span>

<span data-ttu-id="b4f80-225">Transformieren Sie die Daten, und verschieben Sie sie in Produktionstabellen.</span><span class="sxs-lookup"><span data-stu-id="b4f80-225">Transform the data and move it into production tables.</span></span> <span data-ttu-id="b4f80-226">In diesem Schritt werden die Daten in ein Sternschema mit Dimensions- und Faktentabellen umgewandelt, sodass sie für die semantische Modellierung geeignet sind.</span><span class="sxs-lookup"><span data-stu-id="b4f80-226">In this step, the data is transformed into a star schema with dimension tables and fact tables, suitable for semantic modeling.</span></span>

<span data-ttu-id="b4f80-227">Erstellen Sie die Produktionstabellen mit gruppierten Columnstore-Indizes, die beste Abfragegesamtleistung bieten.</span><span class="sxs-lookup"><span data-stu-id="b4f80-227">Create the production tables with clustered columnstore indexes, which offer the best overall query performance.</span></span> <span data-ttu-id="b4f80-228">Columnstore-Indizes sind für Abfragen optimiert, die viele Datensätze überprüfen.</span><span class="sxs-lookup"><span data-stu-id="b4f80-228">Columnstore indexes are optimized for queries that scan many records.</span></span> <span data-ttu-id="b4f80-229">Columnstore-Indizes sind nicht für Singleton-Suchvorgänge (d.h. Suchen in einer einzelnen Zeile) geeignet.</span><span class="sxs-lookup"><span data-stu-id="b4f80-229">Columnstore indexes don't perform as well for singleton lookups (that is, looking up a single row).</span></span> <span data-ttu-id="b4f80-230">Wenn Sie häufig Singleton-Suchvorgänge ausführen müssen, können Sie einen nicht gruppierten Index einer Tabelle hinzufügen.</span><span class="sxs-lookup"><span data-stu-id="b4f80-230">If you need to perform frequent singleton lookups, you can add a non-clustered index to a table.</span></span> <span data-ttu-id="b4f80-231">Singleton-Suchvorgänge können mit einem nicht gruppierten Index erheblich schneller ausgeführt werden.</span><span class="sxs-lookup"><span data-stu-id="b4f80-231">Singleton lookups can run significantly faster using a non-clustered index.</span></span> <span data-ttu-id="b4f80-232">Jedoch sind Singleton-Suchvorgänge in der Regel in Data Warehouse-Szenarien weniger gebräuchlich als OLTP-Workloads.</span><span class="sxs-lookup"><span data-stu-id="b4f80-232">However, singleton lookups are typically less common in data warehouse scenarios than OLTP workloads.</span></span> <span data-ttu-id="b4f80-233">Weitere Informationen finden Sie unter [Indizieren von Tabellen in SQL Data Warehouse](/azure/sql-data-warehouse/sql-data-warehouse-tables-index).</span><span class="sxs-lookup"><span data-stu-id="b4f80-233">For more information, see [Indexing tables in SQL Data Warehouse](/azure/sql-data-warehouse/sql-data-warehouse-tables-index).</span></span>

> [!NOTE]
> <span data-ttu-id="b4f80-234">Gruppierte Columnstore-Tabellen unterstützen nicht die Datentypen `varchar(max)`, `nvarchar(max)` oder `varbinary(max)`.</span><span class="sxs-lookup"><span data-stu-id="b4f80-234">Clustered columnstore tables do not support `varchar(max)`, `nvarchar(max)`, or `varbinary(max)` data types.</span></span> <span data-ttu-id="b4f80-235">Ziehen Sie in diesem Fall einen Heap- oder gruppierten Index in Erwägung.</span><span class="sxs-lookup"><span data-stu-id="b4f80-235">In that case, consider a heap or clustered index.</span></span> <span data-ttu-id="b4f80-236">Sie können diese Spalten in eine separate Tabelle einfügen.</span><span class="sxs-lookup"><span data-stu-id="b4f80-236">You might put those columns into a separate table.</span></span>

<span data-ttu-id="b4f80-237">Da die Beispieldatenbank nicht sehr groß ist, haben wir replizierte Tabellen ohne Partitionen erstellt.</span><span class="sxs-lookup"><span data-stu-id="b4f80-237">Because the sample database is not very large, we created replicated tables with no partitions.</span></span> <span data-ttu-id="b4f80-238">Bei Produktionsworkloads verbessert die Verwendung von verteilten Tabellen wahrscheinlich die Abfrageleistung.</span><span class="sxs-lookup"><span data-stu-id="b4f80-238">For production workloads, using distributed tables is likely to improve query performance.</span></span> <span data-ttu-id="b4f80-239">Siehe [Leitfaden für das Entwerfen verteilter Tabellen in Azure SQL Data Warehouse](/azure/sql-data-warehouse/sql-data-warehouse-tables-distribute).</span><span class="sxs-lookup"><span data-stu-id="b4f80-239">See [Guidance for designing distributed tables in Azure SQL Data Warehouse](/azure/sql-data-warehouse/sql-data-warehouse-tables-distribute).</span></span> <span data-ttu-id="b4f80-240">Unsere Beispielskripts führen die Abfragen mithilfe einer statischen [Ressourcenklasse](/azure/sql-data-warehouse/resource-classes-for-workload-management) aus.</span><span class="sxs-lookup"><span data-stu-id="b4f80-240">Our example scripts run the queries using a static [resource class](/azure/sql-data-warehouse/resource-classes-for-workload-management).</span></span>

### <a name="load-the-semantic-model"></a><span data-ttu-id="b4f80-241">Laden des semantischen Modells</span><span class="sxs-lookup"><span data-stu-id="b4f80-241">Load the semantic model</span></span>

<span data-ttu-id="b4f80-242">Laden Sie die Daten in ein tabellarisches Modell in Azure Analysis Services.</span><span class="sxs-lookup"><span data-stu-id="b4f80-242">Load the data into a tabular model in Azure Analysis Services.</span></span> <span data-ttu-id="b4f80-243">In diesem Schritt erstellen Sie ein semantisches Datenmodell mithilfe von SQL Server Data Tools (SSDT).</span><span class="sxs-lookup"><span data-stu-id="b4f80-243">In this step, you create a semantic data model by using SQL Server Data Tools (SSDT).</span></span> <span data-ttu-id="b4f80-244">Sie können auch ein Modell erstellen, indem Sie es aus einer Power BI Desktop-Datei importieren.</span><span class="sxs-lookup"><span data-stu-id="b4f80-244">You can also create a model by importing it from a Power BI Desktop file.</span></span> <span data-ttu-id="b4f80-245">Da SQL Data Warehouse keine Fremdschlüssel unterstützt, müssen Sie dem Semantikmodell die Beziehungen hinzufügen, damit Sie eine tabellenübergreifende Verknüpfung durchführen können.</span><span class="sxs-lookup"><span data-stu-id="b4f80-245">Because SQL Data Warehouse does not support foreign keys, you must add the relationships to the semantic model, so that you can join across tables.</span></span>

### <a name="use-power-bi-to-visualize-the-data"></a><span data-ttu-id="b4f80-246">Verwenden von Power BI zum Visualisieren von Daten</span><span class="sxs-lookup"><span data-stu-id="b4f80-246">Use Power BI to visualize the data</span></span>

<span data-ttu-id="b4f80-247">Power BI unterstützt zwei Optionen zum Herstellen einer Verbindung mit Azure Analysis Services:</span><span class="sxs-lookup"><span data-stu-id="b4f80-247">Power BI supports two options for connecting to Azure Analysis Services:</span></span>

- <span data-ttu-id="b4f80-248">Importieren.</span><span class="sxs-lookup"><span data-stu-id="b4f80-248">Import.</span></span> <span data-ttu-id="b4f80-249">Die Daten werden in das Power BI-Modell importiert.</span><span class="sxs-lookup"><span data-stu-id="b4f80-249">The data is imported into the Power BI model.</span></span>
- <span data-ttu-id="b4f80-250">Liveverbindung.</span><span class="sxs-lookup"><span data-stu-id="b4f80-250">Live Connection.</span></span> <span data-ttu-id="b4f80-251">Daten werden direkt per Pull aus Analysis Services abgerufen.</span><span class="sxs-lookup"><span data-stu-id="b4f80-251">Data is pulled directly from Analysis Services.</span></span>

<span data-ttu-id="b4f80-252">Verwenden Sie die Liveverbindung, da sie kein Kopieren von Daten in das Power BI-Modell erfordert.</span><span class="sxs-lookup"><span data-stu-id="b4f80-252">We recommend Live Connection because it doesn't require copying data into the Power BI model.</span></span> <span data-ttu-id="b4f80-253">Auch stellt die Verwendung von DirectQuery sicher, dass die Ergebnisse immer mit den neuesten Quelldaten konsistent sind.</span><span class="sxs-lookup"><span data-stu-id="b4f80-253">Also, using DirectQuery ensures that results are always consistent with the latest source data.</span></span> <span data-ttu-id="b4f80-254">Weitere Informationen finden Sie unter [Herstellen einer Verbindung mit Power BI](/azure/analysis-services/analysis-services-connect-pbi).</span><span class="sxs-lookup"><span data-stu-id="b4f80-254">For more information, see [Connect with Power BI](/azure/analysis-services/analysis-services-connect-pbi).</span></span>

<span data-ttu-id="b4f80-255">**Empfehlungen**</span><span class="sxs-lookup"><span data-stu-id="b4f80-255">**Recommendations**</span></span>

<span data-ttu-id="b4f80-256">Vermeiden Sie, BI-Dashboardabfragen direkt im Data Warehouse auszuführen.</span><span class="sxs-lookup"><span data-stu-id="b4f80-256">Avoid running BI dashboard queries directly against the data warehouse.</span></span> <span data-ttu-id="b4f80-257">BI-Dashboards erfordern sehr kurze Antwortzeiten, die direkte Warehouse-Abfragen möglicherweise nicht leisten können.</span><span class="sxs-lookup"><span data-stu-id="b4f80-257">BI dashboards require very low response times, which direct queries against the warehouse may be unable to satisfy.</span></span> <span data-ttu-id="b4f80-258">Darüber hinaus schränkt das Aktualisieren des Dashboards die Anzahl gleichzeitiger Abfragen ein, was sich auf die Leistung auswirken könnte.</span><span class="sxs-lookup"><span data-stu-id="b4f80-258">Also, refreshing the dashboard will count against the number of concurrent queries, which could impact performance.</span></span>

<span data-ttu-id="b4f80-259">Azure Analysis Services dient zum Behandeln der Abfrageanforderungen eines BI-Dashboards, daher ist die empfohlene Vorgehensweise die Abfrage von Analysis Services über Power BI.</span><span class="sxs-lookup"><span data-stu-id="b4f80-259">Azure Analysis Services is designed to handle the query requirements of a BI dashboard, so the recommended practice is to query Analysis Services from Power BI.</span></span>

## <a name="scalability-considerations"></a><span data-ttu-id="b4f80-260">Überlegungen zur Skalierbarkeit</span><span class="sxs-lookup"><span data-stu-id="b4f80-260">Scalability considerations</span></span>

### <a name="sql-data-warehouse"></a><span data-ttu-id="b4f80-261">SQL Data Warehouse</span><span class="sxs-lookup"><span data-stu-id="b4f80-261">SQL Data Warehouse</span></span>

<span data-ttu-id="b4f80-262">Sie können mit SQL Data Warehouse Serverressourcen bedarfsabhängig horizontal hochskalieren.</span><span class="sxs-lookup"><span data-stu-id="b4f80-262">With SQL Data Warehouse, you can scale out your compute resources on demand.</span></span> <span data-ttu-id="b4f80-263">Das Abfragemodul optimiert Abfragen für die parallele Verarbeitung basierend auf der Anzahl von Serverknoten und verschiebt Daten nach Bedarf zwischen Knoten.</span><span class="sxs-lookup"><span data-stu-id="b4f80-263">The query engine optimizes queries for parallel processing based on the number of compute nodes, and moves data between nodes as necessary.</span></span> <span data-ttu-id="b4f80-264">Weitere Informationen finden Sie unter [Verwalten von Computeressourcen in Azure SQL Data Warehouse](/azure/sql-data-warehouse/sql-data-warehouse-manage-compute-overview).</span><span class="sxs-lookup"><span data-stu-id="b4f80-264">For more information, see [Manage compute in Azure SQL Data Warehouse](/azure/sql-data-warehouse/sql-data-warehouse-manage-compute-overview).</span></span>

### <a name="analysis-services"></a><span data-ttu-id="b4f80-265">Analysis Services</span><span class="sxs-lookup"><span data-stu-id="b4f80-265">Analysis Services</span></span>

<span data-ttu-id="b4f80-266">Bei Produktionsworkloads sollten Sie den Standard-Tarif für Azure Analysis Services nutzen, da er Partitionierung und DirectQuery unterstützt.</span><span class="sxs-lookup"><span data-stu-id="b4f80-266">For production workloads, we recommend the Standard Tier for Azure Analysis Services, because it supports partitioning and DirectQuery.</span></span> <span data-ttu-id="b4f80-267">Innerhalb eines Tarifs bestimmt die Größe der Instanz Arbeitsspeicher und Verarbeitungsleistung.</span><span class="sxs-lookup"><span data-stu-id="b4f80-267">Within a tier, the instance size determines the memory and processing power.</span></span> <span data-ttu-id="b4f80-268">Die Verarbeitungsleistung wird in Query Processing Units (QPUs) gemessen.</span><span class="sxs-lookup"><span data-stu-id="b4f80-268">Processing power is measured in Query Processing Units (QPUs).</span></span> <span data-ttu-id="b4f80-269">Beobachten Sie Ihre QPU-Nutzung, um die geeignete Größe auszuwählen.</span><span class="sxs-lookup"><span data-stu-id="b4f80-269">Monitor your QPU usage to select the appropriate size.</span></span> <span data-ttu-id="b4f80-270">Weitere Informationen finden Sie unter [Überwachen von Servermetriken](/azure/analysis-services/analysis-services-monitor).</span><span class="sxs-lookup"><span data-stu-id="b4f80-270">For more information, see [Monitor server metrics](/azure/analysis-services/analysis-services-monitor).</span></span>

<span data-ttu-id="b4f80-271">Bei hoher Last kann die Abfrageleistung durch parallele Abfragen beeinträchtigt werden.</span><span class="sxs-lookup"><span data-stu-id="b4f80-271">Under high load, query performance can become degraded due to query concurrency.</span></span> <span data-ttu-id="b4f80-272">Sie können Analysis Services horizontal hochskalieren, indem Sie einen Pool von Replikaten zum Verarbeiten von Abfragen erstellen, sodass mehrere Abfragen gleichzeitig ausgeführt werden können.</span><span class="sxs-lookup"><span data-stu-id="b4f80-272">You can scale out Analysis Services by creating a pool of replicas to process queries, so that more queries can be performed concurrently.</span></span> <span data-ttu-id="b4f80-273">Die Verarbeitung des Datenmodells erfolgt immer auf dem primären Server.</span><span class="sxs-lookup"><span data-stu-id="b4f80-273">The work of processing the data model always happens on the primary server.</span></span> <span data-ttu-id="b4f80-274">Standardmäßig behandelt der primäre Server auch Abfragen.</span><span class="sxs-lookup"><span data-stu-id="b4f80-274">By default, the primary server also handles queries.</span></span> <span data-ttu-id="b4f80-275">Optional können Sie den primären Server ausschließlich zum Ausführen der Verarbeitung festlegen, sodass der Abfragepool alle Abfragen verarbeitet.</span><span class="sxs-lookup"><span data-stu-id="b4f80-275">Optionally, you can designate the primary server to run processing exclusively, so that the query pool handles all queries.</span></span> <span data-ttu-id="b4f80-276">Wenn Sie hohe Anforderungen an die Verarbeitung stellen, sollten Sie die Verarbeitung vom Abfragepool trennen.</span><span class="sxs-lookup"><span data-stu-id="b4f80-276">If you have high processing requirements, you should separate the processing from the query pool.</span></span> <span data-ttu-id="b4f80-277">Bei hohen Abfragelasten und relativ unaufwändiger Verarbeitung können Sie den primären Server in den Abfragepool einschließen.</span><span class="sxs-lookup"><span data-stu-id="b4f80-277">If you have high query loads, and relatively light processing, you can include the primary server in the query pool.</span></span> <span data-ttu-id="b4f80-278">Weitere Informationen finden Sie unter [Horizontales Hochskalieren von Azure Analysis Services](/azure/analysis-services/analysis-services-scale-out).</span><span class="sxs-lookup"><span data-stu-id="b4f80-278">For more information, see [Azure Analysis Services scale-out](/azure/analysis-services/analysis-services-scale-out).</span></span>

<span data-ttu-id="b4f80-279">Um unnötigen Verarbeitungsaufwand zu verringern, sollten Sie das tabellarische Modell mit Partitionen in logische Bereiche unterteilen.</span><span class="sxs-lookup"><span data-stu-id="b4f80-279">To reduce the amount of unnecessary processing, consider using partitions to divide the tabular model into logical parts.</span></span> <span data-ttu-id="b4f80-280">Jede Partition kann separat verarbeitet werden.</span><span class="sxs-lookup"><span data-stu-id="b4f80-280">Each partition can be processed separately.</span></span> <span data-ttu-id="b4f80-281">Weitere Informationen finden Sie unter [Partitionen](/sql/analysis-services/tabular-models/partitions-ssas-tabular).</span><span class="sxs-lookup"><span data-stu-id="b4f80-281">For more information, see [Partitions](/sql/analysis-services/tabular-models/partitions-ssas-tabular).</span></span>

## <a name="security-considerations"></a><span data-ttu-id="b4f80-282">Sicherheitshinweise</span><span class="sxs-lookup"><span data-stu-id="b4f80-282">Security considerations</span></span>

### <a name="ip-whitelisting-of-analysis-services-clients"></a><span data-ttu-id="b4f80-283">IP-Positivlisten von Analysis Services-Clients</span><span class="sxs-lookup"><span data-stu-id="b4f80-283">IP whitelisting of Analysis Services clients</span></span>

<span data-ttu-id="b4f80-284">Erwägen Sie, mit dem Firewallfeature von Analysis Services Positivlisten von Client-IP-Adressen zu erstellen.</span><span class="sxs-lookup"><span data-stu-id="b4f80-284">Consider using the Analysis Services firewall feature to whitelist client IP addresses.</span></span> <span data-ttu-id="b4f80-285">Bei Aktivierung blockiert die Firewall alle Clientverbindungen, die nicht in den Firewallregeln angegeben sind.</span><span class="sxs-lookup"><span data-stu-id="b4f80-285">If enabled, the firewall blocks all client connections other than those specified in the firewall rules.</span></span> <span data-ttu-id="b4f80-286">Die Standardregeln setzen den Power BI-Dienst auf die Positivliste, aber Sie können diese Regel falls gewünscht deaktivieren.</span><span class="sxs-lookup"><span data-stu-id="b4f80-286">The default rules whitelist the Power BI service, but you can disable this rule if desired.</span></span> <span data-ttu-id="b4f80-287">Weitere Informationen finden Sie unter [Härtung von Azure Analysis Services mit der neuen Firewallfunktion](https://azure.microsoft.com/blog/hardening-azure-analysis-services-with-the-new-firewall-capability/).</span><span class="sxs-lookup"><span data-stu-id="b4f80-287">For more information, see [Hardening Azure Analysis Services with the new firewall capability](https://azure.microsoft.com/blog/hardening-azure-analysis-services-with-the-new-firewall-capability/).</span></span>

### <a name="authorization"></a><span data-ttu-id="b4f80-288">Autorisierung</span><span class="sxs-lookup"><span data-stu-id="b4f80-288">Authorization</span></span>

<span data-ttu-id="b4f80-289">Azure Analysis Services authentifiziert mit Azure Active Directory (Azure AD) Benutzer, die eine Verbindung mit dem Analysis Services-Server herstellen.</span><span class="sxs-lookup"><span data-stu-id="b4f80-289">Azure Analysis Services uses Azure Active Directory (Azure AD) to authenticate users who connect to an Analysis Services server.</span></span> <span data-ttu-id="b4f80-290">Sie können einschränken, welche Daten ein bestimmter Benutzer anzeigen kann, indem Sie Rollen erstellen und dann Azure AD-Benutzer oder Gruppen diesen Rollen zuweisen.</span><span class="sxs-lookup"><span data-stu-id="b4f80-290">You can restrict what data a particular user is able to view, by creating roles and then assigning Azure AD users or groups to those roles.</span></span> <span data-ttu-id="b4f80-291">Für jede Rolle können Sie:</span><span class="sxs-lookup"><span data-stu-id="b4f80-291">For each role, you can:</span></span> 

- <span data-ttu-id="b4f80-292">Tabellen oder einzelne Spalten schützen.</span><span class="sxs-lookup"><span data-stu-id="b4f80-292">Protect tables or individual columns.</span></span> 
- <span data-ttu-id="b4f80-293">Einzelne Zeilen basierend auf Filterausdrücken schützen.</span><span class="sxs-lookup"><span data-stu-id="b4f80-293">Protect individual rows based on filter expressions.</span></span> 

<span data-ttu-id="b4f80-294">Weitere Informationen finden Sie unter [Verwalten von Datenbankrollen und Benutzern](/azure/analysis-services/analysis-services-database-users).</span><span class="sxs-lookup"><span data-stu-id="b4f80-294">For more information, see [Manage database roles and users](/azure/analysis-services/analysis-services-database-users).</span></span>

## <a name="deploy-the-solution"></a><span data-ttu-id="b4f80-295">Bereitstellen der Lösung</span><span class="sxs-lookup"><span data-stu-id="b4f80-295">Deploy the solution</span></span>

<span data-ttu-id="b4f80-296">Führen Sie zum Bereitstellen und Ausführen der Referenzimplementierung die Schritte in der [GitHub-Infodatei][github-folder] aus.</span><span class="sxs-lookup"><span data-stu-id="b4f80-296">To the deploy and run the reference implementation, follow the steps in the [GitHub readme][github-folder].</span></span> <span data-ttu-id="b4f80-297">Folgendes wird bereitgestellt:</span><span class="sxs-lookup"><span data-stu-id="b4f80-297">It deploys the following:</span></span>

- <span data-ttu-id="b4f80-298">Eine Windows-VM, um einen lokalen Datenbankserver zu simulieren.</span><span class="sxs-lookup"><span data-stu-id="b4f80-298">A Windows VM to simulate an on-premises database server.</span></span> <span data-ttu-id="b4f80-299">Sie enthält SQL Server 2017 und zugehörige Tools zusammen mit Power BI Desktop.</span><span class="sxs-lookup"><span data-stu-id="b4f80-299">It includes SQL Server 2017 and related tools, along with Power BI Desktop.</span></span>
- <span data-ttu-id="b4f80-300">Ein Azure Storage-Konto, das Blobspeicher zum Speichern von Daten bereitstellt, die aus SQL Server-Datenbank exportiert wurden.</span><span class="sxs-lookup"><span data-stu-id="b4f80-300">An Azure storage account that provides Blob storage to hold data exported from the SQL Server database.</span></span>
- <span data-ttu-id="b4f80-301">Eine Instanz von Azure SQL Data Warehouse.</span><span class="sxs-lookup"><span data-stu-id="b4f80-301">An Azure SQL Data Warehouse instance.</span></span>
- <span data-ttu-id="b4f80-302">Eine Azure Analysis Services-Instanz.</span><span class="sxs-lookup"><span data-stu-id="b4f80-302">An Azure Analysis Services instance.</span></span>

## <a name="next-steps"></a><span data-ttu-id="b4f80-303">Nächste Schritte</span><span class="sxs-lookup"><span data-stu-id="b4f80-303">Next steps</span></span>

- <span data-ttu-id="b4f80-304">Verwenden Sie Azure Data Factory, um die ELT-Pipeline zu automatisieren.</span><span class="sxs-lookup"><span data-stu-id="b4f80-304">Use Azure Data Factory to automate the ELT pipeline.</span></span> <span data-ttu-id="b4f80-305">Siehe [Automatisierte Enterprise BI-Instanz mit SQL Data Warehouse und Azure Data Factory][adf-ra].</span><span class="sxs-lookup"><span data-stu-id="b4f80-305">See [Automated enterprise BI with SQL Data Warehouse and Azure Data Factory][adf-ra].</span></span>

<!-- links -->

[adf-ra]: ./enterprise-bi-adf.md
[github-folder]: https://github.com/mspnp/reference-architectures/tree/master/data/enterprise_bi_sqldw
[wwi]: /sql/sample/world-wide-importers/wide-world-importers-oltp-database
