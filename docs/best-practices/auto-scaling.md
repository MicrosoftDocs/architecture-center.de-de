---
title: "Anleitungen für die automatische Skalierung"
description: "Leitfaden zur automatischen Skalierung, um die von einer Anwendung benötigten Ressourcen dynamisch zuzuweisen."
author: dragon119
ms.date: 05/17/2017
pnp.series.title: Best Practices
ms.openlocfilehash: a8489aaabab2b8523fbc9f026f4f435bb6d1ad29
ms.sourcegitcommit: 3d9ee03e2dda23753661a80c7106d1789f5223bb
ms.translationtype: HT
ms.contentlocale: de-DE
ms.lasthandoff: 02/23/2018
---
# <a name="autoscaling"></a>Automatische Skalierung
[!INCLUDE [header](../_includes/header.md)]

Die automatische Skalierung ist der Prozess zum dynamischen Zuweisen von Ressourcen gemäß den jeweiligen Leistungsanforderungen. Wenn das Arbeitsvolumen zunimmt, sind für eine Anwendung ggf. zusätzliche Ressourcen erforderlich, um die gewünschten Leistungsebenen aufrechtzuerhalten und die Vereinbarungen zum Servicelevel (SLAs) einzuhalten. Wenn die Nachfrage abnimmt und die zusätzlichen Ressourcen nicht mehr benötigt werden, kann die Zuordnung aufgehoben werden, um die Kosten zu senken.

Die automatische Skalierung nutzt die Elastizität von Umgebungen, die in der Cloud gehostet werden, und reduziert gleichzeitig den Verwaltungsaufwand. Der Verwaltungsaufwand wird reduziert, da die Leistung des Systems nicht ständig von einem Mitarbeiter überwacht werden muss, der Entscheidungen über das Hinzufügen oder Entfernen von Ressourcen trifft.

Es gibt im Wesentlichen zwei Möglichkeiten, eine Anwendung zu skalieren: 

* Bei der **vertikalen Skalierung** (auch als zentrales Hoch- und Herunterskalieren bezeichnet) wird die Kapazität einer Ressource geändert. Beispielsweise kann eine Anwendung auf eine höhere VM-Größe skaliert werden. Für die vertikale Skalierung ist es häufig erforderlich, dass das System während der erneuten Bereitstellung vorübergehend nicht verfügbar ist. Daher ist es weniger häufig der Fall, dass die vertikale Skalierung automatisiert wird.
* Bei der **horizontalen Skalierung** (auch als horizontales Hoch- und Herunterskalieren bezeichnet) werden Instanzen einer Ressource hinzugefügt oder daraus entfernt. Die Anwendung wird weiter ohne Unterbrechung ausgeführt, wenn neue Ressourcen bereitgestellt werden. Nach Abschluss des Bereitstellungsprozesses wird die Lösung auf diesen zusätzlichen Ressourcen bereitgestellt. Wenn die Nachfrage nachlässt, können die zusätzlichen Ressourcen sauber heruntergefahren und die Zuordnungen dafür aufgehoben werden. 

Viele cloudbasierte Systeme, einschließlich Microsoft Azure, unterstützen die automatische horizontale Skalierung. Im restlichen Teil dieses Artikels geht es um die horizontale Skalierung.

> [!NOTE]
> Die automatische Skalierung betrifft hauptsächlich Computeressourcen. Es ist zwar möglich, eine Datenbank oder Nachrichtenwarteschlange horizontal zu skalieren, aber dies beinhaltet normalerweise auch eine [Datenpartitionierung][data-partitioning], die meist nicht automatisiert ist.
>

## <a name="overview"></a>Übersicht

Eine Strategie für die automatische Skalierung umfasst in der Regel die folgenden Elemente:

* Instrumentierung und Überwachungssysteme auf Anwendungs-, Dienst- und Infrastrukturebene. Diese Systeme erfassen wichtige Metriken wie Antwortzeiten, Warteschlangenlängen, CPU-Auslastung und Speicherauslastung.
* Logik für die Entscheidungsfindung, mit der diese Metriken anhand von vordefinierten Schwellenwerten oder Zeitplänen ausgewertet werden, um die Skalierungsentscheidung treffen zu können.
* Komponenten, mit denen das System skaliert wird.
* Testen, Überwachen und Optimieren der Strategie für die automatische Skalierung, um sicherzustellen, dass sie wie erwartet funktioniert.

In Azure werden integrierte Mechanismen für die automatische Skalierung bereitgestellt, um häufig auftretende Szenarien zu bewältigen. Wenn ein bestimmter Dienst oder eine Technologie nicht über integrierte Funktionen für die automatische Skalierung verfügt oder wenn bei Ihnen Anforderungen in Bezug auf die automatische Skalierung bestehen, die damit nicht erfüllt werden können, können Sie eine benutzerdefinierte Implementierung in Erwägung ziehen. Bei einer benutzerdefinierten Implementierung werden betriebs- und systembezogene Metriken gesammelt und analysiert und die Ressourcen dann entsprechend skaliert.

## <a name="configure-autoscaling-for-an-azure-solution"></a>Konfigurieren der automatischen Skalierung für eine Azure-Lösung

Azure ermöglicht die integrierte automatische Skalierung für die meisten Compute-Optionen.

* **Virtuelle Computer** unterstützen die automatische Skalierung über die Nutzung von [VM Scale Sets][vm-scale-sets], mit denen eine Gruppe von virtuellen Azure-Computern verwaltet werden kann. Informationen hierzu finden Sie unter [Verwenden von automatischer Skalierung und VM-Skalierungsgruppen][vm-scale-sets-autoscale].

* **Service Fabric** unterstützt ebenfalls die automatische Skalierung über VM Scale Sets. Jeder Knotentyp in einem Service Fabric-Cluster wird als separate VM-Skalierungsgruppe festgelegt. Auf diese Weise kann jeder Knotentyp einzeln horizontal herunter- oder hochskaliert werden. Informationen hierzu finden Sie unter [Zentrales Hoch- oder Herunterskalieren eines Service Fabric-Clusters mithilfe von Regeln für die automatische Skalierung][service-fabric-autoscale].

* In **Azure App Service** ist die automatische Skalierung integriert. Einstellungen für die automatische Skalierung gelten für alle Apps in einer App Service-Instanz. Informationen hierzu finden Sie unter [Manuelles oder automatisches Skalieren der Instanzenzahl][app-service-autoscale].

* **Azure Cloud Services** verfügen über eine integrierte automatische Skalierung auf Rollenebene. Informationen hierzu finden Sie unter [Konfigurieren der automatischen Skalierung für einen Clouddienst im Portal][cloud-services-autoscale].

Für diese Compute-Optionen wird jeweils die [automatische Azure Monitor-Skalierung][monitoring] genutzt, um einen allgemeinen Satz mit Funktionen für die automatische Skalierung bereitzustellen.

* **Azure Functions** unterscheidet sich von den vorherigen Compute-Optionen, da Sie hierfür keine Regeln für die automatische Skalierung konfigurieren müssen. Stattdessen ordnet Azure Functions automatisch Rechenleistung zu, wenn Ihr Code ausgeführt wird, und führt das horizontale Hochskalieren bedarfsabhängig durch, um die Last zu bewältigen. Weitere Informationen finden Sie unter [Auswählen des richtigen Hostingplans für Azure Functions][functions-scale].

In einigen Fällen kann eine benutzerdefinierte Lösung für die automatische Skalierung nützlich sein. Sie können beispielsweise die Azure-Diagnose und anwendungsbasierte Metriken zusammen mit benutzerdefiniertem Code nutzen, um die Anwendungsmetriken zu überwachen und zu exportieren. Anschließend können Sie benutzerdefinierte Regeln basierend auf diesen Metriken definieren und Resource Manager-REST-APIs verwenden, um die automatische Skalierung auszulösen. Eine benutzerdefinierte Lösung ist aber nicht einfach zu implementieren und sollte nur in Betracht gezogen werden, wenn keine der vorherigen Methoden Ihre Anforderungen erfüllen kann.

Verwenden Sie die integrierten Features für die automatische Skalierung der Plattform, wenn diese Ihre Anforderungen erfüllen. Überlegen Sie sich andernfalls, ob Sie wirklich komplexere Skalierungsfunktionen benötigen. Beispiele für zusätzliche Anforderungen sind eine präzisere Steuerung, verschiedene Methoden zum Erkennen von auslösenden Ereignissen für die Skalierung, die abonnementübergreifende Skalierung und das Skalieren anderer Ressourcentypen.

## <a name="use-azure-monitor-autoscale"></a>Verwenden der automatischen Azure Monitor-Skalierung

Bei der [automatischen Azure Monitor-Skalierung][monitoring] wird eine allgemeine Gruppe von Funktionen zur automatischen Skalierung von VM Scale Sets, Azure App Service und Azure Cloud Services bereitgestellt. Die Skalierung kann nach einem Zeitplan durchgeführt werden oder auf einer Laufzeitmetrik basieren, z.B. CPU oder Speicherauslastung. Beispiele:

- Horizontales Hochskalieren auf zehn Instanzen an Wochentagen, und horizontales Herunterskalieren auf vier Instanzen am Samstag und Sonntag. 
- Horizontales Hochskalieren um eine Instanz, wenn die durchschnittliche CPU-Auslastung über 70% liegt, und horizontales Herunterskalieren um eine Instanz, wenn die CPU-Auslastung unter 50% fällt.
- Horizontales Hochskalieren um eine Instanz, wenn die Anzahl von Nachrichten in einer Warteschlange einen bestimmten Schwellenwert überschreitet.

Eine Liste mit integrierten Metriken finden Sie unter [Allgemeine Metriken für die automatische Skalierung in Azure Monitor][autoscale-metrics]. Sie können auch benutzerdefinierte Metriken implementieren, indem Sie Application Insights verwenden. 

Sie können die automatische Skalierung konfigurieren, indem Sie PowerShell, die Azure CLI, eine Azure Resource Manager-Vorlage oder das Azure-Portal verwenden. Verwenden Sie die [Azure Resource Manager-REST-API](https://msdn.microsoft.com//library/azure/dn790568.aspx), wenn Sie ausführlichere Steuerungsmöglichkeiten benötigen. Außerdem stehen mit der [Azure Monitoring Services-Verwaltungsbibliothek](http://www.nuget.org/packages/Microsoft.WindowsAzure.Management.Monitoring) und der [Microsoft Insights-Bibliothek](https://www.nuget.org/packages/Microsoft.Azure.Insights/) (in der Vorschau) SDKs zur Verfügung, mit denen Sie Metriken aus verschiedenen Ressourcen sammeln und unter Verwendung von REST-APIs eine automatische Skalierung durchführen können. Für Ressourcen, die nicht durch Azure Resource Manager unterstützt werden, oder bei Verwendung von Azure Cloud Services kann die automatische Skalierung mit der Dienstverwaltungs-REST-API durchgeführt werden. Verwenden Sie in allen anderen Fällen Azure Resource Manager.

Beachten Sie bei der Verwendung der automatischen Azure-Skalierung Folgendes:

* Überlegen Sie, ob Sie die Auslastung der Anwendung gut genug vorhersagen können, um die geplante automatische Skalierung zu nutzen und dann Instanzen hinzuzufügen und zu entfernen, wenn prognostizierte Bedarfsspitzen abgedeckt werden müssen. Falls dies nicht möglich ist, können Sie die reaktive automatische Skalierung basierend auf Laufzeitmetriken verwenden, um unvorhersehbare Änderungen des Bedarfs zu bewältigen. Üblicherweise können die beiden Herangehensweisen kombiniert werden. Erstellen Sie beispielsweise eine Strategie, bei der Ressourcen basierend auf einem Zeitplan mit Zeiten hinzugefügt werden, in denen die Anwendung bekanntermaßen am stärksten ausgelastet ist. Hierdurch wird sichergestellt, dass Kapazität bei Bedarf zur Verfügung steht, ohne dass durch den Neustart von Instanzen Verzögerungen auftreten. Definieren Sie für jede geplante Regel die Metriken, die das reaktive automatische Skalieren während des Zeitraums zulassen, um sicherzustellen, dass die Anwendung nachhaltige aber unvorhersehbare Bedarfsspitzen verarbeiten kann.
* Die Beziehung zwischen Metriken und Kapazitätsanforderungen ist häufig schwer zu verstehen, insbesondere dann, wenn eine Anwendung zum ersten Mal bereitgestellt wird. Stellen Sie zu Beginn etwas mehr Kapazität bereit, und überwachen und optimieren Sie dann die Regeln für die automatische Skalierung, um die Kapazität besser auf die tatsächliche Auslastung abzustimmen.
* Konfigurieren Sie die Regeln für die automatische Skalierung, und überwachen Sie anschließend die Leistung Ihrer Anwendung im Laufe der Zeit. Verwenden Sie die Ergebnisse dieser Überwachung, um die Art und Weise anzupassen, in der das System bei Bedarf skaliert wird. Allerdings sollten Sie bedenken, dass die automatische Skalierung nicht sofort geschieht. Es dauert einige Zeit, bis auf eine Metrik (z. B. die durchschnittliche CPU-Auslastung) reagiert wird, die einen angegebenen Schwellenwert über- oder unterschreitet.
* Regeln für die automatische Skalierung, die einen Erkennungsmechanismus basierend auf einem gemessenen Auslöserattribut verwenden (z. B. CPU-Auslastung oder Warteschlangenlänge), nutzen anstelle von unmittelbaren Werten einen über einen längeren Zeitraum aggregierten Wert, um eine Aktion zur automatischen Skalierung auszulösen. Standardmäßig ist das Aggregat ein Durchschnitt der Werte. Dies verhindert, dass das System zu schnell reagiert oder eine schnelle Oszillation verursacht. Außerdem wird so Zeit für neue Instanzen ermöglicht, die automatisch gestartet und in den ausgeführten Modus versetzt werden, sodass keine zusätzlichen automatischen Skalierungsaktionen auftreten, während die neuen Instanzen gestartet werden. Für Azure Cloud Services und Azure Virtual Machines beträgt der Standardzeitraum für die Aggregation 45 Minuten. Es kann also 45 Minuten dauern, bis die Metrik die automatische Skalierung als Reaktion auf Bedarfsspitzen auslöst. Sie können den Aggregationszeitraum mit dem SDK ändern. Beachten Sie aber, dass Zeiträume von weniger als 25 Minuten zu unvorhersehbaren Ergebnissen führen können. Weitere Informationen finden Sie unter [Automatische Skalierung von Clouddiensten für die prozentuale CPU-Auslastung mit der Azure Monitoring Services-Verwaltungsbibliothek](http://rickrainey.com/2013/12/15/auto-scaling-cloud-services-on-cpu-percentage-with-the-windows-azure-monitoring-services-management-library/). Bei Web-Apps ist der durchschnittliche Zeitraum viel kürzer, und neue Instanzen stehen etwa fünf Minuten nach einer Änderung der durchschnittlichen Auslöseaktion zur Verfügung.
* Wenn Sie die automatische Skalierung über das SDK statt über das Portal konfigurieren, können Sie einen detaillierteren Zeitplan angeben, in dem die Regeln aktiv sind. Sie können auch eigene Metriken erstellen und diese mit oder ohne vorhandenen in Ihren Regeln für die automatische Skalierung verwenden. Sie können beispielsweise alternative Leistungsindikatoren verwenden, z. B. die Anzahl von Anforderungen pro Sekunde oder die durchschnittliche Arbeitsspeicherverfügbarkeit. Sie können auch benutzerdefinierte Leistungsindikatoren verwenden, die bestimmte Geschäftsprozesse messen.
* Bei der automatischen Service Fabric-Skalierung bestehen die Knotentypen in Ihrem Cluster am Back-End aus VM-Skalierungsgruppen, sodass Sie für jeden Knotentyp Regeln für die automatische Skalierung einrichten müssen. Sie sollten dabei die Anzahl der Knoten berücksichtigen, die Sie benötigen, bevor Sie die automatische Skalierung einrichten. Die minimale Anzahl von Knoten, die für den primären Knotentyp benötigt wird, wird von der Zuverlässigkeitsstufe gesteuert, die Sie ausgewählt haben. Weitere Informationen finden Sie unter [Zentrales Hoch- oder Herunterskalieren eines Service Fabric-Clusters mithilfe von Regeln für die automatische Skalierung](https://docs.microsoft.com/azure/service-fabric/service-fabric-cluster-scale-up-down).
* Sie können Ressourcen wie SQL-Datenbankinstanzen und Warteschlangen über das Portal mit einer Computedienstinstanz verknüpfen. Dadurch erhalten Sie einen einfacheren Zugriff auf die separaten Konfigurationsoptionen für das manuelle und das automatische Skalieren für jede einzelne verknüpfte Ressource. Weitere Informationen finden Sie unter [Verwalten von Clouddiensten](/azure/cloud-services/cloud-services-how-to-manage).
* Wenn Sie mehrere Richtlinien und Regeln konfigurieren, besteht die Möglichkeit, dass sie miteinander in Konflikt stehen. Die automatische Skalierung verwendet die folgenden Konfliktlösungsregeln, um sicherzustellen, dass immer eine ausreichende Anzahl von Instanzen ausgeführt wird:
  * Vorgänge mit horizontalem Hochskalieren haben immer Vorrang vor Vorgängen mit horizontalem Herunterskalieren.
  * Wenn Konflikte durch horizontales Herunterskalieren entstehen, hat die Regel Vorrang, die den größten Anstieg bei der Anzahl der Instanzen initiiert.
  * Wenn Konflikte durch horizontales Hochskalieren entstehen, hat die Regel Vorrang, die die kleinste Abnahme bei der Anzahl der Instanzen initiiert.
* In einer App Service-Umgebung können alle Workerpool- oder Front-End-Metriken zum Definieren von Regeln für die automatische Skalierung verwendet werden. Weitere Informationen finden Sie unter [Automatische Skalierung und App Service-Umgebung v1](/azure/app-service/app-service-environment-auto-scale).

## <a name="application-design-considerations"></a>Überlegungen zum Anwendungsentwurf
Die automatische Skalierung ist keine sofortige Lösung. Durch das einfache Hinzufügen von Ressourcen zu einem System oder durch das Ausführen mehrerer Instanzen eines Prozesses kann nicht sichergestellt werden, dass sich die Leistung des Systems verbessert. Beim Entwerfen einer Strategie für die automatische Skalierung sollten Sie folgende Punkte berücksichtigen:

* Das System muss so entworfen werden, dass es horizontal skalierbar ist. Vermeiden Sie Annahmen über die Instanzaffinität. Entwerfen Sie keine Lösungen, für die der Code immer in einer bestimmten Instanz eines Prozesses ausgeführt werden muss. Setzen Sie beim horizontalen Skalieren eines Clouddiensts oder einer Website nicht voraus, dass eine Reihe von Anforderungen aus derselben Quelle immer an dieselbe Instanz weitergeleitet wird. Aus demselben Grund sollten Sie statusfreie Dienste entwerfen, um zu vermeiden, dass eine Reihe von Anforderungen von einer Anwendung immer an dieselbe Instanz eines Diensts weitergeleitet werden müssen. Beim Entwerfen eines Diensts, der Nachrichten aus einer Warteschlange liest und verarbeitet, sollten Sie nicht voraussetzen, dass eine bestimmte Instanz des Diensts eine bestimmte Nachricht verarbeitet. Die automatische Skalierung könnte zusätzliche Instanzen eines Diensts starten, wenn die Warteschlangenlänge zunimmt. Im Artikel zum [Muster „Konkurrierende Consumer“][competing-consumers] wird beschrieben, wie Sie bei diesem Szenario vorgehen.
* Wenn die Lösung einen lang andauernden Task implementiert, entwerfen Sie diesen Task so, dass er das horizontale Hoch- und Herunterskalieren unterstützt. Ohne angemessene Sorgfalt könnte ein solcher Task verhindern, dass eine Instanz eines Prozesses ordnungsgemäß heruntergefahren wird, wenn das System horizontal herunterskaliert wird, oder es könnten Daten verloren gehen, wenn der Prozess abgebrochen wird. Im Idealfall sollten Sie einen lang andauernden Task umgestalten und die Verarbeitung in kleinere, einzelne Segmente aufteilen. Im Artikel zum [Muster „Pipes und Filter“][pipes-and-filters] wird ein entsprechendes Beispiel bereitgestellt.
* Alternativ können Sie einen Prüfpunktmechanismus implementieren, der Zustandsinformationen zum Task in regelmäßigen Abständen aufzeichnet und diesen Zustand in einem dauerhaften Speicher ablegt, auf den jede Instanz des Prozesses, der den Task ausführt, zugreifen kann. Wenn der Prozess heruntergefahren wird, kann die von ihm ausgeführte Arbeit auf diese Weise am letzten Prüfpunkt mithilfe einer anderen Instanz fortgesetzt werden.
* Wenn Hintergrundtasks auf separaten Compute-Instanzen ausgeführt werden, z. B. in Workerrollen der über Clouddienste gehosteten Anwendung, müssen Sie möglicherweise verschiedene Teile der Anwendung mit verschiedenen Skalierungsrichtlinien skalieren. Beispielsweise müssen Sie möglicherweise zusätzliche UI-Compute-Instanzen bereitstellen, ohne die Anzahl von Compute-Instanzen im Hintergrund zu erhöhen oder zu reduzieren. Wenn Sie verschiedene Dienstebenen anbieten (z. B. Standard- und Premium-Servicepakete), müssen Sie die Compute-Ressourcen für Premium-Servicepakete möglicherweise aggressiver als für Standardpakete horizontal hochskalieren, um SLAs einzuhalten.
* Sie können beispielsweise die Länge der Warteschlange, über die die UI und Hintergrund-Compute-Instanzen kommunizieren, als Kriterium für Ihre Strategie für die automatische Skalierung verwenden. Dies ist der beste Indikator für ein Ungleichgewicht oder Unterschied zwischen der aktuellen Arbeitslast und der Verarbeitungskapazität des Hintergrundtasks.
* Wenn Sie Ihre Strategie für die automatische Skalierung auf Leistungsindikatoren basieren, die Geschäftsprozesse messen, z. B. die Anzahl der Bestellungen pro Stunde oder die durchschnittliche Ausführungszeit einer komplexen Transaktion, stellen Sie sicher, dass Sie die Beziehung zwischen den Ergebnissen dieser Typen von Indikatoren und den tatsächlichen Compute-Kapazitätsanforderungen vollständig verstehen. Es kann erforderlich sein, mehr als eine Komponente oder Compute-Einheit als Reaktion auf Änderungen in den Unternehmensprozess-Leistungsindikatoren zu skalieren.  
* Um die exzessive Skalierung eines Systems zu verhindern und um die Kosten für das Ausführen mehrerer tausend Instanzen zu vermeiden, sollten Sie die maximale Anzahl von Instanzen, die automatisch hinzugefügt werden können, begrenzen. Die meisten Mechanismen für die automatische Skalierung ermöglichen Ihnen das Angeben der minimalen und der maximalen Anzahl der Instanzen für eine Regel. Darüber hinaus sollten Sie die Funktionalität, die das System bereitstellt, möglicherweise vorsichtig reduzieren, wenn die maximale Anzahl von Instanzen bereitgestellt wurde und das System überlastet ist.
* Bedenken Sie, dass die automatische Skalierung möglicherweise nicht der optimale Mechanismus zum Verarbeiten einer plötzlich zunehmenden Arbeitsauslastung ist. Das Bereitstellen und Starten neuer Instanzen eines Diensts und das Hinzufügen von Ressourcen zu einem System dauert einige Zeit, und wenn die zusätzlichen Ressourcen verfügbar sind, kann die Bedarfsspitze schon wieder vorbei sein. In diesem Szenario kann es besser sein, den Dienst zu drosseln. Weitere Informationen finden Sie unter [Throttling Pattern][throttling] (Drosselungsmuster).
* Umgekehrt gilt: Wenn Sie die Kapazität für die Verarbeitung aller Anforderungen bei einer schnellen Änderung des Volumens benötigen und wenn die Kosten kein wichtiger Faktor sind, können Sie auch eine aggressive Strategie zur automatischen Skalierung verwenden, die zusätzliche Instanzen schneller startet. Sie können auch eine geplante Richtlinie verwenden, die eine ausreichende Anzahl von Instanzen für die maximale Auslastung startet, bevor diese Auslastung erwartet wird.
* Der Mechanismus für die automatische Skalierung sollte den Prozess der automatischen Skalierung überwachen und Details der einzelnen Ereignisse der automatischen Skalierung protokollieren (wodurch das Ereignis ausgelöst wurde und wann welche Ressourcen hinzugefügt oder entfernt wurden). Wenn Sie einen benutzerdefinierten Mechanismus für die automatische Skalierung erstellen, stellen Sie sicher, dass diese Funktion enthalten ist. Überprüfen Sie die Informationen, um die Effektivität der Strategie für die automatische Skalierung zu ermitteln, und optimieren Sie die Strategie gegebenenfalls. Sie können die Strategie sowohl kurzfristig (wenn die Nutzungsmuster offensichtlicher werden) als auch langfristig optimieren (bei Geschäftserweiterung oder sich ändernden Anforderungen der Anwendung). Wenn eine Anwendung die definierte Obergrenze für die automatische Skalierung erreicht, kann der Mechanismus auch eine Warnung an einen Mitarbeiter senden, der bei Bedarf manuell zusätzliche Ressourcen starten kann. Beachten Sie, dass der Operator unter diesen Umständen auch für das manuelle Entfernen dieser Ressourcen nach dem Abklingen die Arbeitsauslastung zuständig sein kann.

## <a name="related-patterns-and-guidance"></a>Zugehörige Muster und Anleitungen
Die folgenden Muster und Anleitungen können auch für Ihr Szenario relevant sein, wenn die automatische Skalierung implementiert wird:

* [Throttling Pattern][throttling] (Drosselungsmuster): Dieses Muster beschreibt, wie eine Anwendung weiterhin funktionieren und Vereinbarungen zum Servicelevel erfüllen kann, wenn eine Bedarfssteigerung eine extreme Ressourcenauslastung mit sich bringt. Die Drosselung kann mit der automatischen Skalierung verwendet werden, um zu verhindern, dass ein System während des horizontalen Hochskalierens überlastet wird.
* [Muster „Konkurrierende Consumer“][competing-consumers]: Die automatische Skalierung kann zum Starten und Beenden von Dienstinstanzen entsprechend der erwarteten Arbeitslast verwendet werden. Dieser Ansatz ermöglicht ein System, mit dem mehrere Nachrichten gleichzeitig verarbeitet werden können. So wird der Durchsatz optimiert, Skalierbarkeit und Verfügbarkeit werden erhöht und die Arbeitsauslastung wird ausgeglichen.
* [Überwachung und Diagnose](./monitoring.md): Instrumentation und Telemetrie sind wichtig für das Sammeln von Informationen, die den Prozess der automatischen Skalierung unterstützen können.


<!-- links -->

[monitoring]: /azure/monitoring-and-diagnostics/monitoring-overview-autoscale
[app-service-autoscale]: /azure/monitoring-and-diagnostics/insights-how-to-scale?toc=%2fazure%2fapp-service-web%2ftoc.json#scaling-based-on-a-pre-set-metric
[app-service-plan]: /azure/app-service/azure-web-sites-web-hosting-plans-in-depth-overview
[autoscale-metrics]: /azure/monitoring-and-diagnostics/insights-autoscale-common-metrics
[cloud-services-autoscale]: /azure/cloud-services/cloud-services-how-to-scale-portal
[competing-consumers]: ../patterns/competing-consumers.md
[data-partitioning]: ./data-partitioning.md
[functions-scale]: /azure/azure-functions/functions-scale
[link-resource-to-cloud-service]: /azure/cloud-services/cloud-services-how-to-manage#how-to-link-a-resource-to-a-cloud-service
[pipes-and-filters]: ../patterns/pipes-and-filters.md
[service-fabric-autoscale]: /azure/service-fabric/service-fabric-cluster-scale-up-down
[throttling]: ../patterns/throttling.md
[vm-scale-sets]: /azure/virtual-machine-scale-sets/virtual-machine-scale-sets-overview
[vm-scale-sets-autoscale]: /azure/virtual-machine-scale-sets/virtual-machine-scale-sets-autoscale-overview
