---
title: Fehlerbehebung bei Leistungsproblemen für Azure Databricks mit Azure Monitor
titleSuffix: ''
description: Verwenden von Grafana-Dashboards zum Beheben von Leistungsproblemen in Azure Databricks
author: petertaylor9999
ms.date: 04/02/2019
ms.topic: ''
ms.service: ''
ms.subservice: ''
ms.openlocfilehash: 49ec63d0c45ab388ca83b3ab0562428327539619
ms.sourcegitcommit: 1a3cc91530d56731029ea091db1f15d41ac056af
ms.translationtype: HT
ms.contentlocale: de-DE
ms.lasthandoff: 04/03/2019
ms.locfileid: "58887889"
---
# <a name="troubleshoot-performance-bottlenecks-in-azure-databricks"></a><span data-ttu-id="54a25-103">Behandeln von Leistungsengpässen in Azure Databricks</span><span class="sxs-lookup"><span data-stu-id="54a25-103">Troubleshoot performance bottlenecks in Azure Databricks</span></span>

<span data-ttu-id="54a25-104">Dieser Artikel beschreibt, wie Überwachungsdashboards verwendet werden, um Leistungsengpässe in Spark-Aufträgen unter Azure Databricks aufzuspüren.</span><span class="sxs-lookup"><span data-stu-id="54a25-104">This article describes how to use monitoring dashboards to find performance bottlenecks in Spark jobs on Azure Databricks.</span></span>

<span data-ttu-id="54a25-105">[Azure Databricks](/azure/azure-databricks/) ist ein Analysedienst, der auf [Apache Spark](https://spark.apache.org/) basiert und eine zügige Entwicklung und Bereitstellung von Analyselösungen für Big Data ermöglicht.</span><span class="sxs-lookup"><span data-stu-id="54a25-105">[Azure Databricks](/azure/azure-databricks/) is an [Apache Spark](https://spark.apache.org/)–based analytics service that makes it easy to rapidly develop and deploy big data analytics.</span></span> <span data-ttu-id="54a25-106">Überwachung und Behandlung von Leistungsproblemen sind im Umgang mit Azure Databricks-Produktionsworkloads entscheidend.</span><span class="sxs-lookup"><span data-stu-id="54a25-106">Monitoring and troubleshooting performance issues is a critical when operating production Azure Databricks workloads.</span></span> <span data-ttu-id="54a25-107">Um häufig auftretende Leistungsprobleme identifizieren zu können, ist es hilfreich, Überwachungsvisualisierungen auf der Grundlage von Telemetriedaten zu verwenden.</span><span class="sxs-lookup"><span data-stu-id="54a25-107">To identify common performance issues, it's helpful to use monitoring visualizations based on telemetry data.</span></span>

## <a name="prerequisites"></a><span data-ttu-id="54a25-108">Voraussetzungen</span><span class="sxs-lookup"><span data-stu-id="54a25-108">Prerequisites</span></span>

<span data-ttu-id="54a25-109">So richten Sie die in diesem Artikel gezeigten Grafana-Dashboards ein:</span><span class="sxs-lookup"><span data-stu-id="54a25-109">To set up the Grafana dashboards shown in this article:</span></span>

- <span data-ttu-id="54a25-110">Konfigurieren Sie den Databricks-Cluster mit der Azure Databricks-Überwachungsbibliothek zum Senden von Telemetriedaten an einen Log Analytics-Arbeitsbereich.</span><span class="sxs-lookup"><span data-stu-id="54a25-110">Configure your Databricks cluster to send telemetry to a Log Analytics workspace, using the Azure Databricks Monitoring Library.</span></span> <span data-ttu-id="54a25-111">Weitere Informationen finden Sie unter [Konfigurieren von Azure Databricks zum Senden von Metriken an Azure Monitor](./configure-cluster.md).</span><span class="sxs-lookup"><span data-stu-id="54a25-111">For details, see [Configure Azure Databricks to send metrics to Azure Monitor](./configure-cluster.md).</span></span>

- <span data-ttu-id="54a25-112">Stellen Sie Grafana auf einem virtuellen Computer bereit.</span><span class="sxs-lookup"><span data-stu-id="54a25-112">Deploy Grafana in a virtual machine.</span></span> <span data-ttu-id="54a25-113">Weitere Informationen finden Sie unter [Visualisieren von Azure Databricks-Metriken mithilfe von Dashboards](./dashboards.md).</span><span class="sxs-lookup"><span data-stu-id="54a25-113">See [Use dashboards to visualize Azure Databricks metrics](./dashboards.md).</span></span>

<span data-ttu-id="54a25-114">Das bereitgestellte Grafana-Dashboard enthält einen Satz von Zeitreihenvisualisierungen.</span><span class="sxs-lookup"><span data-stu-id="54a25-114">The Grafana dashboard that is deployed includes a set of time-series visualizations.</span></span> <span data-ttu-id="54a25-115">Jedes Diagramm ist ein Zeitreihenplot von Metriken, die sich auf einen Apache Spark-Auftrag, die Phasen des Auftrags und die Aufgaben, aus denen jede Phase besteht, beziehen.</span><span class="sxs-lookup"><span data-stu-id="54a25-115">Each graph is time-series plot of metrics related to an Apache Spark job, the stages of the job, and tasks that make up each stage.</span></span>

## <a name="azure-databricks-performance-overview"></a><span data-ttu-id="54a25-116">Übersicht zur Azure Databricks-Leistung</span><span class="sxs-lookup"><span data-stu-id="54a25-116">Azure Databricks performance overview</span></span>

<span data-ttu-id="54a25-117">Azure Databricks basiert auf Apache Spark, einem verteilten Computersystem für allgemeine Zwecke.</span><span class="sxs-lookup"><span data-stu-id="54a25-117">Azure Databricks is based on Apache Spark, a general-purpose distributed computing system.</span></span> <span data-ttu-id="54a25-118">Der als **Auftrag** bezeichnete Anwendungscode wird vom Cluster-Manager koordiniert in einem Apache Spark-Cluster ausgeführt.</span><span class="sxs-lookup"><span data-stu-id="54a25-118">Application code, known as a **job**, executes on an Apache Spark cluster, coordinated by the cluster manager.</span></span> <span data-ttu-id="54a25-119">Im Allgemeinen stellt ein Auftrag die höchste Berechnungseinheitenebene dar.</span><span class="sxs-lookup"><span data-stu-id="54a25-119">In general, a job is the highest-level unit of computation.</span></span> <span data-ttu-id="54a25-120">Ein Auftrag stellt den vollständigen Vorgang dar, den die Spark-Anwendung ausführt.</span><span class="sxs-lookup"><span data-stu-id="54a25-120">A job represents the complete operation performed by the Spark application.</span></span> <span data-ttu-id="54a25-121">Ein normaler Vorgang umfasst das Lesen von Daten aus einer Quelle, Anwenden von Datentransformationen und Schreiben der Ergebnisse in einen Speicher oder ein anderes Ziel.</span><span class="sxs-lookup"><span data-stu-id="54a25-121">A typical operation includes reading data from a source, applying data transformations, and writing the results to storage or another destination.</span></span>

<span data-ttu-id="54a25-122">Aufträge werden in **Phasen** aufgeschlüsselt.</span><span class="sxs-lookup"><span data-stu-id="54a25-122">Jobs are broken down into **stages**.</span></span> <span data-ttu-id="54a25-123">Der Auftrag durchläuft die Phasen sequenziell, was bedeutet, dass spätere Phasen erst ausgeführt werden können, wenn frühere Phasen abgeschlossen sind.</span><span class="sxs-lookup"><span data-stu-id="54a25-123">The job advances through the stages sequentially, which means that later stages must wait for earlier stages to complete.</span></span> <span data-ttu-id="54a25-124">Phasen enthalten Gruppen von identischen **Aufgaben**, die auf mehreren Knoten des Spark-Clusters parallel ausgeführt werden können.</span><span class="sxs-lookup"><span data-stu-id="54a25-124">Stages contain groups of identical **tasks** that can be executed in parallel on multiple nodes of the Spark cluster.</span></span> <span data-ttu-id="54a25-125">Aufgaben sind die detailliertesten Ausführungseinheiten, die für eine Teilmenge der Daten ausgeführt werden.</span><span class="sxs-lookup"><span data-stu-id="54a25-125">Tasks are the most granular unit of execution taking place on a subset of the data.</span></span>

<span data-ttu-id="54a25-126">Die nächsten Abschnitte beschreiben einige Dashboardvisualisierungen, die zur Behebung von Leistungsproblemen hilfreich sind.</span><span class="sxs-lookup"><span data-stu-id="54a25-126">The next sections describe some dashboard visualizations that are useful for performance troubleshooting.</span></span>

## <a name="job-and-stage-latency"></a><span data-ttu-id="54a25-127">Auftrags- und Phasenlatenz</span><span class="sxs-lookup"><span data-stu-id="54a25-127">Job and stage latency</span></span>

<span data-ttu-id="54a25-128">Die Auftragslatenz ist die Dauer der Auftragsausführung vom Zeitpunkt des Beginns bis zum Zeitpunkt des Abschlusses.</span><span class="sxs-lookup"><span data-stu-id="54a25-128">Job latency is the duration of a job execution from when it starts until it completes.</span></span> <span data-ttu-id="54a25-129">Sie wird in Quantilen einer Auftragsausführung pro Cluster und Anwendungs-ID angezeigt, um die Visualisierung von Ausreißern zu ermöglichen.</span><span class="sxs-lookup"><span data-stu-id="54a25-129">It is shown as percentiles of a job execution per cluster and application ID, to allow the visualization of outliers.</span></span> <span data-ttu-id="54a25-130">Das folgende Diagramm zeigt einen Auftragsverlauf, in dem das 90. Quantil 50 Sekunden erreichte, obwohl das 50. Quantil konsistent bei ca. 10 Sekunden lag.</span><span class="sxs-lookup"><span data-stu-id="54a25-130">The following graph shows a job history where the 90th percentile reached 50 seconds, even though the 50th percentile was consistently around 10 seconds.</span></span>

![Diagramm der Auftragslatenz](./_images/grafana-job-latency.png)

<span data-ttu-id="54a25-132">Untersuchen Sie die Ausführung des Auftrags nach Cluster und Anwendung, und achten Sie auf Latenzspitzen.</span><span class="sxs-lookup"><span data-stu-id="54a25-132">Investigate job execution by cluster and application, looking for spikes in latency.</span></span> <span data-ttu-id="54a25-133">Sobald Cluster und Anwendungen mit hoher Latenz identifiziert sind, fahren Sie mit der Untersuchung der Phasenlatenz fort.</span><span class="sxs-lookup"><span data-stu-id="54a25-133">Once clusters and applications with high latency are identified, move on to investigate stage latency.</span></span>

<span data-ttu-id="54a25-134">Die Phasenlatenz wird ebenfalls in Quantilen angezeigt, um die Visualisierung von Ausreißern zu ermöglichen.</span><span class="sxs-lookup"><span data-stu-id="54a25-134">Stage latency is also shown as percentiles to allow the visualization of outliers.</span></span> <span data-ttu-id="54a25-135">Die Phasenlatenz wird nach Cluster, Anwendung und Phasenname aufgeschlüsselt.</span><span class="sxs-lookup"><span data-stu-id="54a25-135">Stage latency is broken out by cluster, application, and stage name.</span></span> <span data-ttu-id="54a25-136">Identifizieren Sie Spitzen der Aufgabenlatenz im Diagramm, um zu bestimmen, welche Aufgaben den Abschluss der Phase aufhalten.</span><span class="sxs-lookup"><span data-stu-id="54a25-136">Identify spikes in task latency in the graph to determine which tasks are holding back completion of the stage.</span></span>

![Diagramm der Phasenlatenz](./_images/grafana-stage-latency.png)

<span data-ttu-id="54a25-138">Das Diagramm des Clusterdurchsatzes zeigt die Anzahl der Aufträge, Phasen und Aufgaben, die pro Minute abgeschlossen werden.</span><span class="sxs-lookup"><span data-stu-id="54a25-138">The cluster throughput graph shows the number of jobs, stages, and tasks completed per minute.</span></span> <span data-ttu-id="54a25-139">So können Sie die Workload im Hinblick auf die relative Anzahl von Phasen und Aufgaben pro Auftrag besser verstehen.</span><span class="sxs-lookup"><span data-stu-id="54a25-139">This helps you to understand the workload in terms of the relative number of stages and tasks per job.</span></span> <span data-ttu-id="54a25-140">Hier sehen Sie, dass die Anzahl der Aufträge pro Minute im Bereich zwischen 2 und 6 liegt, während die Anzahl der Phasen ungefähr 12 &ndash; 24 pro Minute beträgt.</span><span class="sxs-lookup"><span data-stu-id="54a25-140">Here you can see that the number of jobs per minute ranges between 2 and 6, while the number of stages is about 12 &ndash; 24 per minute.</span></span>

![Diagramm des Clusterdurchsatzes](./_images/grafana-cluster-throughput.png)

## <a name="sum-of-task-execution-latency"></a><span data-ttu-id="54a25-142">Summe der Aufgabenausführungslatenz</span><span class="sxs-lookup"><span data-stu-id="54a25-142">Sum of task execution latency</span></span>

<span data-ttu-id="54a25-143">Diese Visualisierung zeigt die Summe der Aufgabenausführungslatenz pro Host in einem Cluster.</span><span class="sxs-lookup"><span data-stu-id="54a25-143">This visualization shows the sum of task execution latency per host running on a cluster.</span></span> <span data-ttu-id="54a25-144">Verwenden Sie dieses Diagramm, um Aufgaben zu erkennen, die aufgrund der Verlangsamung des Hosts auf einem Cluster oder der Fehlzuordnung von Aufgaben pro Executor langsam ausgeführt werden.</span><span class="sxs-lookup"><span data-stu-id="54a25-144">Use this graph to detect tasks that run slowly due to the host slowing down on a cluster, or a misallocation of tasks per executor.</span></span> <span data-ttu-id="54a25-145">Im folgenden Diagramm haben die meisten Hosts eine Summe von ungefähr 30 Sekunden.</span><span class="sxs-lookup"><span data-stu-id="54a25-145">In the following graph, most of the hosts have a sum of about 30 seconds.</span></span> <span data-ttu-id="54a25-146">Allerdings haben zwei Hosts Summen von etwa 10 Minuten.</span><span class="sxs-lookup"><span data-stu-id="54a25-146">However, two of the hosts have sums that hover around 10 minutes.</span></span> <span data-ttu-id="54a25-147">Entweder werden die Hosts langsam ausgeführt, oder die Anzahl der Aufgaben pro Executor ist falsch zugeordnet.</span><span class="sxs-lookup"><span data-stu-id="54a25-147">Either the hosts are running slow or the number of tasks per executor is misallocated.</span></span>

![Diagramm der Summe der Taskausführungen pro Host](./_images/grafana-sum-task-exec.png)

<span data-ttu-id="54a25-149">Die Anzahl der Aufgaben pro Executor zeigt, dass zwei Executor eine unverhältnismäßig hohe Anzahl von Aufgaben zugewiesen ist, was einen Engpass verursacht.</span><span class="sxs-lookup"><span data-stu-id="54a25-149">The number of tasks per executor shows that two executors are assigned a disproportionate number of tasks, causing a bottleneck.</span></span>

![Diagramm mit Aufgaben pro Executor](./_images/grafana-tasks-per-exec.png)

## <a name="task-metrics-per-stage"></a><span data-ttu-id="54a25-151">Aufgabenmetriken pro Phase</span><span class="sxs-lookup"><span data-stu-id="54a25-151">Task metrics per stage</span></span>

<span data-ttu-id="54a25-152">Die Visualisierung der Aufgabenmetriken zeigt die Aufschlüsselung der Kosten für eine Aufgabenausführung.</span><span class="sxs-lookup"><span data-stu-id="54a25-152">The task metrics visualization gives the cost breakdown for a task execution.</span></span> <span data-ttu-id="54a25-153">Sie können damit die für Aufgaben wie Serialisierung und Deserialisierung aufgewendete relative Zeit erkennen.</span><span class="sxs-lookup"><span data-stu-id="54a25-153">You can use it see the relative time spent on tasks such as serialization and deserialization.</span></span> <span data-ttu-id="54a25-154">Diese Daten könnten auf Möglichkeiten zur Optimierung hinweisen &mdash; z.B. durch Verwendung von [Broadcastvariablen](https://spark.apache.org/docs/2.2.0/rdd-programming-guide.html#broadcast-variables), um Datenversand zu vermeiden.</span><span class="sxs-lookup"><span data-stu-id="54a25-154">This data might show opportunities to optimize &mdash; for example, by using [broadcast variables](https://spark.apache.org/docs/2.2.0/rdd-programming-guide.html#broadcast-variables) to avoid shipping data.</span></span> <span data-ttu-id="54a25-155">Die Aufgabenmetriken zeigen auch die Menge der Shuffledaten für eine Aufgabe an sowie die Shufflelese- und Shuffleschreibzeiten.</span><span class="sxs-lookup"><span data-stu-id="54a25-155">The task metrics also show the shuffle data size for a task, and the shuffle read and write times.</span></span> <span data-ttu-id="54a25-156">Wenn diese Werte hoch sind, bedeutet dies, dass große Datenmengen über das Netzwerk verschoben werden.</span><span class="sxs-lookup"><span data-stu-id="54a25-156">If these values are high, it means that a lot of data is moving across the network.</span></span>

<span data-ttu-id="54a25-157">Eine weitere Aufgabenmetrik ist die Planerverzögerung, die misst, wie lange es dauert, eine Aufgabe zu planen.</span><span class="sxs-lookup"><span data-stu-id="54a25-157">Another task metric is the scheduler delay, which measures how long it takes to schedule a task.</span></span> <span data-ttu-id="54a25-158">Im Idealfall sollte dieser Wert niedrig sein im Vergleich zur Executorcomputezeit – der Zeit, die tatsächlich zum Ausführen der Aufgabe aufgewendet wird.</span><span class="sxs-lookup"><span data-stu-id="54a25-158">Ideally, this value should be low compared to the executor compute time, which is the time spent actually executing the task.</span></span>

<span data-ttu-id="54a25-159">Das folgende Diagramm zeigt eine Planerverzögerungszeit (3,7s), die die Executorcomputezeit (1,1s) überschreitet.</span><span class="sxs-lookup"><span data-stu-id="54a25-159">The following graph shows a scheduler delay time (3.7 s) that exceeds the executor compute time (1.1 s).</span></span> <span data-ttu-id="54a25-160">Es wird also mehr Zeit für das Warten auf das Planen von Aufgaben aufgewendet als für die eigentliche Arbeit.</span><span class="sxs-lookup"><span data-stu-id="54a25-160">That means more time is spent waiting for tasks to be scheduled than doing the actual work.</span></span>

![Diagramm der Aufgabenmetriken pro Phase](./_images/grafana-metrics-per-stage.png)

<span data-ttu-id="54a25-162">In diesem Fall wurde das Problem durch zu viele Partitionen verursacht, die einen beträchtlichen Mehraufwand erforderten.</span><span class="sxs-lookup"><span data-stu-id="54a25-162">In this case, the problem was caused by having too many partitions, which caused a lot of overhead.</span></span> <span data-ttu-id="54a25-163">Die Reduzierung der Anzahl von Partitionen verringerte die Planerverzögerungszeit.</span><span class="sxs-lookup"><span data-stu-id="54a25-163">Reducing the number of partitions lowered the scheduler delay time.</span></span> <span data-ttu-id="54a25-164">Das folgende Diagramm zeigt, dass die meiste Zeit für das Ausführen der Aufgabe aufgewendet wird.</span><span class="sxs-lookup"><span data-stu-id="54a25-164">The next graph shows that most of the time is spent executing the task.</span></span>

![Diagramm der Aufgabenmetriken pro Phase](./_images/grafana-metrics-per-stage2.png)

## <a name="streaming-throughput-and-latency"></a><span data-ttu-id="54a25-166">Streamingdurchsatz und Latenz</span><span class="sxs-lookup"><span data-stu-id="54a25-166">Streaming throughput and latency</span></span>

<span data-ttu-id="54a25-167">Der Streamingdurchsatz steht im direkten Zusammenhang mit strukturiertem Streaming.</span><span class="sxs-lookup"><span data-stu-id="54a25-167">Streaming throughput is directly related to structured streaming.</span></span> <span data-ttu-id="54a25-168">Zwei wichtige Metriken sind mit dem Streamingdurchsatz verknüpft: Eingabezeilen pro Sekunde und verarbeitete Zeilen pro Sekunde.</span><span class="sxs-lookup"><span data-stu-id="54a25-168">There are two important metrics associated with streaming throughput: Input rows per second and processed rows per second.</span></span> <span data-ttu-id="54a25-169">Wenn die Zahl der Eingabezeilen pro Sekunde die Zahl der verarbeiteten Zeilen pro Sekunde überschreitet, bedeutet dies, dass das System zur Datenstromverarbeitung im Rückstand ist.</span><span class="sxs-lookup"><span data-stu-id="54a25-169">If input rows per second outpaces processed rows per second, it means the stream processing system is falling behind.</span></span> <span data-ttu-id="54a25-170">Auch wenn die eingehenden Daten von Event Hubs oder Kafka stammen, sollte die Zahl der Eingabezeilen pro Sekunde mit der Datenerfassungsrate am Front-End Schritt halten.</span><span class="sxs-lookup"><span data-stu-id="54a25-170">Also, if the input data comes from Event Hubs or Kafka, then input rows per second should keep up with the data ingestion rate at the front end.</span></span>

<span data-ttu-id="54a25-171">Zwei Aufträge können einen ähnlichen Clusterdurchsatz, jedoch sehr unterschiedliche Streamingmetriken haben.</span><span class="sxs-lookup"><span data-stu-id="54a25-171">Two jobs can have similar cluster throughput but very different streaming metrics.</span></span> <span data-ttu-id="54a25-172">Der folgende Screenshot zeigt zwei verschiedene Workloads.</span><span class="sxs-lookup"><span data-stu-id="54a25-172">The following screenshot shows two different workloads.</span></span> <span data-ttu-id="54a25-173">Sie sind im Hinblick auf den Clusterdurchsatz (Aufträge, Phasen und Aufgaben pro Minute) ähnlich.</span><span class="sxs-lookup"><span data-stu-id="54a25-173">They are similar in terms of cluster throughput (jobs, stages, and tasks per minute).</span></span> <span data-ttu-id="54a25-174">Aber der zweite verarbeitet 12.000 Zeilen/s gegenüber 4.000 Zeilen/s.</span><span class="sxs-lookup"><span data-stu-id="54a25-174">But the second run processes 12,000 rows/sec versus 4,000 rows/sec.</span></span>

![Diagramm des Streamingdurchsatzes](./_images/grafana-streaming-throughput.png)

<span data-ttu-id="54a25-176">Der Streamingdurchsatz ist häufig eine bessere Geschäftsmetrik als der Clusterdurchsatz, da die Anzahl der verarbeiteten Datensätze gemessen wird.</span><span class="sxs-lookup"><span data-stu-id="54a25-176">Streaming throughput is often a better business metric than cluster throughput, because it measures the number of data records that are processed.</span></span>

## <a name="resource-consumption-per-executor"></a><span data-ttu-id="54a25-177">Ressourcenverbrauch pro Executor</span><span class="sxs-lookup"><span data-stu-id="54a25-177">Resource consumption per executor</span></span>

<span data-ttu-id="54a25-178">Diese Metriken helfen Ihnen, die Arbeit der einzelnen Executor zu verstehen.</span><span class="sxs-lookup"><span data-stu-id="54a25-178">These metrics help to understand the work that each executor performs.</span></span>

<span data-ttu-id="54a25-179">**Prozentuale Metriken** messen, wie viel Zeit ein Executor für verschiedene Aktionen aufwendet, als Verhältnis der aufgewendeten Zeit zur gesamten Executorcomputezeit.</span><span class="sxs-lookup"><span data-stu-id="54a25-179">**Percentage metrics** measure how much time an executor spends on various things, expressed as a ratio of time spent versus the overall executor compute time.</span></span> <span data-ttu-id="54a25-180">Die Metriken sind:</span><span class="sxs-lookup"><span data-stu-id="54a25-180">The metrics are:</span></span>

- <span data-ttu-id="54a25-181">% Serialisierungszeit</span><span class="sxs-lookup"><span data-stu-id="54a25-181">% Serialize time</span></span>
- <span data-ttu-id="54a25-182">% Deserialisierungszeit</span><span class="sxs-lookup"><span data-stu-id="54a25-182">% Deserialize time</span></span>
- <span data-ttu-id="54a25-183">% CPU-Executorzeit</span><span class="sxs-lookup"><span data-stu-id="54a25-183">% CPU executor time</span></span>
- <span data-ttu-id="54a25-184">% JVM-Zeit</span><span class="sxs-lookup"><span data-stu-id="54a25-184">% JVM time</span></span>

<span data-ttu-id="54a25-185">Diese Visualisierungen zeigen, wie viel jede dieser Metriken zur gesamten Executorverarbeitung beiträgt.</span><span class="sxs-lookup"><span data-stu-id="54a25-185">These visualizations show how much each of these metrics contributes to overall executor processing.</span></span>

![Diagramm der prozentualen Metriken](./_images/grafana-percentage.png)

<span data-ttu-id="54a25-187">**Shufflemetriken** sind Metriken, die sich auf das Datenshuffling zwischen Executorn beziehen.</span><span class="sxs-lookup"><span data-stu-id="54a25-187">**Shuffle metrics** are metrics related to data shuffling across the executors.</span></span>

- <span data-ttu-id="54a25-188">Shuffle-E/A</span><span class="sxs-lookup"><span data-stu-id="54a25-188">Shuffle I/O</span></span>
- <span data-ttu-id="54a25-189">Shufflearbeitsspeicher</span><span class="sxs-lookup"><span data-stu-id="54a25-189">Shuffle memory</span></span>
- <span data-ttu-id="54a25-190">Dateisystemnutzung</span><span class="sxs-lookup"><span data-stu-id="54a25-190">File system usage</span></span>
- <span data-ttu-id="54a25-191">Datenträgerauslastung</span><span class="sxs-lookup"><span data-stu-id="54a25-191">Disk usage</span></span>

## <a name="common-performance-bottlenecks"></a><span data-ttu-id="54a25-192">Häufige Leistungsengpässe</span><span class="sxs-lookup"><span data-stu-id="54a25-192">Common performance bottlenecks</span></span>

<span data-ttu-id="54a25-193">Zwei häufige Leistungsengpässe in Spark sind *Aufgabennachzügler* und eine *nicht optimale Shufflepartitionszahl*.</span><span class="sxs-lookup"><span data-stu-id="54a25-193">Two common performance bottlenecks in Spark are *task stragglers* and a *non-optimal shuffle partition count*.</span></span>

### <a name="task-stragglers"></a><span data-ttu-id="54a25-194">Aufgabennachzügler</span><span class="sxs-lookup"><span data-stu-id="54a25-194">Task stragglers</span></span>

<span data-ttu-id="54a25-195">Die Phasen in einem Auftrag werden nacheinander ausgeführt, wobei frühere Phasen spätere Phasen blockieren.</span><span class="sxs-lookup"><span data-stu-id="54a25-195">The stages in a job are executed sequentially, with earlier stages blocking later stages.</span></span> <span data-ttu-id="54a25-196">Wenn eine Aufgabe eine Shufflepartition langsamer ausführt als andere Aufgaben, müssen alle Aufgaben im Cluster auf die langsame Aufgabe warten, bevor die Phase abgeschlossen werden kann.</span><span class="sxs-lookup"><span data-stu-id="54a25-196">If one task executes a shuffle partition more slowly than other tasks, all tasks in the cluster must wait for the slow task to catch up before the stage can end.</span></span> <span data-ttu-id="54a25-197">Dies kann aus folgenden Gründen geschehen:</span><span class="sxs-lookup"><span data-stu-id="54a25-197">This can happen for the following reasons:</span></span>

1. <span data-ttu-id="54a25-198">Ein Host oder eine Gruppe von Hosts werden langsam ausgeführt.</span><span class="sxs-lookup"><span data-stu-id="54a25-198">A host or group of hosts are running slow.</span></span> <span data-ttu-id="54a25-199">Symptome: Hohe Aufgaben-, Phasen- oder Auftragslatenz und niedriger Clusterdurchsatz.</span><span class="sxs-lookup"><span data-stu-id="54a25-199">Symptoms: High task, stage, or job latency and low cluster throughput.</span></span> <span data-ttu-id="54a25-200">Die Summe der Aufgabenlatenzen pro Host wird nicht gleichmäßig verteilt.</span><span class="sxs-lookup"><span data-stu-id="54a25-200">The summation of tasks latencies per host won't be evenly distributed.</span></span> <span data-ttu-id="54a25-201">Der Ressourcenverbrauch wird jedoch gleichmäßig auf die Executor verteilt.</span><span class="sxs-lookup"><span data-stu-id="54a25-201">However, resource consumption will be evenly distributed across executors.</span></span>

1. <span data-ttu-id="54a25-202">Aufgaben müssen eine aufwändige Aggregation (Datenschiefe) ausführen.</span><span class="sxs-lookup"><span data-stu-id="54a25-202">Tasks have an expensive aggregation to execute (data skewing).</span></span> <span data-ttu-id="54a25-203">Symptome: Hoher Aufgaben-, Phasen- oder Auftrags- und niedriger Clusterdurchsatz, aber die Summe der Latenzen pro Host wird gleichmäßig verteilt.</span><span class="sxs-lookup"><span data-stu-id="54a25-203">Symptoms: High task, stage, or job and low cluster throughput, but the summation of latencies per host is evenly distributed.</span></span> <span data-ttu-id="54a25-204">Der Ressourcenverbrauch wird gleichmäßig auf die Executor verteilt.</span><span class="sxs-lookup"><span data-stu-id="54a25-204">Resource consumption will be evenly distributed across executors.</span></span>

1. <span data-ttu-id="54a25-205">Wenn Partitionen nicht dieselbe Größe aufweisen, kann eine größere Partition eine unausgeglichene Aufgabenausführung (Partitionsschiefe) verursachen.</span><span class="sxs-lookup"><span data-stu-id="54a25-205">If partitions are of unequal size, a larger partition may cause unbalanced task execution (partition skewing).</span></span> <span data-ttu-id="54a25-206">Symptome: Der Executorressourcenverbrauch ist im Vergleich zu anderen im Cluster ausgeführten Executorn hoch.</span><span class="sxs-lookup"><span data-stu-id="54a25-206">Symptoms: Executor resource consumption is high compared to other executors running on the cluster.</span></span> <span data-ttu-id="54a25-207">Alle auf diesem Executor ausgeführte Aufgaben werden langsam ausgeführt und halten die Phasenausführung in der Pipeline.</span><span class="sxs-lookup"><span data-stu-id="54a25-207">All tasks running on that executor will run slow and hold the stage execution in the pipeline.</span></span> <span data-ttu-id="54a25-208">Diese Phasen werden als *Phasenbarrieren* bezeichnet.</span><span class="sxs-lookup"><span data-stu-id="54a25-208">Those stages are said to be *stage barriers*.</span></span>

### <a name="non-optimal-shuffle-partition-count"></a><span data-ttu-id="54a25-209">Nicht optimale Shufflepartitionszahl</span><span class="sxs-lookup"><span data-stu-id="54a25-209">Non-optimal shuffle partition count</span></span>

<span data-ttu-id="54a25-210">Während einer Strukturiertes-Streaming-Abfrage ist die Zuweisung einer Aufgabe an einen Executor für den Cluster ein ressourcenintensiver Vorgang.</span><span class="sxs-lookup"><span data-stu-id="54a25-210">During a structured streaming query, the assignment of a task to an executor is a resource-intensive operation for the cluster.</span></span> <span data-ttu-id="54a25-211">Wenn die Größe der Shuffledaten nicht optimal ist, beeinträchtigt die Dauer der Verzögerung für eine Aufgabe Durchsatz und Latenz.</span><span class="sxs-lookup"><span data-stu-id="54a25-211">If the shuffle data isn't the optimal size, the amount of delay for a task will negatively impact throughput and latency.</span></span> <span data-ttu-id="54a25-212">Wenn zu wenige Partitionen vorhanden sind, werden die Kerne im Cluster nicht ausreichend ausgelastet, was zu Leistungseinbußen bei der Verarbeitung führen kann.</span><span class="sxs-lookup"><span data-stu-id="54a25-212">If there are too few partitions, the cores in the cluster will be underutilized which can result in processing inefficiency.</span></span> <span data-ttu-id="54a25-213">Wenn andererseits zu viele Partitionen vorhanden sind, entsteht ein hoher Verwaltungsmehraufwand für eine kleine Anzahl von Aufgaben.</span><span class="sxs-lookup"><span data-stu-id="54a25-213">Conversely, if there are too many partitions, there's a great deal of management overhead for a small number of tasks.</span></span>

<span data-ttu-id="54a25-214">Verwenden Sie die Metriken zum Ressourcenverbrauch, um Partitionsschiefe und Fehlzuordnung von Executorn im Cluster zu beheben.</span><span class="sxs-lookup"><span data-stu-id="54a25-214">Use the resource consumption metrics to troubleshoot partition skewing and misallocation of executors on the cluster.</span></span> <span data-ttu-id="54a25-215">Wenn eine Partition verzerrt ist, werden Executorressourcen im Vergleich zu anderen im Cluster ausgeführten Executorn erhöht.</span><span class="sxs-lookup"><span data-stu-id="54a25-215">If a partition is skewed, executor resources will be elevated in comparison to other executors running on the cluster.</span></span>

<span data-ttu-id="54a25-216">Das folgende Diagramm zeigt beispielsweise, dass der für das Shuffling verwendete Arbeitsspeicher auf den ersten beiden Executorn 90-mal größer ist als auf den anderen Executorn:</span><span class="sxs-lookup"><span data-stu-id="54a25-216">For example, the following graph shows that the memory used by shuffling on the first two executors is 90X bigger than the other executors:</span></span>

![Diagramm der prozentualen Metriken](./_images/grafana-shuffle-memory.png)